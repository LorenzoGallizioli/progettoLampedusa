knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
<<<<<<< HEAD
=======
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
nba_model <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
<<<<<<< HEAD
=======
nba_model <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [ dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST ]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df = dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82]
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
<<<<<<< HEAD
install.packages("corrplot")
=======
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
library(corrplot)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
<<<<<<< HEAD
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE
df$o_canestriSuTotali <- df$o_fgm/df$o_fga # proporzione tra tiri realizzati su tiri totali
df$d_canestriSuTotali <- df$d_fgm/df$d_fga # proporzione tra tiri subiti su tiri totali
df$d_stoppateSuTiri <- df$d_blk/df$d_fga # proporzione su quanti tiri tentati sono stati stoppati
df$o_rimbTiriSbagliati <- df$o_oreb/(df$o_fga-df$o_fgm) # percentuale di rimbalzi presi su tiri sbagliati in attacco
df$d_rimbDef <- df$d_dreb/(df$d_fga-df$d_fgm) # percentuale di rimbalzi difensivi presi in difesa
df$formula_metric <- df$d_pf * (df$o_ftm / df$o_fta)^2 * (df$o_ftm / (df$o_ftm + 2 * (df$o_fgm - df$o_3pm) + 3 * df$o_3pm))
# Modello di regressione 1
(linMod <- lm(won ~ o_canestriSuTotali + d_canestriSuTotali + d_stoppateSuTiri + o_rimbTiriSbagliati + d_rimbDef + formula_metric, data = df ))
summary (linMod)
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time
# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
df$d_canestriSuTotali_z <- scale(df$d_canestriSuTotali)
df$d_stoppateSuTiri_z <- scale(df$d_stoppateSuTiri)
df$o_rimbTiriSbagliati_z <- scale(df$o_rimbTiriSbagliati)
df$d_rimbDef_z <- scale(df$d_rimbDef)
# Modello di regressione 2
(linModNormalized <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = df ))
summary (linModNormalized)
# TEST SUL MODELLO DI REGRESSIONE LINEARE
# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)
# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
summary(m)
plot(m)
shapiro.test(residuals(m))
summary(m)
plot(m, which = 1)
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
'''Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.
Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01.
In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling. '''
=======
detach("package:corrplot", unload = TRUE)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
boxplot(df$won ~ df$tmID, las=2)
cor()
library(corrplot)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
boxplot(df$won ~ df$tmID, las=2)
cor()
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[,c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
df$lgID <- as.factor(df$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
as.matrix(df[, c(11:25, 54)])
as.matrix(df[, c(11:25, 54)]))
df
dataset
# INIZIALIZZAZIONE DATI E GRAFICI DATI
full_df <- read.csv("0_Materiale/basketball_teams_comma.csv") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- full_df [full_df$lgID=="NBA" & full_df$year >= FIRST & full_df$year <= LAST & full_df$games==82,]
df$lgID <- as.factor(df$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
<<<<<<< HEAD
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE
df$o_canestriSuTotali <- df$o_fgm/df$o_fga # proporzione tra tiri realizzati su tiri totali
df$d_canestriSuTotali <- df$d_fgm/df$d_fga # proporzione tra tiri subiti su tiri totali
df$d_stoppateSuTiri <- df$d_blk/df$d_fga # proporzione su quanti tiri tentati sono stati stoppati
df$o_rimbTiriSbagliati <- df$o_oreb/(df$o_fga-df$o_fgm) # percentuale di rimbalzi presi su tiri sbagliati in attacco
df$d_rimbDef <- df$d_dreb/(df$d_fga-df$d_fgm) # percentuale di rimbalzi difensivi presi in difesa
df$formula_metric <- df$d_pf * (df$o_ftm / df$o_fta)^2 * (df$o_ftm / (df$o_ftm + 2 * (df$o_fgm - df$o_3pm) + 3 * df$o_3pm))
# Modello di regressione 1
(linMod <- lm(won ~ o_canestriSuTotali + d_canestriSuTotali + d_stoppateSuTiri + o_rimbTiriSbagliati + d_rimbDef + formula_metric, data = df ))
summary (linMod)
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time
# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
df$d_canestriSuTotali_z <- scale(df$d_canestriSuTotali)
df$d_stoppateSuTiri_z <- scale(df$d_stoppateSuTiri)
df$o_rimbTiriSbagliati_z <- scale(df$o_rimbTiriSbagliati)
df$d_rimbDef_z <- scale(df$d_rimbDef)
# Modello di regressione 2
(linModNormalized <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = df ))
summary (linModNormalized)
# TEST SUL MODELLO DI REGRESSIONE LINEARE
# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)
# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
summary(m)
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
'''Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.
Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01.
In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling. '''
install.packages("nortest")
library(corrplot)
library(nortest)
knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
'''Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.
Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01.
In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling. '''
install.packages("nortest")
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
#Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01. In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling.
#TEST KOLMOGOROV SMIRNOV
ks.test(df$reb, "pnorm")
# Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme). In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.
#TEST SHAPIRO WILK
sf.test(df$reb)
#In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa.
install.packages("nortest")
knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
library(nortest)
library(corrplot)
sf.test(df$reb)
df$reb = df$o_reb + df$d_reb
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
#Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01. In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling.
#TEST KOLMOGOROV SMIRNOV
ks.test(df$reb, "pnorm")
# Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme). In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.
#TEST SHAPIRO WILK
sf.test(df$reb)
#In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa.
install.packages("nortest")
df$reb <- c(df$o_reb + df$d_reb, o_oreb)
knitr::opts_chunk$set(echo = TRUE)
library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
=======
# INIZIALIZZAZIONE DATI E GRAFICI DATI
dataset <- read.csv("0_Materiale/basketball_teams_comma.csv") # andiamo a leggere il database fornito
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio
df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)
# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]
hist(df$won)
plot(density(df$won))
M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
<<<<<<< HEAD
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
boxplot(df$won ~ df$tmID, las=2)
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE
# """
# o_oreb = palle riprese dopo azione in attacco
# o_dreb = palle perse dopo azione in attacco
# o_reb  = totale rimbalzi in attacco
# d_oreb = palle perse dopo azione subita
# d_dreb = palle riprese dopo azione subita
# d_reb  = totale rimbalzi in difesa
# formula rapporto:
# o_oreb / o_reb
# formula differenza:
# o_oreb - o_dreb
#   (2 * df$o_to * df$d_to) / (df$o_dreb * df$d_oreb)
# MODELLO "L'IMPORTANZA DEI RIMBALZI"
# Formula 1 [Coefficiente di possesso rimbalzi offensivi]:
# - Abbiamo trovato questa formula importante perché rappresenta la capacità della squadra di ripossesso della palla
# dopo un tiro che non va a canestro e colpisce il tabellone
# Formula 2 [Coefficiente di contropiede]:
# - Abbiamo trovato questa formula importante perché rappresenta la capacità della squadra di impossessarsi della
# palla dopo un tiro sbagliato della squadra avversaria che colpisce il tabellone, che troviamo un buon stimatore
# della capacità di contropiede della squadra
# Formula 3 [Coefficiente ]
# - Abbiamo trovato questa formula importante perché rappresenta il rapporto tra le palle riprese nei rimbalzi (sia
# offensivi che difensivi) rispetto alle palle perse nei rimbalzi (sia offensivi che difensivi). I coefficienti
# sono stati scelti in base a ciò che riteniamo più importante in una partita, ossia la difesa del proprio
# canestro
# Formula 4:
#
df$f1 <- (df$o_oreb)/(df$o_fga-df$o_fgm)
df$f2 <- (df$d_dreb)/(df$d_fga-df$d_fgm)
df$f3 <- (df$o_oreb + 1.5 * df$d_dreb)/(df$o_dreb + 2 * df$d_oreb)
df$f4 <- (df$o_oreb - df$o_dreb) + 1.5 * (df$d_dreb - df$d_oreb)
df$f5 <- (df$d_oreb / df$d_to) / (df$o_dreb / df$o_to)
# Modello di regressione 1
linMod <- lm(won ~ f1 + f2 + f3 + f4 + f5, data = df)
summary (linMod)
plot(linMod)
# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time
# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
# TEST SUL MODELLO DI REGRESSIONE LINEARE
# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)
# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]
m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
df$reb <- c(df$o_reb + df$d_reb, o_oreb)
df$reb <- c(df$o_reb + df$d_reb, df$o_oreb)
df$reb <- c(df$o_reb + df$d_reb)
summary(df$reb)
hist (df$reb, col = 'steelblue', main = 'caccaculo',
xlab = 'Petal Width')
plot(density(df$reb))
df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
title="Correlation Matrix between Predictor and Outcome variables")
pie(df$reb, labels=df$tmID)
barplot(df$reb, col = c("#1b98e0", "#353436"))
legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))
boxplot(df$won ~ df$reb, las=2)
heatmap(cbind(df$o_reb, df$d_reb))
#TEST ANDERSON-DARLING
install.packages('nortest')
library(nortest)
ad.test(df$reb)
#Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01. In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling.
#TEST KOLMOGOROV SMIRNOV
ks.test(df$reb, "pnorm")
# Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme). In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.
#TEST SHAPIRO WILK
sf.test(df$reb)
#In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa.
install.packages("nortest")
install.packages("Rtools")
=======
>>>>>>> f7f1feea52913bf9662d97ff768f7d7c704de895
