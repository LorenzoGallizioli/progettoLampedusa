---
title: "Analisi Statistica del dataframe Basketball Teams, Gruppo Lampedusa"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document:
    latex_engine: xelatex
  word_document: default
author: "Bonsembiante Davide, Fumagalli Uriel, Gallizioli Lorenzo, Paganelli Thomas"
abstract: "Questo documento rappresenta un'approfondita analisi statistica nel campo del basket professionistico, con un focus specifico sulle prestazioni delle squadre NBA. Utilizzando metodi statistici avanzati, si esplorano diverse metriche chiave per comprendere meglio le dinamiche del gioco e i fattori che influenzano il successo delle squadre."
editor_options: 
  markdown: 
    wrap: 80
    reference_location: document
---

# Indice

- [Indice](#indice)
- [Progetto scelto: 5](#progetto-scelto-5)
- [Presentazione problema](#presentazione-problema)
- [Analisi dati iniziale e grafici](#analisi-dati-iniziale-e-grafici)
  - [Correlazione dati](#correlazione-dati)
  - [Analisi vittorie](#analisi-vittorie)
    - [Boxplot](#boxplot)
    - [Densità](#densità)
  - [Analisi rimbalzi](#analisi-rimbalzi)
    - [Densità variabili singole](#densità-variabili-singole)
    - [Percentuale di valori non zero per ciascuna variabile di interesse](#percentuale-di-valori-non-zero-per-ciascuna-variabile-di-interesse)
    - [Heatmap](#heatmap)
    - [Barplot](#barplot)
    - [Densità](#densità)
    - [Boxplot](#boxplot)
  - [Test](#test)
    - [Test Anderson-Darling](#test-anderson-darling)
    - [Test Kolmogorov-Smirnov](#test-kolmogorov-smirnov)
    - [Test Shapiro-Wilk](#test-shapiro-wilk)
- [Presentazione modello lineare](#presentazione-modello-lineare)
  - [Modello: L'importanza dei rimbalzi](#modello-limportanza-dei-rimbalzi)
  - [Formule](#formule)
  - [Modello lineare sul dataframe train](#modello-lineare-sul-dataframe-train)
  - [Legenda significato acronimi:](#legenda-significato-acronimi)
  - [Divisione dataframe in train e test](#divisione-dataframe-in-train-e-test)
  - [Modello lineare normalizzato sul dataframe train](#modello-lineare-normalizzato-sul-dataframe-train)
  - [Normalizzazione](#normalizzazione)
  - [Grafici](#grafici)
  - [Test modello lineare](#test-modello-lineare)
    - [Summary](#summary)
    - [R-quadrato](#r-quadrato)
    - [R-quadrato Adattato](#r-quadrato-adattato)
    - [Test Shapiro](#test-shapiro)
    - [Test di omoschedasticità](#test-di-omoschedasticità)
    - [Test di multicollinearità](#test-di-multicollinearità)
  - [Rimozione outliers e LASSO](#rimozione-outliers-e-lasso)
    - [Identificazione degli Outliers](#identificazione-degli-outliers)
    - [Rimozione degli Outliers](#rimozione-degli-outliers)
    - [Confronto dei Modelli Prima e Dopo la Rimozione degli Outliers](#confronto-dei-modelli-prima-e-dopo-la-rimozione-degli-outliers)
    - [Grafico di Influenza:](#grafico-di-influenza)
    - [Visualizzazione Residui e Leverage](#visualizzazione-residui-e-leverage)
    - [Risultati](#risultati)
    - [Implementazione del Modello LASSO per l'Ottimizzazione della Regressione](#implementazione-del-modello-lasso-per-lottimizzazione-della-regressione)
    - [Allenamento modello LASSO](#allenamento-modello-lasso)
    - [Valutazione Comparativa delle Previsioni: LASSO contro Modello Lineare](#valutazione-comparativa-delle-previsioni-lasso-contro-modello-lineare)
    - [Valutazione delle Prestazioni del Modello](#valutazione-delle-prestazioni-del-modello)
    - [Calcolo delle Metriche di Valutazione](#calcolo-delle-metriche-di-valutazione)
    - [Analisi della Varianza (ANOVA) per Valutazione di Fattori Categorici](#analisi-della-varianza-anova-per-valutazione-di-fattori-categorici)
    - [Analisi dell'Effetto della Variabile 'confID'](#analisi-delleffetto-della-variabile-confid)
    - [Analisi degli Effetti di Interazione](#analisi-degli-effetti-di-interazione)
    - [Costruzione del Modello con Effetti di Interazione](#costruzione-del-modello-con-effetti-di-interazione)
    - [Selezione delle Interazioni Significative](#selezione-delle-interazioni-significative)
    - [Rifinitura e Valutazione del Modello Finale](#rifinitura-e-valutazione-del-modello-finale)
  - [Esplorazione del Modello di Regressione di Poisson](#esplorazione-del-modello-di-regressione-di-poisson)
    - [Costruzione del Modello di Poisson](#costruzione-del-modello-di-poisson)
    - [Confronto dei Coefficienti dei Modelli Lineare e di Poisson](#confronto-dei-coefficienti-dei-modelli-lineare-e-di-poisson)
- [Considerazioni Generali:](#considerazioni-generali)
- [Conclusioni](#conclusioni)

---

# Progetto scelto: 5

- **Variabile Dipendente**
  - Numero di Vittorie per Stagione: Questa variabile rappresenta l'obiettivo primario dell'analisi, indicando il successo complessivo di una squadra nel corso di una singola stagione NBA.
- **Covariate**
  - Variabili Selezionate: A seconda degli obiettivi specifici dell'analisi, verranno incluse diverse covariate. Queste possono comprendere una vasta gamma di metriche di gioco.
- **Criterio di Selezione della Squadra**
  - Partite Giocate: Nel dataset, si considereranno esclusivamente le squadre che hanno disputato un totale di 82 partite nella stagione (identificate come `df$games == 82`). Questo criterio assicura l'uniformità e la comparabilità dei dati analizzati.

---

# Presentazione problema

In questo report, ci siamo concentrati sull'elaborazione di un modello lineare predittivo per determinare il numero di vittorie in funzione dei rimbalzi annuali effettuati dalle squadre nella NBA. Il modello si applica esclusivamente a squadre che hanno disputato almeno 82 partite per stagione, considerando un arco temporale che va dal 1976 al 2011.

L'approccio del modello lineare si basa sull'adozione di coefficienti accuratamente selezionati, mirati a massimizzare la significatività e l'aderenza alla nostra interpretazione dell'impatto di specifiche variabili sulle vittorie. Questi coefficienti sono stati scelti in modo da riflettere al meglio la nostra concezione di quali fattori influenzino maggiormente il successo delle squadre.

Ulteriori informazioni riguardanti l'esecuzione del programma e l'utilizzo della funzione predittiva sono fornite nei paragrafi successivi, dove viene anche descritto il processo di sviluppo e validazione del modello.

```{r Inizializzazione, message=FALSE, warning=FALSE, include=FALSE}

# Carica le librerie necessarie
library(here)         # Gestione dei percorsi dei file
library(corrplot)     # Visualizzazione matrice di correlazione
library(nortest)      # Test di normalità
library(lmtest)       # Test diagnostici per modelli lineari
library(car)          # Test di collinearità e altri test per modelli lineari
library(plotly)       # Visualizzazioni interattive
library(heatmaply)    # Heatmap interattivo
library(ggheatmap)    # Heatmap con ggplot2
library(gridExtra)    # Organizzazione di grafici con grid
library(ggfortify)    # Visualizzazioni grafiche per modelli statistici
library(olsrr)        # Diagnostica e grafici per modelli di regressione
library(ggplot2)      # Creazione di grafici con ggplot2
library(viridis)      # Colormaps viridis
library(glmnet)       # Modelli di regressione con penalizzazione lasso ed elastic net
library(highcharter)  # Creazione di grafici interattivi con Highcharts
library(reshape2)     # Manipolazione dati
library(RColorBrewer) # Colormaps
library(tidyr)        # Manipolazione dati
library(dplyr)        # Manipolazione dati

# Configura il percorso di root per la generazione di report
knitr::opts_knit$set(root.dir = here("0_Materiale"))

```

---

# Analisi dati iniziale e grafici


Il chunk riportato legge un dataset da un file, filtra le righe in base ai criteri sopra riportati, calcola una nuova variabile e offre la possibilità di ottenere un riassunto statistico dei dati filtrati.
```{r Lettura dati dal dataset}

# Leggi il dataset da un file di testo
filepath <- here("0_Materiale", "basketball_teams.txt")
dataset <- read.delim(filepath)

# Definisci il primo e l'ultimo anno del range da considerare per lo studio
FIRST <- 1976
LAST <- 2011

# Filtra il dataset secondo le condizioni specificate
df <- dataset[dataset$lgID == "NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games == 82,]

# Converti la colonna lgID in un fattore per consentire la generazione di variabili dummy
dataset$lgID <- as.factor(dataset$lgID)

# Stampiamo un riassunto statistico del dataframe filtrato
# summary(df)

```


## Correlazione dati
La mappa di calore della matrice di correlazione, o "corrplot", è un metodo visivo efficace per esaminare le relazioni bivariate tra tutte le variabili di un dataset. In questo particolare corrplot, ogni cella rappresenta il coefficiente di correlazione tra le variabili sulle righe e le colonne.
Le tonalità di colore variano in base alla forza e alla direzione della correlazione:

- Le tonalità più scure di viola indicano una correlazione negativa forte o nessuna correlazione.
- Le tonalità più chiare di arancione o bianco indicano una correlazione positiva.

L'asse delle ordinate (Y) e l'asse delle ascisse (X) elencano le variabili incluse nel dataset, permettendo di identificare rapidamente quali coppie di variabili mostrano le correlazioni più forti. Ad esempio, una cella chiara sulle diagonali rappresenta la perfetta correlazione positiva di una variabile con sé stessa, mentre le altre celle off-topic permettono di vedere come ogni variabile si relaziona con le altre.

Questa rappresentazione grafica è particolarmente utile per identificare potenziali problemi di multicollinearità in modelli di regressione, dove variabili altamente correlate possono distorcere o influenzare eccessivamente i risultati. Inoltre, può aiutare a scoprire pattern interessanti nei dati che potrebbero meritare ulteriori indagini.
```{r Analisi correlazione dati - corrplot, echo=FALSE, warning = FALSE, message = FALSE}

# CORRPLOT

data_subset <- df[, c(11:40, 54)]
cor_matrix <- cor(data_subset, use = "complete.obs")  

cor_data <- melt(cor_matrix)
names(cor_data) <- c("Variable1", "Variable2", "Correlation")



# HEATMAP

p <- plot_ly(data = cor_data, x = ~Variable1, y = ~Variable2, z = ~Correlation,
             type = "heatmap",
             colors = viridis(n = 1024, option = "magma"),
             hoverinfo = "x+y+z") %>%
  layout(
    title = '<b><i>Correlation Matrix Heatmap</i></b>',
    xaxis = list(
      title = list(text = "<b><i>Variabile 1</i></b>", standoff = 0),
      tickangle = 45,
      zeroline = FALSE
    ),
    yaxis = list(
      title = list(text = "<b><i>Variabile 2</i></b>", standoff = 0),
      tickangle = 45,
      zeroline = FALSE
    ),
    autosize = TRUE
  )

# Visualizza la heatmap
(p)

```

## Analisi vittorie

### Boxplot

Il grafico presentato è un insieme di box plot, una rappresentazione grafica utilizzata per evidenziare la distribuzione e la variabilità delle vittorie per diverse squadre sportive, ognuna codificata con un colore distinto. Il box plot visualizza cinque statistiche descrittive principali: il minimo, il primo quartile (Q1), la mediana, il terzo quartile (Q3) e il massimo. La linea che attraversa il box rappresenta la mediana, il valore centrale del dataset. Le "antenne" si estendono dal box fino ai valori minimi e massimi esclusi gli outliers, che sono rappresentati come punti individuali. Questo tipo di grafico è particolarmente utile per confrontare le distribuzioni tra più gruppi e per identificare eventuali deviazioni significative dalla norma.

```{r Analisi distribuzione vittorie - boxplot, echo=FALSE, message=FALSE, warning=FALSE}

# BOXPLOT

aggregated_data <- df %>%
  select(tmID, year, won) %>%
  group_by(tmID, year) %>%
  summarize(
    won = mean(won, na.rm = TRUE),
  )

reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(won), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")

fig <- plot_ly()

for (i in 2:ncol(reshaped_data)) {
  current_column_data <- reshaped_data[[i]]
  fig <- fig %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

# Visualizza il boxplot interattivo
(fig)

```

Dall'analisi del box plot si osserva un'ampia variazione nel numero di vittorie tra le squadre. Alcune squadre dimostrano una maggiore coerenza nelle prestazioni, come evidenziato da box più stretti, mentre altre presentano una maggiore dispersione dei risultati, suggerendo una variabilità significativa nelle loro prestazioni durante la stagione. Gli outliers indicano delle prestazioni eccezionali o sotto la media rispetto al resto del campione. La mediana di ciascuna squadra offre una valutazione robusta delle loro prestazioni tipiche escludendo l'influenza di tali valori anomali.

```{r Analisi distribuzione vittorie istogramma, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

# ISTOGRAMMA INTERATTIVO

# Calcola la media della variabile "won" nel data frame "df"
mean_value <- mean(df$won)

# Crea un istogramma con plot_ly
histogram <- plot_ly(df, x = ~won, type = "histogram",
                     marker = list(color = "skyblue", line = list(color = "white", width = 0.5)),
                     opacity = 0.7, name = "Campione") %>%
  layout(title = list(text = "<b><i>Distribuzione delle Vittorie</i></b>", y = 0.97),
         xaxis = list(title = "<b><i>Numero di Vittorie</i></b>", zeroline = FALSE),
         yaxis = list(title = "<b><i>Frequenza</i></b>", zeroline = FALSE),
         barmode = "overlay") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "lines", 
            line = list(color = "red", width = 2), name = "<i><b>Media</i></b>") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "markers", 
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean_value, y = 0, 
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2)

# Visualizza l'istogramma interattivo
histogram

```

### Densità

Il secondo grafico è un diagramma di densità, il quale fornisce una stima continua della distribuzione di probabilità delle vittorie complessive. La linea curva riflette la densità di probabilità, dove picchi più alti corrispondono a un numero maggiore di osservazioni vicine a un particolare valore. La linea rossa verticale indica la media delle vittorie, fornendo un punto di riferimento per la posizione centrale della distribuzione.

```{r, Analisi distribuzione vittorie densita, warning = FALSE, echo = FALSE, message = FALSE}

# PLOT DENSITA INTERATTIVO

# Calcola la densità delle vittorie
density_plot <- density(df$won)

# Crea il plot di densità con plot_ly
density_interactive <- plot_ly(x = density_plot$x, y = density_plot$y, type = "scatter", mode = "lines",
                               line = list(color = "skyblue", width = 2), name = "Densità") %>%
  layout(title = list(text = "<b><i>Distribuzione di Densità delle Vittorie</i></b>", x = 0.5),
         xaxis = list(title = "<i>Numero di Vittorie</i>"),
         yaxis = list(title = "<i>Densità</i>"),
         showlegend = TRUE) %>%
  add_trace(x = c(mean(df$won), mean(df$won)), y = c(0, max(density_plot$y)),
            type = "scatter", mode = "lines", line = list(color = "red", width = 2),
            name = "<i><b>Media</b></i>") %>%
  add_trace(x = mean(df$won), y = max(density_plot$y), type = "scatter", mode = "markers",
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean(df$won), y = max(density_plot$y) * 1.05,
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2,
                  ax = 0, ay = -40)

# Visualizza il plot di densità interattivo
density_interactive

```

Osservando il diagramma di densità, si nota che la distribuzione delle vittorie complessive assume una forma approssimativamente simmetrica attorno alla media, indicata dalla linea rossa verticale. Questo suggerisce che, per il campione in esame, le vittorie sono distribuite in modo relativamente uniforme intorno al valore medio, con una tendenza a seguire una distribuzione normale. Tale simmetria e il picco pronunciato attorno alla media possono implicare che le prestazioni delle squadre tendono a raggrupparsi intorno a un 'valore tipico', con deviazioni che seguono un modello prevedibile.

## Analisi rimbalzi

Nel nostro dataframe sono incluse variabili specifiche per analizzare in dettaglio il ruolo dei rimbalzi nel basket. Ecco una descrizione degli acronimi utilizzati:

- o_oreb: **Rimbalzi ottenuti in attacco**
  - Questo valore rappresenta il numero di volte in cui una squadra recupera la palla dopo un tiro mancato mentre è in fase offensiva. È un indicatore diretto dell'aggressività e dell'efficacia offensiva di una squadra.
- o_dreb: **Rimbalzi subiti in attacco**
  - Indica il numero di rimbalzi che una squadra concede all'avversario mentre è in attacco. Un valore più basso suggerisce una maggiore capacità di mantenere il controllo della palla dopo un tiro mancato.
- o_reb: **Totale rimbalzi in attacco** 
  - Questa è la somma dei rimbalzi ottenuti e subiti in attacco. Fornisce una misura complessiva dell'attività di rimbalzo di una squadra quando è in fase offensiva.
- d_oreb: **Rimbalzi subiti in difesa**
  - Rappresenta il numero di rimbalzi che una squadra permette all'avversario di ottenere mentre è in difesa. Minimizzare questo numero è cruciale per prevenire seconde opportunità di punteggio per l'avversario.
- d_dreb: **Rimbalzi ottenuti in difesa**
  - Indica il numero di volte in cui una squadra recupera la palla dopo un tiro mancato dall'avversario mentre è in difesa. È un indicatore chiave dell'efficacia difensiva e della capacità di interrompere l'attacco avversario.
- d_reb: **Totale rimbalzi in difesa**
  - Questo è il totale dei rimbalzi che una squadra ottiene o concede mentre è in difesa. Offre una visione olistica dell'impegno e dell'efficacia di una squadra nel controllare la zona difensiva durante il gioco.

### Densità variabili singole

Gli istogrammi delle variabili (di cui abbiamo approssimato la curva di densità) che ora vediamo rappresentano la distribuzione dei dati per diverse variabili, mostrando la frequenza o la probabilità di osservazione entro intervalli specifici. Le curve di densità forniscono una stima continua della distribuzione di probabilità e sono spesso confrontate con una distribuzione normale, indicata da una linea rossa.

```{r Plot densita per ogni variabile, echo = FALSE}

# Creazione di una nuova variabile 'reb' come somma di 'o_reb' e 'd_reb'
df$reb <- c(df$o_reb + df$d_reb)

# Seleziona le colonne pertinenti dal dataframe
df_reb <- subset(df, select = c("o_oreb", "o_dreb", "o_reb", "d_oreb", "d_dreb", "d_reb", "won"))

# Imposta il layout a 2 righe e 3 colonne per i grafici di densità
par(mfrow = c(2, 3))

# Ciclo per generare grafici di densità per ciascuna variabile di interesse
for (variables in 1:(dim(df_reb)[2]-1)) {
  thisvar <- df_reb[, variables]
  d <- density(thisvar)
  xmin <- floor(min(thisvar))
  xmax <- ceiling(max(thisvar))
  
  # Crea il plot della densità con stile accattivante
  plot(d, main = names(df_reb)[variables], xlab = "", col = "blue", lwd = 1.5, xlim = c(xmin, xmax), ylim = c(0, max(d$y)*1.1))
  
  # Aggiungi la distribuzione normale teorica ideale in rosso
  x <- seq(xmin, xmax, length = 100)
  lines(x, dnorm(x, mean = mean(thisvar), sd = sd(thisvar)), col = "red", lwd = 1.5)  # Modifica lo spessore delle linee
  
  # Aggiungi griglia per migliorare la leggibilità
  grid()
}

# Aggiungi titolo in grassetto e corsivo, con spessore del testo modificato
title(bquote(bold(italic("Density plots with Normal Distribution"))), line = -17, cex.main = 2, outer = TRUE)

```

Dai grafici osservati, è possibile trarre conclusioni riguardo la normalità della distribuzione dei dati per ciascuna variabile. Se la curva di densità blu segue da vicino la linea rossa della distribuzione normale, ciò implica che i dati di quella variabile potrebbero essere ben modellati da una distribuzione normale. Deviazioni significative da questa linea potrebbero indicare asimmetria o presenza di outlier. Tali informazioni sono vitali per la scelta di test statistici appropriati e per la comprensione delle caratteristiche fondamentali dei dati analizzati.

### Percentuale di valori non zero per ciascuna variabile di interesse

Viene Calcolata la percentuale di valori non zero per ciascuna variabile di interesse all'interno del dataframe df_reb, serve per verificare ulteriormente la consistenza dei dati acqusiti.
```{r Percentuale di valori non zero per ogni variabile, echo = FALSE}

# Stampa percentuale di valori non zero per ciascuna variabile di interesse
print(paste("Percentage non-zero o_oreb: ", round(length(which(df_reb$o_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_dreb: ", round(length(which(df_reb$o_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_reb: ", round(length(which(df_reb$o_reb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_oreb: ", round(length(which(df_reb$d_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_dreb: ", round(length(which(df_reb$d_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_reb: ", round(length(which(df_reb$d_reb > 0)) / dim(df_reb)[1] * 100, 2)))

```

### Heatmap

Il grafico presentato è una combinazione di heatmap e dendrogramma. La heatmap è una rappresentazione visiva dei dati dove i valori individuali contenuti in una matrice sono rappresentati come colori. In questo caso, è probabile che i colori rappresentino l'intensità dei rimbalzi (offensivi e difensivi) di squadre sportive, mentre i dendrogrammi ai lati rappresentano una gerarchia di clustering basata sulla somiglianza delle prestazioni tra le squadre. Questo tipo di visualizzazione permette di identificare rapidamente modelli, come gruppi di squadre con prestazioni simili, e correlazioni tra i diversi tipi di rimbalzi.

```{r Heatmap rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

# Calcolo di valori aggregati per le variabili specificate
values <- aggregate(cbind(reb, o_oreb, o_dreb, d_oreb, d_dreb, o_reb, d_reb, won) ~ tmID, data = df, FUN = sum)


# HEATMAP

heatmap_df <- subset(values, select = -c(o_oreb, o_dreb, d_oreb, d_dreb, won, reb))
rownames(heatmap_df) <- heatmap_df$tmID
heatmap_df <- heatmap_df[,-1]

heatmap_plot <- heatmaply(
 heatmap_df,
 colors = viridis(n = 256,  option = "magma"),
 k_col = 2,
 k_row = 4,
)

(heatmap_plot)

```

L'analisi della heatmap e del dendrogramma indica l'esistenza di distinti gruppi di squadre che mostrano pattern simili nei rimbalzi. I cluster formati nel dendrogramma evidenziano relazioni che non sarebbero immediatamente ovvie senza questa forma di analisi gerarchica. Le gradazioni di colore nella heatmap offrono una visione intuitiva dell'intensità dei rimbalzi: colori più caldi indicano un numero maggiore di rimbalzi, mentre colori più freddi ne indicano di meno. Questo permette di identificare facilmente le squadre con prestazioni eccezionali o sottotono.

### Barplot

Il secondo grafico è un diagramma a barre sovrapposte che confronta due variabili categoriche: i rimbalzi offensivi e difensivi per ogni squadra, rappresentati con colori distinti. Le barre verticali mostrano il numero totale di rimbalzi per ciascuna squadra, permettendo di comparare direttamente i rimbalzi offensivi con quelli difensivi.

```{r Barplot stacked rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

# BARPLOT

bar_plot <- plot_ly(values, x = ~tmID, y = ~o_reb, type = 'bar', name = 'Rimbalzi offensivi', marker = list(color = '#FFAFA1')) %>%
  add_trace(y = ~d_reb, name = 'Rimbalzi difensivi', marker = list(color = '#b2fff8')) %>%
  layout(yaxis = list(title = 'Valori'), barmode = 'stack')

(bar_plot)

```

L'esame del grafico a barre sovrapposte non rivela variazioni significative nel rapporto tra rimbalzi offensivi e difensivi tra le squadre, mostrando una tendenza all'auto-bilanciamento tra le due.

```{r Istogramma rimbalzi, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

# ISTOGRAMMA INTERATTIVO

histogram <- plot_ly(data = df, x = ~reb, type = "histogram",
        marker = list(color = 'skyblue', line = list(color = 'black', width = 1)),
        nbinsx = 20, legendgroup = "Rimbalzi", name = "Campione") %>% 
  add_trace(type = "scatter", mode = "lines",
            x = c(mean(df$reb), mean(df$reb)),
            y = c(0, 215),
            line = list(color = "red", width = 2, dash = "dash"),
            name = "Media") %>%
  layout(title = list(text = "<b><i>Istogramma dei Rimbalzi</i></b>", pad = 10),
         xaxis = list(title = '<b><i>Rimbalzi</i></b>'),
         yaxis = list(title = '<b><i>Frequenza</i></b>'),
         legend = list(title = "<b><i>Legenda</i></b>", tracegrouporder = "reversed"))

(histogram)

```

### Densità

Il terzo grafico è un diagramma di densità che confronta la distribuzione totale dei rimbalzi con una distribuzione normale ideale. La densità è mostrata dalla curva blu, mentre la distribuzione normale ideale è rappresentata dalla linea verde (con area sottostante). La linea rossa tratteggiata indica la media dei rimbalzi totali.

```{r Densita rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

# PLOT DI DENSITA CON SOVRAPPOSIZIONE DI UNA NORMALE IDEALE

density_data <- density(df$reb)
mu <- mean(df$reb)
sigma <- sd(df$reb)
normal_data <- dnorm(density_data$x, mean = mu, sd = sigma)

density_plot <- plot_ly(x = density_data$x, y = density_data$y, type = 'scatter', mode = 'lines',
             line = list(color = 'blue', width = 2),
             name = "Densità rimbalzi totale") %>%
  layout(title = "Densità dei Rimbalzi",
         xaxis = list(title = "Rimbalzi"),
         yaxis = list(title = "Density", autotick = TRUE, autorange = TRUE))

density_plot <- add_trace(density_plot, x = density_data$x, y = normal_data, mode = 'lines',
               line = list(color = 'green', width = 2),
               fill = "tozeroy", fillcolor = "rgba(0, 255, 0, 0.2)",
               name = "Dist normale ideale")

density_plot <- add_trace(density_plot, x = c(mu, mu), y = c(0, max(density_data$y)),
               mode = 'lines', line = list(color = 'red', width = 2, dash = 'dash'),
               name = "Media")

(density_plot)

```

Analizzando il diagramma di densità, si osserva che la distribuzione dei rimbalzi totali segue abbastanza fedelmente una distribuzione normale, come indicato dalla sovrapposizione delle due curve. La media, indicata dalla linea rossa, cade quasi al centro della curva di densità, suggerendo che la maggior parte delle squadre ha un numero di rimbalzi vicino alla media del campione.

### Boxplot

L'ultimo grafico è un insieme di box plot, simile al primo grafico condiviso, ma questa volta per rimbalzi offensivi e difensivi. Ogni squadra è rappresentata da due box plot adiacenti, uno per i rimbalzi offensivi (o_reb) e uno per i rimbalzi difensivi (d_reb), permettendo un confronto immediato tra le due metriche per ogni squadra.

```{r Boxplot rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

# BOX PLOT

aggregated_data <- df %>%
  select(tmID, year, o_reb, d_reb) %>%
  group_by(tmID, year) %>%
  summarize(
    o_reb = mean(o_reb, na.rm = TRUE), 
    d_reb = mean(d_reb, na.rm = TRUE),
    .groups = "drop"  # Aggiunto per evitare il raggruppamento
  )
reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(o_reb, d_reb), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")
box_plot <- plot_ly()
for (i in 2:ncol(reshaped_data)) {
    current_column_data <- reshaped_data[[i]]
    box_plot <- box_plot %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

(box_plot)

```

Il grafico mostra che c'è variabilità sia nei rimbalzi offensivi sia in quelli difensivi tra le diverse squadre. Si notano differenze nella mediana, nella variabilità e nella presenza di valori anomali (outliers), il che potrebbe indicare diverse efficacie o stili di gioco. Ad esempio, alcune squadre potrebbero avere una forte tendenza ai rimbalzi difensivi ma meno capacità nei rimbalzi offensivi, o viceversa, fornendo spunti per ulteriori indagini sulle strategie di gioco.

```{r Corrplot rimbalzi, eval=FALSE, message=FALSE, warning=FALSE, include=FALSE}

# CORRPLOT

data_subset <- df[, c("reb", "o_reb", "d_reb")]
cor_matrix <- cor(data_subset)

rownames(cor_matrix) <- colnames(data_subset)
colnames(cor_matrix) <- colnames(data_subset)

cor_data <- reshape2::melt(cor_matrix)
names(cor_data) <- c("Var1", "Var2", "Corr")

dimnames(cor_matrix) <- list(rownames(cor_matrix), colnames(cor_matrix))
data_for_plotly <- as.data.frame(as.table(cor_matrix))

cor_plot <- plot_ly(data = cor_data, 
             x = ~Var1, 
             y = ~Var2, 
             z = ~Corr, 
             type = "heatmap", 
             colors = colorRampPalette(c("#4575b4", "#91bfdb", "#e0f3f8", "#fee08b", "#d73027"))(100),
             hoverinfo = "x+y+z") %>% 
  layout(title = 'Correlation Matrix',
         xaxis = list(title = "", tickangle = 45, side = "bottom", automargin = TRUE),
         yaxis = list(title = "", automargin = TRUE),
         autosize = TRUE)

cor_values <- round(as.matrix(cor_matrix), 2)  # Round for readability
for (i in seq_len(nrow(cor_matrix))) {
  for (j in seq_len(ncol(cor_matrix))) {
    cor_plot <- cor_plot %>% add_annotations(
      x = rownames(cor_matrix)[i],
      y = colnames(cor_matrix)[j],
      text = as.character(cor_values[i, j]),
      showarrow = FALSE,
      font = list(color = ifelse(cor_values[i, j] < 0.5, "white", "black"))
    )
  }
}
(cor_plot)

```

## Test

### Test Anderson-Darling

Il test Anderson-Darling è un test statistico non parametrico, utilizzato per verificare l'ipotesi che un campione di dati provenga da una particolare distribuzione, in questo caso, la distribuzione normale. È particolarmente sensibile alle deviazioni nella coda della distribuzione.  
- **Range**: 0 a $+\infty$  
- **Interpretazione**: Valori più bassi indicano una maggiore aderenza alla distribuzione normale. Si confronta il valore di test con valori critici specifici per determinare se rifiutare l'ipotesi di normalità.
```{r, warning=FALSE}

# Questo codice esegue il test di Anderson-Darling sulla variabile 'reb' nel tuo dataset (df)
ad.test(df$reb)

```

Con un livello di significatività ($\alpha$) di 0.01 e un p-value molto
piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per
i dati della variabile df\$reb, si puo concludere che si hanno sufficienti
evidenze statistiche per respingere lipotesi nulla che i dati seguano una
distribuzione normale. Con il livello di significatività del 0.01 e
il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di
significatività, quindi si respinge lipotesi nulla. Questo suggerisce
che i dati nella variabile df\$reb non seguono una distribuzione normale
al livello di significatività del 0.01. In termini più pratici, si hanno
abbastanza evidenze statistice per concludere che la variabile df\$reb
non segue una distribuzione normale.

### Test Kolmogorov-Smirnov

Il test Kolmogorov-Smirnov (K-S) è un metodo non parametrico utilizzato per determinare se un campione di dati segue una specifica distribuzione, in questo caso, la distribuzione normale. È ampiamente impiegato per la sua generalità e la facilità di implementazione.  
- **Range**: 0 a 1  
- **Interpretazione**: Valori più bassi indicano una maggiore somiglianza alla distribuzione normale. Un valore di test significativamente grande porta al rifiuto dell'ipotesi di normalità.
```{r, warning=FALSE}

# Test di Kolmogorov-Smirnov per confrontare la distribuzione di 'reb' con una distribuzione normale
ks.test(df$reb, "pnorm")

```

Il test KS
confronta la distribuzione empirica dei dati con una distribuzione
teorica (spesso una distribuzione uniforme). In breve, il risultato
suggerisce che i nostri dati non seguono la distribuzione teorica normale
presunta, e cè un elevata probabilità che la differenza osservata sia
statisticamente significativa.

### Test Shapiro-Wilk

Il test Shapiro-Wilk è un metodo statistico non parametrico utilizzato specificatamente per testare la normalità di un campione di dati. È noto per la sua affidabilità e precisione, soprattutto in campioni di dimensioni ridotte.  
- **Range**: 0 a 1  
- **Interpretazione**: Valori più vicini a 1 suggeriscono una maggiore aderenza alla distribuzione normale. Valori significativamente bassi indicano la deviazione dalla normalità.
```{r, warning=FALSE}

# Test di Shapiro-Wilk per la normalità dei dati nella variabile 'reb' (rimbalzi)
sf.test(df$reb)

```

In sintesi, il risultato del test di Shapiro-Francia indica che i
dati nella variabile df\$reb non seguono una distribuzione normale.
Questo è supportato dal valore basso del p-value, il quale suggerisce
che la differenza tra la distribuzione dei dati e una distribuzione
normale è statisticamente significativa.

---
 
# Presentazione modello lineare

## Modello: L'importanza dei rimbalzi

Abbiamo creato un modello lineare per esplorare come i rimbalzi influenzano le vittorie in NBA. L'idea è semplice: capire se squadre che rimbalzano meglio vincono di più. Il modello analizza diversi tipi di rimbalzi (offensivi, difensivi) e come questi si traducono in successo sul campo.

## Formule

Le formule che usiamo si concentrano su diversi aspetti dei rimbalzi, come recuperare la palla dopo un tiro sbagliato o proteggere il canestro. Ogni formula ci dà un'idea di come le squadre gestiscono e sfruttano i rimbalzi durante le partite. L'obiettivo è vedere quale impatto hanno questi fattori sulle vittorie.

> $\text{Formula1} = \frac{\text{Rimbalzi offensivi in attacco}}{\text{Tiri sbagliati su azione}}$  
  
- **Formula 1: Efficienza nel Rimbalzo Offensivo**  
Questa formula calcola la percentuale di rimbalzi offensivi catturati dalla squadra in seguito ai tiri mancati. Il numeratore, "Rimbalzi offensivi in attacco", rappresenta il totale dei rimbalzi catturati dopo un tiro mancato dall'attacco. Il denominatore, "Tiri sbagliati su azione", è il numero totale di tiri non riusciti dalla squadra. Il quoziente fornisce un indice diretto della competenza di una squadra nel mantenere il possesso della palla dopo un tentativo di tiro fallito, un aspetto cruciale per generare opportunità di punteggio aggiuntive.

> $\text{Formula2} = \frac{\text{Rimbalzi difensivi in difesa presi}}{\text{Tiri sbagliati su azione degli avversari}}$  
  
- **Formula 2: Competenza nel Rimbalzo Difensivo**
Questa formula misura l'efficacia della squadra nel recuperare i rimbalzi difensivi. Il numeratore, "Rimbalzi difensivi in difesa presi", indica il totale dei rimbalzi catturati dalla squadra in difesa. Il denominatore, "Tiri sbagliati su azione degli avversari", è il numero di tiri falliti dalla squadra avversaria. Il risultato fornisce un'indicazione quantitativa della capacità di una squadra di terminare l'attacco avversario e iniziare una transizione offensiva, elemento fondamentale per il controllo del flusso di gioco.


> $\text{Formula3} = \frac{\text{Palle riprese in attacco} + 1.5 \times \text{Palle riprese in difesa}}{\text{Palle perse in attacco} + 2 \times \text{Rimbalzi subiti in difesa}}$  
  
- **Formula 3: Bilancio Rimbalzi/Palle Perse**
Questa formula presenta un rapporto complesso, dove il numeratore somma "Palle riprese in attacco" (rimbalzi offensivi) e "Palle riprese in difesa" (rimbalzi difensivi) moltiplicate per 1.5, un fattore che sottolinea l'importanza dei rimbalzi difensivi. Il denominatore combina "Palle perse in attacco" e "Rimbalzi subiti in difesa" moltiplicati per 2, indicando le occasioni perse di recupero di rimbalzi. Questa formula è progettata per valutare la gestione globale dei rimbalzi da parte di una squadra, enfatizzando il valore della difesa rispetto all'attacco.

> $\text{Formula4} = (\text{Palle riprese in attacco - Palle perse in attacco}) + 1.5*(\text{Palle riprese in difesa - Palle perse in difesa})$  
  
- **Formula 4: Efficienza Rimbalzi Netta**
Questa formula calcola la differenza netta tra i rimbalzi catturati e quelli persi, sia in attacco che in difesa, applicando un coefficiente di 1.5 ai rimbalzi difensivi. Il calcolo evidenzia il saldo netto di rimbalzi catturati contro quelli persi, con un'enfasi aggiuntiva sulla componente difensiva. Questo indice fornisce una misura diretta dell'efficacia complessiva di una squadra nel dominare il gioco sui rimbalzi.

> $\text{Formula5} = \frac{(\frac{\text{Rimbalzi subiti in difesa}}{\text{Palle perse in difesa}})}{(\frac{\text{Rimbalzi subiti in attacco}}{\text{Palle perse in attacco}})}$  
  
- **Formula 5: Rapporto Rimbalzi/Palle Perse**
Questa formula offre un confronto tra l'effetto dei rimbalzi sulla perdita di palla in attacco e in difesa. Il numeratore rappresenta il rapporto tra "Rimbalzi subiti in difesa" e "Palle perse in difesa", mentre il denominatore fa lo stesso per l'attacco. Questo rapporto mette in luce l'impatto dei rimbalzi sulle opportunità perse, sia in termini di difesa che di attacco.

> $\text{Formula6} = (\text{Rimbalzi ottenuti in attacco} + \text{Rimbalzi ottenuti in difesa}) - (\text{Rimbalzi subiti in difesa} - \text{Rimbalzi subiti in attacco})^2$  

- **Formula 6: Bilancio Complessivo Rimbalzi**  
Questa formula calcola un indice che tiene conto sia dei rimbalzi ottenuti in attacco (Rimbalzi ottenuti in attacco) e in difesa (Rimbalzi ottenuti in difesa), sia dei rimbalzi subiti in difesa (Rimbalzi subiti in difesa) e in attacco (Rimbalzi subiti in attacco), elevando al quadrato la differenza tra i rimbalzi subiti. Offre una visione complessiva dell'efficacia della squadra nel controllo dei rimbalzi sotto entrambi i canestri.

> $\text{Formula7} = (\text{Efficienza nel Rimbalzo Offensivo} + \text{Competenza nel Rimbalzo Difensivo})^2$  

- **Formula 7: Sinergia Tra Rimbalzi Offensivi e Difensivi**  
Combina le misurazioni dell'efficienza nei rimbalzi offensivi (Efficienza nel Rimbalzo Offensivo) e difensivi (Competenza nel Rimbalzo Difensivo), elevandone la somma al quadrato. Questo calcolo evidenzia l'importanza della sinergia tra le due componenti del gioco sui rimbalzi.

> $\text{Formula8} = \frac{\text{Rimbalzi ottenuti in attacco}}{\text{Totale rimbalzi in attacco}}$  

- **Formula 8: Proporzione Rimbalzi Offensivi**  
Questa formula determina la percentuale dei rimbalzi offensivi (Rimbalzi ottenuti in attacco) sul totale dei rimbalzi in attacco (Totale rimbalzi in attacco). Fornisce un'indicazione diretta dell'efficienza di una squadra nel recuperare la palla dopo i tiri falliti in attacco.

> $\text{Formula9} = \left(\frac{\text{Rimbalzi ottenuti in attacco}}{\text{Rimbalzi subiti in attacco}}\right)^2$  

- **Formula 9: Predominanza dei Rimbalzi Offensivi**  
Calcola il rapporto tra i rimbalzi offensivi ottenuti (Rimbalzi ottenuti in attacco) e i rimbalzi subiti in attacco (Rimbalzi subiti in attacco), elevato al quadrato. Questa formula enfatizza la capacità di una squadra di dominare sotto il proprio canestro in fase offensiva.

> $\text{Formula10} = \left(\frac{\text{Rimbalzi ottenuti in difesa}}{\text{Rimbalzi subiti in difesa}}\right)^2$  

- **Formula 10: Predominanza dei Rimbalzi Difensivi**  
Analoga alla Formula 9, ma applicata al contesto difensivo. Misura il rapporto tra i rimbalzi difensivi ottenuti (Rimbalzi ottenuti in difesa) e i rimbalzi subiti in difesa (Rimbalzi subiti in difesa), elevato al quadrato. Sottolinea l'efficacia di una squadra nel proteggere il proprio canestro in fase difensiva.

## Modello lineare sul dataframe train

### Legenda significato acronimi:

- o_oreb: Rimbalzi ottenuti in attacco 
- o_dreb: Rimbalzi subiti in attacco 
- o_reb: Totale rimbalzi in attacco 
- d_oreb: Rimbalzi subiti in difesa 
- d_dreb: Rimbalzi ottenuti in difesa 
- d_reb: Totale rimbalzi in difesa 

```{r Formule, warning = FALSE}

# Definizione di nuove variabili
df$f1 <- (df$o_oreb) / (df$o_fga - df$o_fgm)
df$f2 <- (df$d_dreb) / (df$d_fga - df$d_fgm)
df$f3 <- (df$o_oreb + 1.5 * df$d_dreb) / (df$o_dreb + 2 * df$d_oreb)
df$f4 <- (df$o_oreb - df$o_dreb) + 1.5 * (df$d_dreb - df$d_oreb)
df$f5 <- (df$d_oreb / df$d_to) / (df$o_dreb / df$o_to)
df$f6 <- (df$o_oreb + df$d_dreb) - (df$d_oreb - df$o_dreb)^2
df$f7 <- (df$f1 + df$f2)^2
df$f8 <- (df$o_oreb) / (df$o_reb)
df$f9 <- ((df$o_oreb) / (df$o_dreb))^2
df$f10 <- ((df$d_dreb) / (df$d_oreb))^2

```

### Divisione dataframe in train e test

Si esegue la divisione del dataframe df in un set di addestramento (train) e un set di test (test). La divisione è effettuata campionando casualmente il 70% delle righe per l'addestramento e utilizzando il restante 30% per il test. Successivamente, viene creato il modello lineare utilizzando le variabili predittive sopra create per prevedere la variabile di risposta won nel set di addestramento.
```{r Divisione tra train e test}

# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df = subset(df, select = c("f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "won", "divID", "confID"))

train  <- df[sample, ]
test   <- df[!sample, ]

#ATTENZIONE: facendo il train sul valore delle variabili, questo significa che sono esse ad essere i nostri dati, non i rimbalzi in se.

# Creazione del modello lineare
linMod <- lm(won ~ f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10, data = train)
summary(linMod)

```

# Modello lineare normalizzato sul dataframe train

### Normalizzazione

La normalizzazione dei dati è una pratica fondamentale nell'elaborazione di modelli statistici, specialmente nei modelli lineari. Questo processo è volto a standardizzare la scala delle variabili, rendendo più agevole il confronto tra di esse e migliorando l'efficienza dell'algoritmo di regressione. In particolare, la normalizzazione è cruciale quando le variabili hanno scale molto diverse, poiché ciò potrebbe influenzare negativamente la precisione del modello.

Nel codice R seguente, abbiamo normalizzato le variabili del nostro dataframe 'df', utilizzando la funzione `scale`. Questo assicura che ciascuna variabile contribuisca in modo equo al modello, permettendo una più accurata interpretazione dei coefficienti della regressione lineare.

```{r, warning = FALSE}

# Normalizziamo le covariate
train$f1_z <- scale(train$f1)
train$f2_z <- scale(train$f2)
train$f3_z <- scale(train$f3)
train$f4_z <- scale(train$f4)
train$f5_z <- scale(train$f5)
train$f6_z <- scale(train$f6)
train$f7_z <- scale(train$f7)
train$f8_z <- scale(train$f8)
train$f9_z <- scale(train$f9)
train$f10_z <- scale(train$f10)

# Normalizzo i dati di test
test$f1_z <- scale(test$f1)
test$f2_z <- scale(test$f2)
test$f3_z <- scale(test$f3)
test$f4_z <- scale(test$f4)
test$f5_z <- scale(test$f5)
test$f6_z <- scale(test$f6)
test$f7_z <- scale(test$f7)
test$f8_z <- scale(test$f8)
test$f9_z <- scale(test$f9)
test$f10_z <- scale(test$f10)

linModNormalized <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train)

```

### Grafici

I quattro grafici costituiscono un'esplorazione diagnostica del modello di regressione lineare applicato per analizzare la correlazione tra i rimbalzi (sia offensivi che difensivi) e le vittorie di una squadra di basket.

1. Il primo grafico, denominato "Residui Standardizzati vs Valori Adattati", mette in luce la relazione tra i residui del modello e i valori predetti. La distribuzione casuale dei punti attorno all'asse orizzontale è un indicatore della qualità dell'adattamento del modello. La linea rossa tratteggiata offre un riferimento per identificare eventuali pattern sistematici nei residui che potrebbero suggerire non linearità, eteroscedasticità o punti influenti.

2. Il secondo grafico è un "Q-Q Plot dei Residui Standardizzati", che confronta la distribuzione dei residui del modello con quella che ci si aspetterebbe da una distribuzione normale. Questo tipo di grafico è cruciale per valutare l'assunzione della normalità dei residui, un presupposto fondamentale della regressione lineare. I punti seguono la linea diagonale rappresentativa della distribuzione normale teorica, e le deviazioni da questa linea possono indicare deviazioni dalla normalità.

3. Il terzo grafico, "Scale-Location" (o Spread-Location Plot), è utilizzato per verificare l'assunzione di omoscedasticità, ovvero la costanza della varianza dei residui attraverso il range dei valori predetti dal modello. Una dispersione uniforme dei punti lungo l'asse orizzontale suggerisce che la varianza dei residui è costante. Variazioni significative da questa uniformità possono indicare eteroscedasticità, che è una violazione di un'altra assunzione fondamentale della regressione lineare.

4. Il quarto grafico presenta il "Q-Q Plot dei Residui" con la distanza di Cook, che è una misura dell'influenza di ogni osservazione sui parametri stimati del modello. Valori elevati della distanza di Cook possono indicare punti con un'influenza sproporzionata, che potrebbero essere considerati outlier o punti di leva che meritano un'ulteriore indagine.

```{r echo=FALSE, message=FALSE, warning=FALSE}

# Imposta il layout della pagina
par(mfrow = c(2, 2))

# Grafico dei residui standardizzati
plot(linModNormalized, which = 1, col = "skyblue", pch = 16, main = "Residui Standardizzati")
abline(h = 0, col = "red", lty = 2)  # Aggiunta una linea orizzontale a zero nel grafico dei residui standardizzati

# Grafico dei livelli
plot(linModNormalized, which = 2, col = "lightgreen", pch = 16, main = "Grafico dei Livelli")

# Grafico della distribuzione dei residui
plot(linModNormalized, which = 3, col = "pink", pch = 16, main = "Distribuzione dei Residui")

# Grafico di Q-Q plot dei residui
plot(linModNormalized, which = 4, col = "orange", pch = 16, main = "Q-Q Plot dei Residui")

# Ripristina il layout predefinito
par(mfrow = c(1, 1))

```

Ecco cosa possiamo dedurre da questi grafici:

1. L'analisi del primo grafico rivela una disposizione abbastanza casuale dei residui attorno allo zero, suggerendo che il modello non presenta errori sistematici nella predizione. Tuttavia, la presenza di alcuni punti distanti dalla massa centrale potrebbe indicare la presenza di outliers o di punti con pattern di varianza non catturati dal modello.

2. Il secondo grafico, il Q-Q plot, mostra una generale aderenza alla linea teorica, con alcune deviazioni evidenti nelle code. Queste deviazioni possono suggerire la presenza di outliers o che la distribuzione dei residui è leggermente asimmetrica, questioni che richiedono un'attenta valutazione.

3. Nel terzo grafico, la dispersione non uniforme dei punti suggerisce che la varianza dei residui non è costante per tutti i valori predetti, un fenomeno noto come eteroscedasticità. Questo aspetto potrebbe essere mitigato attraverso trasformazioni dei dati o l'utilizzo di modelli più complessi che tengono conto di varianze eterogenee.

4. Il quarto grafico mostra che la maggior parte delle osservazioni ha una distanza di Cook bassa, il che implica un impatto minimo sulla stima dei parametri del modello. Tuttavia, ci sono alcuni punti che superano la soglia suggerita, indicati con i numeri di osservazione, che potrebbero essere esaminati più a fondo per comprendere la loro potenziale influenza sulle previsioni del modello.

---

# Test modello lineare

Il processo di test di un modello lineare è cruciale per assicurare la sua affidabilità e accuratezza. Questa fase prevede la valutazione di vari aspetti del modello, come l'adattamento dei dati, la normalità dei residui, l'omoschedasticità e la multicollinearità. Ognuno di questi test fornisce un'indicazione su come il modello si adatta ai dati e su eventuali problemi che potrebbero influenzarne le prestazioni.

### Summary
Per una comprensione immediata del modello, è utile visualizzare il riepilogo tramite `summary(linModNormalized)`. Questo fornisce dettagli sui coefficienti, la significatività statistica e altre metriche chiave.
```{r}

summary (linModNormalized)

```

### R-quadrato
Il test R-quadrato misura la proporzione della varianza totale della variabile dipendente che viene spiegata dal modello di regressione. Un R-quadrato elevato indica che una grande parte della varianza nella variabile dipendente può essere spiegata dalle variabili indipendenti nel modello.  
- **Range:** 0 a 1  
- **Interpretazione:** 0 indica nessuna spiegazione della varianza da parte del modello. 1 indica una spiegazione completa della varianza da parte del modello.
```{r}

summary_linModNormalized <- summary(linModNormalized)
r_squared <- summary_linModNormalized$r.squared
cat("R-quadro:", r_squared, "\n")

```

### R-quadrato Adattato
Il R-quadrato adattato modifica il R-quadrato per tenere conto del numero di predittori nel modello. È più affidabile per i modelli con molteplici variabili indipendenti, poiché penalizza la complessità aggiuntiva, fornendo una misura più realistica della bontà di adattamento.  
- **Range:** Può essere negativo, ma generalmente 0 a 1  
- **Interpretazione:** Valori più vicini a 1 indicano una migliore spiegazione della varianza, considerando il numero di predittori.
```{r}

n <- length(train$o_reb)
k <- length(linModNormalized$coefficients) - 1
adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - k - 1))
cat("R-quadro adattato:", adjusted_r_squared, "\n")

```

### Test Shapiro
Il test di Shapiro-Wilk sui residui è utilizzato per valutare la normalità dei residui in un modello di regressione lineare. La normalità dei residui è un'assunzione critica in molti test statistici. Se i residui non seguono una distribuzione normale, le inferenze sulle stime dei parametri potrebbero essere invalide.  
- **Range:** 0 a 1  
- **Interpretazione:** Valori più vicini a 1 suggeriscono una maggiore probabilità che i residui seguano una distribuzione normale.
```{r}

shapiro.test(residuals(linModNormalized))

```

### Test di omoschedasticità
Il test di Breusch-Pagan verifica l'assunzione di omoschedasticità (varianza costante) dei residui in un modello di regressione. La presenza di eteroschedasticità (varianza non costante) nei residui può portare a stime inefficaci e test statistici non affidabili.  
- **Range:** 0 a $+\infty$  
- **Interpretazione:** Valori più alti indicano una maggiore probabilità di eteroschedasticità. Si confronta il valore del test con un valore critico (ad es., da una distribuzione chi-quadrato) per determinare la significatività.
```{r}

bptest(linModNormalized)

```

### Test di multicollinearità
Il test di multicollinearità verifica se esiste una correlazione elevata tra le variabili indipendenti in un modello di regressione lineare. La multicollinearità può causare problemi nella stima dei coefficienti del modello, rendendo difficili l'interpretazione e la significatività statistica delle variabili indipendenti. Strumenti comuni per rilevarla includono il fattore di inflazione della varianza (VIF) e l'indice di tolleranza.  
- **Range del VIF:** 1 a $+\infty$  
- **Interpretazione:** 1 indica assenza di multicollinearità. Valori superiori a 5 o 10 sono spesso considerati indicatori di multicollinearità significativa.
```{r}

car::vif(linModNormalized)

```

---

# Rimozione outliers e LASSO

Nel perfezionare i modelli statistici, la gestione degli outliers è cruciale. Gli outliers possono distorcere significativamente i risultati e portare a stime dei parametri poco affidabili. La loro rimozione o adeguato trattamento è fondamentale per aumentare la precisione del modello. Tale processo non solo migliora la validità delle inferenze statistiche ma anche la capacità del modello di generalizzare a dati non osservati.

Parallelamente, tecniche di regolarizzazione come LASSO (Least Absolute Shrinkage and Selection Operator) si rivelano preziose. LASSO penalizza la grandezza assoluta dei coefficienti di regressione, con l'effetto diretto di ridurre il sovradimensionamento (overfitting) e favorire la selezione delle variabili. Attraverso la contrazione dei coefficienti verso zero, LASSO contribuisce a escludere predittori non informativi, affinando il modello sui fattori più rilevanti.

Incorporando LASSO, possiamo quindi affrontare due problematiche fondamentali: la riduzione della complessità del modello e l'incremento dell'interpretabilità dei dati. La rimozione degli outliers, combinata con l'approccio selettivo di LASSO, è una strategia potente per migliorare la robustezza e l'efficacia del nostro modello lineare, ottimizzando la correlazione tra i rimbalzi e le vittorie.

### Identificazione degli Outliers

La prima fase nel perfezionamento del modello implica l'identificazione accurata degli outliers. Per questa operazione, adottiamo un grafico di influenza, uno strumento grafico che mette in evidenza le osservazioni che esercitano un'influenza eccessiva sulla stima dei parametri.

Questo tipo di grafico è utilizzato per valutare l'effetto che ogni osservazione ha sulla stima dei coefficienti del modello. Le dimensioni dei cerchi sono proporzionali alla distanza di Cook, una misura che combina la deviazione dei residui standardizzati (sull'asse verticale) e il leverage o hat-values (sull'asse orizzontale). Un valore di leverage alto indica che l'osservazione ha un grande impatto sulla forma del modello, mentre residui standardizzati grandi indicano deviazioni dai valori predetti. La combinazione di entrambi può segnalare punti potenzialmente influenti o outlier.

```{r Grafico modello attuale, echo=FALSE, message=FALSE, warning=FALSE}

# Influence plot il modello lineare normalizzato linModNormalized
influencePlot(linModNormalized, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))
title(main = "Influence Plot - Modello 1", col.main = "blue", font.main = 4)

```

Esaminando il grafico, si notano alcune osservazioni con cerchi di dimensioni maggiori, in particolare le osservazioni 957, 822 e 769, che hanno una distanza di Cook relativamente alta e quindi esercitano un'influenza maggiore sul modello rispetto ad altre osservazioni. Queste osservazioni dovrebbero essere esaminate attentamente, poiché la loro rimozione o la correzione dei dati sottostanti potrebbe significativamente alterare i coefficienti stimati nel modello di regressione.

Valutiamo i residui rispetto ai valori predetti e definiamo come outliers quegli osservazioni la cui deviazione dalla media supera un limite prefissato, che in questo contesto è stabilito a due deviazioni standard.

```{r Trovare outliers}

# Calcola i residui dal modello di regressione lineare normalizzato
residui <- residuals(linModNormalized)

# Definisci una soglia per gli outlier
soglia_outlier <- 2
outliers <- which(abs(residui) > soglia_outlier*sd(residui))

# Identifica gli outlier basati sulla soglia definita
outliers <- which(abs(residui) > soglia_outlier * sd(residui))
outliers

```

### Rimozione degli Outliers

Identificati gli outliers, procediamo con la loro esclusione dal dataset utilizzato per l'addestramento del modello. Tale rimozione mira a migliorare la robustezza e la generalizzabilità del modello.

```{r Rimozione outliers, echo=TRUE, message=FALSE, warning=FALSE}

# Rimuovi gli outliers e ricrea il modello lineare normalizzato
if (length(outliers) != 0) {
  train_1 <- train[-outliers,]
} else {
  train_1 <- train  # questo è il caso in cui non siano presenti outliers
}

# ATTENZIONE: facendo il train sul valore delle variabili, questo significa 
# che sono esse ad essere i nostri dati, non i rimbalzi in sé.

```

### Confronto dei Modelli Prima e Dopo la Rimozione degli Outliers

Il confronto tra i modelli prima e dopo l'eliminazione degli outliers è vitale per valutare l'efficacia di questo intervento. Analizziamo i riepiloghi statistici del modello per discernere le variazioni nelle performance.

### Prima della Rimozione degli Outliers:
  Si esamina il sommario del modello originale per stabilire un benchmark delle prestazioni.

```{r Grafici outliers, echo=FALSE, message=FALSE, warning=FALSE}

# Stampa i summary
summary(linModNormalized)

```

### Dopo la Rimozione degli Outliers:
  Una volta esclusi gli outliers, ricostruiamo il modello e esaminiamo nuovamente il grafico di influenza per osservare come l'eliminazione abbia modificato l'impatto delle osservazioni sui parametri stimati.

```{r, echo=FALSE, message=FALSE, warning=FALSE}

linModNormalized_1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train_1)

# Stampa i summary
summary(linModNormalized_1)

```

### Grafico di Influenza:

La metodologia è identica a quella del primo grafico, ma le osservazioni qui rappresentate possono essere differenti a causa delle variazioni nei dati o nei coefficienti inclusi in questo secondo modello. Di nuovo, i cerchi più grandi rappresentano una maggiore distanza di Cook e quindi una maggiore influenza sull'adattamento del modello.

```{r, echo = FALSE, warning=FALSE}

# Influence plot per il modello lineare normalizzato linModNormalized_1
influencePlot(linModNormalized_1, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))

# Aggiunta un titolo sopra al grafico
title(main = "Influence Plot - Modello 2", col.main = "blue", font.main = 4)

```

In questo grafico, l'osservazione 769 si distingue nuovamente come la più influente, indicando che questo punto dati è particolarmente critico per entrambi i modelli di regressione. Altre osservazioni, come le 693 e 1206, mostrano anche un'alta influenza ma in misura minore rispetto al modello addestrato con gli outliers.

### Visualizzazione Residui e Leverage
Questo blocco di codice utilizza la funzione `ols_plot_resid_lev` per visualizzare la relazione tra i residui e il leverage per entrambi i modelli lineari. I due grafici rappresentano una comparativa diagnostica dei residui standardizzati rispetto al leverage per due versioni di un modello di regressione lineare: il primo prima della rimozione degli outliers e il secondo dopo tale processo. Questi grafici sono strumenti essenziali per valutare la presenza e l'impatto di outliers e punti ad alto leverage sulla stima dei parametri del modello. La soglia di leverage è indicata da una linea verticale rossa, e i punti sono colorati diversamente per indicare se sono normali, outliers, punti ad alto leverage, o una combinazione di queste caratteristiche.

```{r, warning=FALSE, echo = FALSE}

# Visualizza il grafico dei residui rispetto ai livelli per il modello lineare normalizzato linModNormalized
ols_plot_resid_lev(linModNormalized)

# Visualizza il grafico dei residui rispetto ai livelli per il modello lineare normalizzato linModNormalized_1
ols_plot_resid_lev(linModNormalized_1)

```

Esaminando i due grafici, è evidente che il secondo modello presenta meno osservazioni con alto leverage, come dimostrato dalla riduzione dei punti che superano la soglia di leverage. Ciò suggerisce che la rimozione degli outliers ha avuto l'effetto desiderato di ridurre l'influenza di osservazioni atipiche e potenzialmente distorsive sul modello di regressione.

### Risultati

Entrambi i modelli mostrano prestazioni simili, spiegando circa l'84% della varianza nella variabile dipendente "won". Tuttavia, la rimozione degli outliers ha leggermente migliorato i risultati.

# Implementazione del Modello LASSO per l'Ottimizzazione della Regressione

Il modello LASSO (Least Absolute Shrinkage and Selection Operator) viene utilizzato per migliorare la qualità predittiva e l'interpretabilità di modelli di regressione statistica attraverso la selezione di variabili e la regolarizzazione. Il suo impiego è particolarmente vantaggioso per affrontare problemi di overfitting e per identificare i predittori più rilevanti, consentendo al modello di mantenere robustezza e precisione anche su dati non inclusi nella fase di addestramento.

### 1. Preparazione e Valutazione del Modello di Regressione LASSO

Per implementare il modello LASSO, seguiamo un processo meticoloso che inizia con la definizione chiara della variabile risposta e la selezione accurata delle variabili predittive. Procediamo quindi con una cross-validation k-fold, un metodo rigoroso per determinare il valore ottimale del parametro di regolarizzazione lambda, che equilibra complessità e capacità predittiva del modello.

```{r, warning = FALSE}
# Impostazione del contesto per il metodo di regressione LASSO con cross-validation per selezionare il valore lambda più efficace.

# Definizione della variabile risposta
y <- train_1$won

# Creazione della matrice dei predittori, selezionando le features di interesse
x <- data.matrix(train_1[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])

# Applicazione della cross-validation k-fold per identificare il lambda ottimale
cv_model <- cv.glmnet(x, y, alpha = 1)

# Estrazione del valore di lambda che minimizza il Mean Squared Error sul test set
best_lambda <- cv_model$lambda.min

```

Questo è il grafico di tutti i valori possibili di lambda.

```{r, echo = FALSE, warning=FALSE}
# Visualizzazione del grafico MSE per diversi valori di lambda
plot(cv_model, xvar="lambda", main="", xlab="log(Lambda)", ylab="Mean Squared Error", col="blue", lwd=2)

# Personalizzazione del titolo del grafico con formattazione LaTeX
title(main=expression(bold(italic("Validazione Incrociata per la Scelta di Lambda nel Modello LASSO"))), line = 3)
```

```{r, echo = FALSE}
print(paste("Lambda migliore:", round(best_lambda, digits = 4)))
```

### Allenamento modello LASSO

```{r, warning=FALSE}
# Allenamento del modello LASSO con il parametro lambda identificato
cv_model <- cv.glmnet(x, y)
```


Dopo aver individuato il valore di lambda che minimizza l'errore quadratico medio, procediamo all'addestramento del modello LASSO. Esaminiamo i coefficienti risultanti per valutare l'importanza assegnata a ciascuna variabile predittiva, offrendo così una visione quantitativa dell'impatto di ogni feature sulle vittorie della squadra.

```{r, warning = FALSE}

# Fittiamo il modello con il miglior lambda (penalizzazione)
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

# Stampa i coefficienti del modello LASSO
coef(best_model)

# Stampa il summary del modello lineare normalizzato precedente per confronto
summary(linModNormalized_1)

```

### 2. Valutazione Comparativa delle Previsioni: LASSO contro Modello Lineare

Il confronto delle previsioni generate dal modello LASSO e da un modello lineare classico ci permette di valutare l'efficacia di ciascun approccio nel contesto specifico dei nostri dati. Utilizziamo i dati di test per misurare la precisione predittiva e confrontiamo le metriche chiave come l'errore quadratico medio (RMSE) e le performance di classificazione.

```{r, warning = FALSE}

# Questo codice esegue stime usando un modello Lasso e un modello lineare (LM) su un set di dati di test e ne valuta le prestazioni utilizzando l'errore quadratico medio (RMSE) e le metriche    di classificazione binaria, ad esempio matrice di confusione, accuratezza, precisione, sensibilità, punteggio F e specificità.

# Predizioni utilizzando il modello Lasso
new <- data.matrix(test[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])
prevLasso <- predict(best_model, s = best_lambda, newx = new)

# Predizioni utilizzando il modello LM (Linear Model)
new <- subset(test, select = c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z"))
prevLM <- predict(linModNormalized_1, newdata = new)

```

Confrontando i risultati ottenuti dai due modelli, possiamo apprezzare l'efficacia del LASSO nell'affrontare la complessità e il potenziale overfitting. La selezione di variabili intrinseca al LASSO si rivela particolarmente utile quando il numero di predittori è elevato rispetto al numero di osservazioni. Questo approccio non solo semplifica il modello, riducendo i predittori ai soli fattori significativi, ma migliora anche la chiarezza interpretativa dei risultati, un aspetto fondamentale nella comunicazione delle scoperte a un pubblico più ampio.

In sintesi, il modello LASSO offre un equilibrio ottimale tra complessità del modello e capacità predittiva, rendendolo uno strumento prezioso nella nostra analisi statistica.

### 3. Valutazione delle Prestazioni del Modello
Confrontiamo le prestazioni di entrambi i modelli (LASSO e lineare) attraverso diverse metriche.

- Calcolo del RMS (Root Mean Square)  
Questi blocchi di codice calcolano il RMS, una misura dell'errore di previsione, per il modello LASSO e il modello lineare (LM). Il RMS fornisce una stima dell'errore quadratico medio tra i valori previsti e i valori reali.
```{r}

# Calcolo dell'Errore Quadratico Medio (RMSE) per il modello Lasso
rmsLasso <- sqrt(mean((test$won - prevLasso)^2))

# Calcolo dell'Errore Quadratico Medio (RMSE) per il modello LM (Linear Model)
rmsLM <- sqrt(mean((test$won - prevLM)^2))

```

- Previsioni Binarie e Matrice di Confusione  
Convertiamo le previsioni del modello LASSO in valori binari (0 o 1) e generiamo una matrice di confusione per confrontare le previsioni con i valori reali. Questo passaggio è utile per valutare la classificazione effettuata dal modello.

```{r}

# Classificazione binaria utilizzando una soglia (0.5) per le predizioni del modello Lasso
prev <- ifelse(prevLasso > 0.5, "1", "0")
prev <- as.factor(prev)

# Matrice di Confusione per le predizioni del modello Lasso
confMatrix <- table(prev, test$won)

```

### Calcolo delle Metriche di Valutazione  
Calcoliamo diverse metriche di valutazione come l'accuratezza (accuracy), la precisione (precision), la sensibilità (sensitivity), l'F-score e la specificità (specificity). Queste metriche forniscono una valutazione complessiva dell'efficacia del modello.

Ecco come interpretarle:

- **Accuracy** (Accuratezza):
  - **Significato**: La proporzione di previsioni corrette (sia positive che negative) rispetto al totale delle previsioni.
  - **Interpretazione**: Un valore elevato indica che il modello è generalmente accurato nel classificare sia le istanze positive che quelle negative. Tuttavia, in contesti con classi sbilanciate, una alta accuracy può essere fuorviante.
- **Precision** (Precisione):
  - **Significato**: La proporzione di previsioni positive corrette rispetto al totale delle previsioni positive fatte dal modello.
  - **Interpretazione**: Misura la qualità delle previsioni positive del modello. Una alta precisione indica che una grande percentuale delle previsioni positive del modello è effettivamente corretta.
- **Sensitivity** (Sensibilità) o Recall:
  - **Significato**: La proporzione di veri positivi rispetto al totale delle istanze effettivamente positive.
  - **Interpretazione**: Indica quanto bene il modello è in grado di identificare le istanze positive. Un valore alto significa che il modello cattura bene la maggior parte delle istanze positive.
- **F-score**:
  - **Significato**: Una media armonica di precision e sensitivity. 
  - **Interpretazione**: Combina la precisione e la sensibilità in un singolo numero. È utile quando si desidera un equilibrio tra precisione e sensibilità, specialmente in contesti con distribuzioni di classe disuguali.
- **Specificity** (Specificità):
  - **Significato**: La proporzione di veri negativi rispetto al totale delle istanze effettivamente negative.
  - **Interpretazione**: Misura quanto bene il modello è in grado di identificare le istanze negative. Una alta specificità indica che il modello è efficace nel riconoscere le istanze non positive.
- **RMSE** (Root Mean Square Error):
  - **Significato**: La radice quadrata della media degli errori al quadrato.
  - **Interpretazione**: Fornisce una misura della differenza tra i valori previsti dal modello e i valori osservati. A differenza delle altre metriche, il RMSE è sensibile agli outliers. Un valore basso di RMSE indica una maggiore precisione del modello nelle previsioni.
```{r}

# Metriche di Performance
accuracy <- sum(confMatrix[1], confMatrix[4]) / sum(confMatrix[1:4])
precision <- confMatrix[4] / sum(confMatrix[4], confMatrix[2])
sensitivity <- confMatrix[4] / sum(confMatrix[4], confMatrix[3])
fscore <- (2 * (sensitivity * precision)) / (sensitivity + precision)
specificity <- confMatrix[1] / sum(confMatrix[1], confMatrix[2])

```

```{r, echo = FALSE}

# Visualizza i Risultati
print(paste("Accuratezza:", round(accuracy, digits = 4)))
print(paste("Precisione:", round(precision, digits = 4)))
print(paste("Sensibilità:", round(sensitivity, digits = 4)))
print(paste("F-Score:", round(fscore, digits = 4)))
print(paste("Specificità:", round(specificity, digits = 4)))

# Confronto tra RMS
print(paste("RMS Lasso:", round(rmsLasso, digits = 4)))
print(paste("RMS Modello Lineare:", round(rmsLM, digits = 4)))

```
---

# Analisi della Varianza (ANOVA) per Valutazione di Fattori Categorici

L'analisi della varianza (ANOVA) è un metodo statistico utilizzato per testare le differenze tra le medie di diverse categorie e può essere particolarmente utile per valutare l'impatto di variabili categoriche su una variabile di risposta continua. In questo segmento del report, eseguiamo il test ANOVA per determinare l'efficacia di due variabili categoriche, 'confID' e 'divID', come predittori delle vittorie.

### Analisi dell'Effetto della Variabile 'confID'
Per iniziare, esploriamo l'influenza della variabile 'confID', che rappresenta la conferenza a cui appartiene una squadra, sulla variabile dipendente 'won', che indica il numero di vittorie.

```{r}
# Esecuzione del test ANOVA per esaminare l'impatto della variabile 'confID'
resp_conf <- anova(lm(won ~ confID, data = train_1))

# Stampa dei risultati con interpretazione condizionale
if (resp_conf["confID", "Pr(>F)"] < 0.05) {
  print("L'ipotesi nulla è respinta: la variabile 'confID' ha un effetto significativo sulle vittorie.")
} else {
  print("L'ipotesi nulla è accettata: non si rileva un effetto significativo della variabile 'confID' sulle vittorie.")
}

```

### Esame dell'Effetto della Variabile 'divID'
Successivamente, esaminiamo il potenziale impatto della variabile 'divID', che designa la divisione di una squadra, sempre sulla variabile 'won'.

```{r}

# Esecuzione del test ANOVA per valutare l'impatto della variabile 'divID'
resp_div <- anova(lm(won ~ divID, data = train_1))

# Decisione basata sui risultati del test e impostazione della variabile logica
if (resp_div["divID", "Pr(>F)"] < 0.05) {
  print("L'ipotesi nulla è respinta: la variabile 'divID' ha un effetto significativo sulle vittorie.")
  div <- TRUE
} else {
  print("L'ipotesi nulla è accettata: non emerge un effetto significativo della variabile 'divID' sulle vittorie.")
  div <- FALSE
}

```

# Analisi degli Effetti di Interazione

Nella modellizzazione statistica, gli effetti di interazione tra variabili possono rivelare dinamiche complesse e influenze reciproche che non sono apprezzabili quando le variabili sono considerate isolatamente. Questa sezione è dedicata alla costruzione di un modello lineare che incorpora tali effetti di interazione, permettendo di comprendere meglio come le combinazioni di fattori influenzino il numero di vittorie.

### Costruzione del Modello con Effetti di Interazione
La decisione di includere gli effetti di interazione nel modello dipende dall'analisi preliminare svolta sulla variabile `div`. Se `div` si rivela significativa, la includeremo nel modello; in caso contrario, la escluderemo.

```{r}

# Verifica del valore di 'div' per costruire il modello appropriato
if (div) {
  linModNormalized_2 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + divID + f1_z:f2_z + f4_z:divID, data = train_1)
} else {
  linModNormalized_2 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + f1_z:f2_z + f4_z:divID, data = train_1)
}

# Estrazione del riassunto del modello
riassunto <- summary(linModNormalized_2)

```

### Selezione delle Interazioni Significative
Una volta costruito il modello, procediamo all'identificazione delle interazioni significative. Utilizziamo i p-value per determinare quali effetti di interazione meritano di essere inclusi nel modello. Nel caso di questa analisi abbiamo verificato la significativita' delle interazioni 'f4_z:divID' e 'f1_z:f2_z', in quanto vogliamo analizzare se l'efficienza netta dei rimbalzi (Formula 4) ha un' interazione con la divisione, e se l'efficienza nel rimbalzo offensivo (Formula 1) ha un' interazione con la capacita' della squadra nel recuperare rimbalzi difensivi (Formula 2).

```{r}

# Estrazione dei nomi delle righe dal riassunto del modello
nomi_righe <- rownames(riassunto$coefficients)

# Nomi delle righe da escludere
nomi_da_escludere <- c("(Intercept)", "f1_z:f2_z", "f4_z:divIDCD", "f4_z:divIDMW", "f4_z:divIDNW", "f4_z:divIDPC", "f4_z:divIDSE", "f4_z:divIDSW", "divIDCD", "divIDMW", "divIDNW", "divIDPC", "divIDSE", "divIDSW")

# Creazione di un vettore con i nomi delle righe da utilizzare
nomi_righe_da_utilizzare <- setdiff(nomi_righe, nomi_da_escludere)

# divID' viene aggiunto a modello solo se e' stata riscontrata influenza significativa durante il test anova, ma non     significa che sara significativo anche nel nuovo modello.
if ("divIDCD" %in% nomi_righe) {
  nomi_righe_da_utilizzare <- append(nomi_righe_da_utilizzare, c("divID"))
}

# Indici di inizio e fine per le p-values della variabile 'divID'
div_indice_inizio <- which(rownames(riassunto$coefficients) == "f4_z:divIDCD")
div_indice_fine <- which(rownames(riassunto$coefficients) == "f4_z:divIDSW")

# Estrazione delle p-values della variabile 'divID'
div_p_values <- riassunto$coefficients[div_indice_inizio:div_indice_fine, "Pr(>|t|)"]

# Aggiunta di 'f4_z:divID' se la media delle p-values è inferiore a 0.05
if (mean(div_p_values) < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f4_z:divID"))
}

# Aggiunta di 'f1_z:f2_z' se la sua p-value è inferiore a 0.05
if (riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f1_z:f2_z"))
}

# Se nessuna delle condizioni precedenti è soddisfatta, utilizza solo le variabili esistenti
if (!(mean(div_p_values) < 0.05) && !(riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05)) {
  variabili <- nomi_righe_da_utilizzare
}

# Creazione della formula significativa per il modello
formula_significativa <- as.formula(paste("won ~", paste(variabili, collapse = " + ")))

```

L'analisi dettagliata degli effetti di interazione ci permette di affinare il modello lineare, migliorando la nostra comprensione di come le variabili interagiscono tra loro e il loro impatto collettivo sulle vittorie. La selezione attenta di queste interazioni è fondamentale, poiché modella la realtà di come i fattori di gioco si influenzano reciprocamente in maniere non sempre intuitivamente prevedibili.

### Rifinitura e Valutazione del Modello Finale
Dopo aver selezionato gli effetti di interazione rilevanti, rifiniamo il modello includendo solo quelle interazioni che hanno dimostrato una significatività statistica, portando a un modello più snello e potenzialmente più potente.

```{r}

# Costruzione del nuovo modello lineare con la formula significativa
linModNormalized_2 <- lm(formula_significativa, data = train_1)

# Visualizzazione del riassunto del nuovo modello
summary(linModNormalized_2)

```
```{r}

# Calcolare il summary del modello lineare
summary_linModNormalized_2 <- summary(linModNormalized_2)

# Ottenere il coefficiente di determinazione R-quadrato
r_squared_LM_2 <- summary_linModNormalized_2$r.squared
cat("R-quadrato LM_2:", r_squared_LM_2, "\n")

# Calcolare l'R-quadrato adattato
# (dove n è il numero di osservazioni e k è il numero di parametri nel modello)
n <- length(linModNormalized_2$residuals)  # Numero di osservazioni
k <- length(linModNormalized_2$coefficients) - 1  # Numero di parametri nel modello
adjusted_r_squared_LM_2 <- 1 - ((1 - r_squared_LM_2) * (n - 1) / (n - k - 1))

cat("R-quadrato adattato LM_2:", adjusted_r_squared_LM_2, "\n")

```
---

# Esplorazione del Modello di Regressione di Poisson

Nell'ambito degli studi statistici, la regressione di Poisson può offrire una prospettiva alternativa e talvolta più adeguata per la modellazione di variabili di conteggio, come il numero di vittorie in un contesto sportivo. Pertanto, esploriamo la possibilità di utilizzare un modello di regressione generalizzata di Poisson per confrontare la sua efficacia con quella del modello lineare già sviluppato.

### Costruzione del Modello di Poisson
Il modello di Poisson è particolarmente adatto per dati che descrivono il conteggio di eventi che si verificano in uno spazio o in un intervallo di tempo definiti. In questo caso, il numero di vittorie può essere adatto per tale modellizzazione, presupponendo che i dati si conformino alla distribuzione di Poisson.

```{r}

# Questo codice addestra un modello di regressione generalizzata di Poisson (linModNormalized2_pois) utilizzando la stessa specifica del modello lineare (linModNormalized2). Successivamente,    vengono ottenuti e combinati i coefficienti di entrambi i modelli in un unico dataframe per una facile comparazione.

# Creazioni di un modello di regressione generalizzata di Poisson
linModNormalized_2_pois = glm(formula_significativa, family=poisson(link=log), data = train_1)
summary(linModNormalized_2_pois)

```

### Confronto dei Coefficienti dei Modelli Lineare e di Poisson
Per un'analisi comparativa, estraiamo i coefficienti dai modelli lineare e di Poisson. È importante notare che i coefficienti del modello di Poisson vengono esponenziati per facilitarne l'interpretazione nel contesto del modello log-lineare.

```{r}

# Ottenimento dei coefficienti per ambo i modelli
normal = coefficients(linModNormalized_2)
poisson = exp(coefficients(linModNormalized_2_pois))

# Combinazione dei coefficienti in un unico dataframe
coefficients_table <- cbind(normal, poisson)

coefficients_table
```

### Considerazioni Generali:
È importante notare che gli effetti delle variabili possono essere interpretati in modo diverso a seconda della distribuzione scelta per il modello. La scelta tra distribuzione normale e di   Poisson dipende dalla natura della variabile dipendente e dagli obiettivi di modellazione. Nel contesto di modelli di regressione, è sempre buona pratica verificare l'adeguatezza del   modello esaminando i residui, eseguendo test diagnostici e valutando la bontà di adattamento. L'interpretazione dei coefficienti dovrebbe essere fatta considerando la scala appropriata per    la distribuzione utilizzata (lineare per la normale, logaritmica per la Poisson). Dato che stiamo cercando di prevedere il numero di vittorie, la distribuzione di Poisson potrebbe essere più appropriata per variabili conteggio come questa. Tuttavia, è sempre necessario verificare l'adeguatezza del modello ai dati specifici.

### Valutazione dei modelli mediante l'Akaike Information Criterion
Possiamo valutare la bonta dei due modelli mediante il valore di AIC:
Acronimo di Akaike Information Criterion, è una misura utilizzata in statistica per valutare la bontà di un modello statistico; L'obiettivo dell'AIC è trovare un compromesso tra la bontà di adattamento del modello ai dati e la sua complessità, cercando di selezionare il modello migliore in termini di previsione. E' preferibile un modello con AIC piu basso.

```{r}

# Calcola il criterio di informazione di Akaike (AIC) per il modello lineare
aic_2 <- AIC(linModNormalized_2)

# Calcola il criterio di informazione di Akaike (AIC) per il modello di Poisson
aic_2_pois <- AIC(linModNormalized_2_pois)

# Stampa i risultati AIC
cat("AIC per il modello lineare (linModNormalized_2):", aic_2, "\n")
cat("AIC per il modello di Poisson (linModNormalized_2_pois):", aic_2_pois, "\n")

```
Pertanto, il modello lineare (linModNormalized_2) sembra essere migliore rispetto al modello di Poisson (linModNormalized_2_pois), poiché ha un valore AIC inferiore. La differenza tra i due valori AIC può essere ulteriormente considerata per valutare quanto il modello lineare sia significativamente migliore rispetto al modello di Poisson.

---

# Conclusioni

Nel corso di questo studio sull'influenza dei rimbalzi rispetto alle vittorie nel campionato di basket NBA, abbiamo implementato e confrontato diversi modelli statistici. Inizialmente, il processo di normalizzazione e la rimozione degli outliers hanno portato alla creazione di un modello lineare iniziale, seguito da un modello Lasso basato sui dati di training. Il modello Lasso ha dimostrato una maggiore efficacia, incoraggiando il suo utilizzo come modello preferito.

Successivamente, attraverso un'analisi delle variabili, abbiamo identificato il modello finale linModNormalized_2, che include interazioni significative tra le variabili e tiene conto dell'impatto della Divisione sulle vittorie. Questo modello ha mostrato un notevole miglioramento delle metriche di adattamento rispetto al modello iniziale, evidenziando la sua robustezza nell'esplorare le relazioni sottostanti nei dati.

Inoltre, l'analisi delle metriche di adattamento del modello lineare finale linModNormalized_2 ha confermato la sua efficacia, con valori più elevati di R@ e R2adjusted rispetto al modello iniziale basato solo sui dati di training (senza outliers). Questi risultati supportano la scelta del modello linModNormalized_2 come modello preferito per spiegare la variazione nei dati.

Infine, il confronto dei modelli è stato esteso all'analisi della differenza tra un modello lineare e un modello di Poisson attraverso il criterio di informazione di Akaike (AIC). I risultati dell'AIC hanno indicato che il modello lineare (linModNormalized_2) è preferibile al modello di Poisson (linModNormalized_2_pois), suggerendo che il primo si adatti meglio alla variabilità delle vittorie in relazione ai rimbalzi.

In conclusione, il processo analitico ha permesso di identificare e validare un modello lineare finale che si adatta bene ai dati e offre una migliore comprensione della relazione tra rimbalzi e vittorie nel contesto del campionato NBA.

---







