---
title: "Analisi Statistica del dataframe Basketball Teams, Gruppo Lampedusa"
date: "`r Sys.Date()`"
output:
  html_document: 
    df_print: paged
  pdf_document:
    latex_engine: xelatex
  word_document: default
author: "Bonsembiante Davide, Fumagalli Uriel, Gallizioli Lorenzo, Paganelli Thomas"
abstract: "Questo documento rappresenta un'approfondita analisi statistica nel campo del basket professionistico, con un focus specifico sulle prestazioni delle squadre NBA. Utilizzando metodi statistici avanzati, si esplorano diverse metriche chiave per comprendere meglio le dinamiche del gioco e i fattori che influenzano il successo delle squadre."
editor_options: 
  markdown: 
    wrap: 80
    reference_location: document
---

# Indice
  - [Indice](#indice)
  - [Progetto numero 5](#progetto-numero-5)
  - [Presentazione problema](#presentazione-problema)
  - [Analisi dati iniziale e grafici](#analisi-dati-iniziale-e-grafici) 
    - [Correlazione dati](#correlazione-dati)
    - [Analisi vittorie](#analisi-vittorie)
    - [Analisi rimbalzi](#analisi-rimbalzi)
    - [Test](#test)
      - [Test Anderson-Darling sui rimbalzi](#test-anderson-darling-sui-rimbalzi)
      - [Test Kolmogorov-Smirnov](#test-kolmogorov-smirnov)
      - [Test Shapiro-Wilk](#test-shapiro-wilk)
  - [Divisione train/test](#divisione-train/test)
  - [Presentazione modello lineare](#presentazione-modello-lineare)
    - [Modello: L'importanza dei rimbalzi](#modello:-l'importanza-dei-rimbalzi)
    - [Formule](#formule)
    - [Modello lineare sul dataframe train](#modello-lineare-sul-dataframe-train)
    - [Grafici](#grafici)
  - [Modello lineare normalizzato sul dataframe train](#modello-lineare-normalizzato-sul-dataframe-train)
  - [Test modello lineare](#test-modello-lineare)
    - [Summary](#summary)
    - [R-quadrato](#r-quadrato)
    - [R-quadrato Adattato](#r-quadrato-adattato)
    - [Test Shapiro](#test-shapiro)
    - [Test di omoschedasticità](#test-di-omoschedasticità)
    - [Test di multicollinearità](#test-di-multicollinearità)
  - [Modello lineare sul dataframe test](#modello-lineare-sul-dataframe-test)
  - [LASSO](#lasso)
  - [Rimozione outliers e LASSO](#rimozione-outliers-e-lasso)
    - [Rimozione outliers](#rimozione-outliers)

---

# Progetto scelto: 5

- **Variabile Dipendente**
  - Numero di Vittorie per Stagione: Questa variabile rappresenta l'obiettivo primario dell'analisi, indicando il successo complessivo di una squadra nel corso di una singola stagione NBA.
- **Covariate**
  - Variabili Selezionate: A seconda degli obiettivi specifici dell'analisi, verranno incluse diverse covariate. Queste possono comprendere una vasta gamma di metriche di gioco.
- **Criterio di Selezione della Squadra**
  - Partite Giocate: Nel dataset, si considereranno esclusivamente le squadre che hanno disputato un totale di 82 partite nella stagione (identificate come `df$games == 82`). Questo criterio assicura l'uniformità e la comparabilità dei dati analizzati.

---

# Presentazione problema

In questo report, ci siamo concentrati sull'elaborazione di un modello lineare predittivo per determinare il numero di vittorie in funzione dei rimbalzi annuali effettuati dalle squadre nella NBA. Il modello si applica esclusivamente a squadre che hanno disputato almeno 82 partite per stagione, considerando un arco temporale che va dal 1976 al 2011.

L'approccio del modello lineare si basa sull'adozione di coefficienti accuratamente selezionati, mirati a massimizzare la significatività e l'aderenza alla nostra interpretazione dell'impatto di specifiche variabili sulle vittorie. Questi coefficienti sono stati scelti in modo da riflettere al meglio la nostra concezione di quali fattori influenzino maggiormente il successo delle squadre.

Ulteriori informazioni riguardanti l'esecuzione del programma e l'utilizzo della funzione predittiva sono fornite nei paragrafi successivi, dove viene anche descritto il processo di sviluppo e validazione del modello.

```{r Inizializzazione, message=FALSE, warning=FALSE, include=FALSE}

library(here)
library(corrplot)
library(nortest)
library(lmtest)
library(car)
library(plotly)
library(heatmaply)
library(ggheatmap)
library(gridExtra)
library(olsrr)
library(ggplot2)
library(viridis)
library(glmnet)
library(highcharter)
library(reshape2)
library(RColorBrewer)
library(tidyr)
library(dplyr)

knitr::opts_knit$set(root.dir = here("0_Materiale"))

```

---

# Analisi dati iniziale e grafici


Il chunk riportato legge un dataset da un file, filtra le righe in base ai criteri sopra riportati, calcola una nuova variabile e offre la possibilità di ottenere un riassunto statistico dei dati filtrati.
```{r Lettura dati dal dataset}
filepath <- here("0_Materiale", "basketball_teams.txt")
dataset <- read.delim(filepath)
# str(dataset)

FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio 

df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
df$reb <- df$o_reb + df$d_reb

# summary(df)
```


## Correlazione dati

```{r Analisi correlazione dati - corrplot, echo=FALSE, warning = FALSE, message = FALSE}

# CORRPLOT

data_subset <- df[, c(11:40, 54)]
cor_matrix <- cor(data_subset, use = "complete.obs")  

cor_data <- melt(cor_matrix)
names(cor_data) <- c("Variable1", "Variable2", "Correlation")

# Create the heatmap
p <- plot_ly(data = cor_data, x = ~Variable1, y = ~Variable2, z = ~Correlation, 
             type = "heatmap", 
             colors = viridis(n = 1024,  option = "magma"),
             hoverinfo = "x+y+z") %>% 
  layout(title = 'Correlation Matrix Heatmap',
         xaxis = list(tickangle = 45),
         yaxis = list(tickangle = 45),
         autosize = TRUE)
p

```


## Analisi rimbalzi

Nel nostro dataframe sono incluse variabili specifiche per analizzare in dettaglio il ruolo dei rimbalzi nel basket. Ecco una descrizione degli acronimi utilizzati:

- o_oreb: **Rimbalzi ottenuti in attacco**
  - Questo valore rappresenta il numero di volte in cui una squadra recupera la palla dopo un tiro mancato mentre è in fase offensiva. È un indicatore diretto dell'aggressività e dell'efficacia offensiva di una squadra.
- o_dreb: **Rimbalzi subiti in attacco**
  - Indica il numero di rimbalzi che una squadra concede all'avversario mentre è in attacco. Un valore più basso suggerisce una maggiore capacità di mantenere il controllo della palla dopo un tiro mancato.
- o_reb: **Totale rimbalzi in attacco** 
  - Questa è la somma dei rimbalzi ottenuti e subiti in attacco. Fornisce una misura complessiva dell'attività di rimbalzo di una squadra quando è in fase offensiva.
- d_oreb: **Rimbalzi subiti in difesa**
  - Rappresenta il numero di rimbalzi che una squadra permette all'avversario di ottenere mentre è in difesa. Minimizzare questo numero è cruciale per prevenire seconde opportunità di punteggio per l'avversario.
- d_dreb: **Rimbalzi ottenuti in difesa**
  - Indica il numero di volte in cui una squadra recupera la palla dopo un tiro mancato dall'avversario mentre è in difesa. È un indicatore chiave dell'efficacia difensiva e della capacità di interrompere l'attacco avversario.
- d_reb: **Totale rimbalzi in difesa**
  - Questo è il totale dei rimbalzi che una squadra ottiene o concede mentre è in difesa. Offre una visione olistica dell'impegno e dell'efficacia di una squadra nel controllare la zona difensiva durante il gioco.

```{r Plot densita per ogni variabile, echo = FALSE}
df_reb <- subset(df, select = c("o_oreb", "o_dreb", "o_reb", "d_oreb", "d_dreb", "d_reb", "won"))

# Imposta il layout a 2 righe e 3 colonne per i grafici di densità
par(mfrow = c(2, 3))

# Ciclo per generare grafici di densità per ciascuna variabile di interesse
for (variables in 1:(dim(df_reb)[2]-1)) {
  thisvar <- df_reb[, variables]
  d <- density(thisvar)
  xmin <- floor(min(thisvar))
  xmax <- ceiling(max(thisvar))
  
  # Crea il plot della densità con stile accattivante
  plot(d, main = names(df_reb)[variables], xlab = "", col = "blue", lwd = 1.5, xlim = c(xmin, xmax), ylim = c(0, max(d$y)*1.1))
  
  # Aggiungi la distribuzione normale teorica ideale in rosso
  x <- seq(xmin, xmax, length = 100)
  lines(x, dnorm(x, mean = mean(thisvar), sd = sd(thisvar)), col = "red", lwd = 1.5)  # Modifica lo spessore delle linee
  
  # Aggiungi griglia per migliorare la leggibilità
  grid()
}

# Aggiungi titolo in grassetto e corsivo, con spessore del testo modificato
title(bquote(bold(italic("Density plots with Normal Distribution"))), line = -17, cex.main = 2, outer = TRUE)
```

### Percentuale di valori non zero per ciascuna variabile di interesse

Viene Calcolata la percentuale di valori non zero per ciascuna variabile di interesse all'interno del dataframe df_reb, serve per verificare ulteriormente la consistenza dei dati acqusiti.
```{r Percentuale di valori non zero per ogni variabile, echo = FALSE}
# Stampa percentuale di valori non zero per ciascuna variabile di interesse
print(paste("Percentage non-zero o_oreb: ", round(length(which(df_reb$o_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_dreb: ", round(length(which(df_reb$o_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_reb: ", round(length(which(df_reb$o_reb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_oreb: ", round(length(which(df_reb$d_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_dreb: ", round(length(which(df_reb$d_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_reb: ", round(length(which(df_reb$d_reb > 0)) / dim(df_reb)[1] * 100, 2)))

```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Heatmap rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

values <- aggregate(cbind(reb, o_oreb, o_dreb, d_oreb, d_dreb, o_reb, d_reb, won) ~ tmID, data = df, FUN = sum)

heatmap_df <- subset(values, select = -c(o_oreb, o_dreb, d_oreb, d_dreb, won, reb))
rownames(heatmap_df) <- heatmap_df$tmID
heatmap_df <- heatmap_df[,-1]

heatmaply(
 heatmap_df,
 colors = viridis(n = 256,  option = "magma"),
 k_col = 2,
 k_row = 4,
  main = "<b><i>Confronto tra rimbalzi (Heatmap)</i></b>"
)

```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Istogramma stacked rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
plot_ly(values, x = ~tmID, y = ~o_reb, type = 'bar', name = 'Rimbalzi offensivi', marker = list(color = '#FFAFA1')) %>%
  add_trace(y = ~d_reb, name = 'Rimbalzi difensivi', marker = list(color = '#b2fff8')) %>%
  layout(yaxis = list(title = 'Valori'), barmode = 'stack', title="<b><i>Confronto tra rimbalzi (Istogramma)</i></b>")
```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Istogramma rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
histogram <- plot_ly(data = df, x = ~reb, type = "histogram",
        marker = list(color = 'skyblue', line = list(color = 'black', width = 1)),
        nbinsx = 20, legendgroup = "Rimbalzi", name = "Campione") %>% 
  add_trace(type = "scatter", mode = "lines",
            x = c(mean(df$reb), mean(df$reb)),
            y = c(0, 215),
            line = list(color = "red", width = 2, dash = "dash"),
            name = "Media") %>%
  layout(title = list(text = "<b><i>Frequenza dei Rimbalzi</i></b>", pad = 10),
         xaxis = list(title = '<b><i>Rimbalzi</i></b>'),
         yaxis = list(title = '<b><i>Frequenza</i></b>'),
         legend = list(title = "<b><i>Legenda</i></b>", tracegrouporder = "reversed"))

(histogram)
```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Densita rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
density_data <- density(df$reb)
mu <- mean(df$reb)
sigma <- sd(df$reb)
normal_data <- dnorm(density_data$x, mean = mu, sd = sigma)

density_plot <- plot_ly(x = density_data$x, y = density_data$y, type = 'scatter', mode = 'lines',
             line = list(color = 'blue', width = 2),
             name = "Densità rimbalzi totale") %>%
  layout(title = "Densità dei Rimbalzi",
         xaxis = list(title = "Rimbalzi"),
         yaxis = list(title = "Density", autotick = TRUE, autorange = TRUE))

density_plot <- add_trace(density_plot, x = density_data$x, y = normal_data, mode = 'lines',
               line = list(color = 'green', width = 2),
               fill = "tozeroy", fillcolor = "rgba(0, 255, 0, 0.2)",
               name = "Dist normale ideale")

density_plot <- add_trace(density_plot, x = c(mu, mu), y = c(0, max(density_data$y)),
               mode = 'lines', line = list(color = 'red', width = 2, dash = 'dash'),
               name = "Media")

(density_plot)
```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Boxplot rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
aggregated_data <- df %>%
  select(tmID, year, o_reb, d_reb) %>%
  group_by(tmID, year) %>%
  summarize(
    o_reb = mean(o_reb, na.rm = TRUE), 
    d_reb = mean(d_reb, na.rm = TRUE),
    .groups = "drop"  # Aggiunto per evitare il raggruppamento
  )
reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(o_reb, d_reb), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")
box_plot <- plot_ly()
for (i in 2:ncol(reshaped_data)) {
    current_column_data <- reshaped_data[[i]]
    box_plot <- box_plot %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

box_plot <- box_plot %>% layout(title = "<b><i>Boxplot dei Rimbalzi Offensivi e Difensivi</i></b>", yaxis = list(title = "Valori"), xaxis = list(title = "tmID"))
(box_plot)


```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Corrplot rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
data_subset <- df[, c("reb", "o_reb", "d_reb")]
cor_matrix <- cor(data_subset)

rownames(cor_matrix) <- colnames(data_subset)
colnames(cor_matrix) <- colnames(data_subset)

cor_data <- reshape2::melt(cor_matrix)
names(cor_data) <- c("Var1", "Var2", "Corr")

dimnames(cor_matrix) <- list(rownames(cor_matrix), colnames(cor_matrix))
data_for_plotly <- as.data.frame(as.table(cor_matrix))

cor_plot <- plot_ly(data = cor_data, 
             x = ~Var1, 
             y = ~Var2, 
             z = ~Corr, 
             type = "heatmap", 
             colors = colorRampPalette(c("#4575b4", "#91bfdb", "#e0f3f8", "#fee08b", "#d73027"))(100),
             hoverinfo = "x+y+z") %>% 
  layout(title = '<b><i>Correlation Matrix</i></b>',
         xaxis = list(title = "", tickangle = 45, side = "bottom", automargin = TRUE),
         yaxis = list(title = "", automargin = TRUE),
         autosize = TRUE)

cor_values <- round(as.matrix(cor_matrix), 2)  # Round for readability
for (i in seq_len(nrow(cor_matrix))) {
  for (j in seq_len(ncol(cor_matrix))) {
    cor_plot <- cor_plot %>% add_annotations(
      x = rownames(cor_matrix)[i],
      y = colnames(cor_matrix)[j],
      text = as.character(cor_values[i, j]),
      showarrow = FALSE,
      font = list(color = ifelse(cor_values[i, j] < 0.5, "white", "black"))
    )
  }
}
(cor_plot)
```

## Analisi vittorie


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r Analisi distribuzione vittorie - boxplot, warning=FALSE, echo = FALSE, message = FALSE, message = FALSE}

#BOXPLOT
aggregated_data <- df %>%
  select(tmID, year, won) %>%
  group_by(tmID, year) %>%
  summarize(
    won = mean(won, na.rm = TRUE),
  )

reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(won), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")

fig <- plot_ly()

for (i in 2:ncol(reshaped_data)) {
  current_column_data <- reshaped_data[[i]]
  fig <- fig %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

fig <- fig %>% layout(title = "<b><i>Boxplot delle vittorie</i></b>", yaxis = list(title = "Numero vittorie"), xaxis = list(title = "tmID"))
(fig)

```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r, Analisi distribuzione vittorie - istogramma, warning = FALSE, echo = FALSE, message = FALSE}
# ISTOGRAMMA INTERATTIVO
# Calcola la media della variabile "won" nel data frame "df"
mean_value <- mean(df$won)
# Crea un istogramma con plot_ly
histogram <- plot_ly(df, x = ~won, type = "histogram",
                     marker = list(color = "skyblue", line = list(color = "white", width = 0.5)),
                     opacity = 0.7, name = "Campione") %>%
  layout(title = list(text = "<b><i>Distribuzione delle Vittorie</i></b>", y = 0.97),
         xaxis = list(title = "<b><i>Numero di Vittorie</i></b>", zeroline = FALSE),
         yaxis = list(title = "<b><i>Frequenza</i></b>", zeroline = FALSE),
         barmode = "overlay") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "lines", 
            line = list(color = "red", width = 2), name = "<i><b>Media</i></b>") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "markers", 
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean_value, y = 0, 
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2)

# Visualizza l'istogramma interattivo
(histogram)

```


#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r, Analisi distribuzione vittorie - densita, warning = FALSE, echo = FALSE, message = FALSE}
# PLOT DENSITA INTERATTIVO

# Calcola la densità delle vittorie
density_plot <- density(df$won)

# Crea il plot di densità con plot_ly
density_interactive <- plot_ly(x = density_plot$x, y = density_plot$y, type = "scatter", mode = "lines",
                               line = list(color = "skyblue", width = 2), name = "Densità") %>%
  layout(title = list(text = "<b><i>Distribuzione di Densità delle Vittorie</i></b>", x = 0.5),
         xaxis = list(title = "<i>Numero di Vittorie</i>"),
         yaxis = list(title = "<i>Densità</i>"),
         showlegend = TRUE) %>%
  add_trace(x = c(mean(df$won), mean(df$won)), y = c(0, max(density_plot$y)),
            type = "scatter", mode = "lines", line = list(color = "red", width = 2),
            name = "<i><b>Media</b></i>") %>%
  add_trace(x = mean(df$won), y = max(density_plot$y), type = "scatter", mode = "markers",
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean(df$won), y = max(density_plot$y) * 1.05,
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2,
                  ax = 0, ay = -40)

# Visualizza il plot di densità interattivo
(density_interactive)

```


## Test

### Test Anderson-Darling sui rimbalzi

Il test Anderson-Darling è un test statistico non parametrico, utilizzato per verificare l'ipotesi che un campione di dati provenga da una particolare distribuzione, in questo caso, la distribuzione normale. È particolarmente sensibile alle deviazioni nella coda della distribuzione.  
- **Range**: 0 a $+\infty$  
- **Interpretazione**: Valori più bassi indicano una maggiore aderenza alla distribuzione normale. Si confronta il valore di test con valori critici specifici per determinare se rifiutare l'ipotesi di normalità.
```{r, warning=FALSE}
# Questo codice esegue il test di Anderson-Darling sulla variabile 'reb' nel tuo dataset (df)

ad.test(df$reb)
```

Con un livello di significatività ($\alpha$) di 0.01 e un p-value molto
piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per
i dati della variabile df\$reb, si puo concludere che si hanno sufficienti
evidenze statistiche per respingere lipotesi nulla che i dati seguano una
distribuzione normale. Con il livello di significatività del 0.01 e
il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di
significatività, quindi si respinge lipotesi nulla. Questo suggerisce
che i dati nella variabile df\$reb non seguono una distribuzione normale
al livello di significatività del 0.01. In termini più pratici, si hanno
abbastanza evidenze statistice per concludere che la variabile df\$reb
non segue una distribuzione normale.

### Test Kolmogorov-Smirnov

Il test Kolmogorov-Smirnov (K-S) è un metodo non parametrico utilizzato per determinare se un campione di dati segue una specifica distribuzione, in questo caso, la distribuzione normale. È ampiamente impiegato per la sua generalità e la facilità di implementazione.  
- **Range**: 0 a 1  
- **Interpretazione**: Valori più bassi indicano una maggiore somiglianza alla distribuzione normale. Un valore di test significativamente grande porta al rifiuto dell'ipotesi di normalità.
```{r, warning=FALSE}
# Test di Kolmogorov-Smirnov per confrontare la distribuzione di 'reb' con una distribuzione normale

ks.test(df$reb, "pnorm")
```

Il test KS
confronta la distribuzione empirica dei dati con una distribuzione
teorica (spesso una distribuzione uniforme). In breve, il risultato
suggerisce che i nostri dati non seguono la distribuzione teorica normale
presunta, e cè un elevata probabilità che la differenza osservata sia
statisticamente significativa.

### Test Shapiro-Wilk

Il test Shapiro-Wilk è un metodo statistico non parametrico utilizzato specificatamente per testare la normalità di un campione di dati. È noto per la sua affidabilità e precisione, soprattutto in campioni di dimensioni ridotte.  
- **Range**: 0 a 1  
- **Interpretazione**: Valori più vicini a 1 suggeriscono una maggiore aderenza alla distribuzione normale. Valori significativamente bassi indicano la deviazione dalla normalità.
```{r, warning=FALSE}
# Test di Shapiro-Wilk per la normalità dei dati nella variabile 'reb' (rimbalzi)

sf.test(df$reb)
```

In sintesi, il risultato del test di Shapiro-Francia indica che i
dati nella variabile df\$reb non seguono una distribuzione normale.
Questo è supportato dal valore basso del p-value, il quale suggerisce
che la differenza tra la distribuzione dei dati e una distribuzione
normale è statisticamente significativa.

---
 
# Presentazione modello lineare

## Modello: L'importanza dei rimbalzi

Abbiamo creato un modello lineare per esplorare come i rimbalzi influenzano le vittorie in NBA. L'idea è semplice: capire se squadre che rimbalzano meglio vincono di più. Il modello analizza diversi tipi di rimbalzi (offensivi, difensivi) e come questi si traducono in successo sul campo.

## Formule

Le formule che usiamo si concentrano su diversi aspetti dei rimbalzi, come recuperare la palla dopo un tiro sbagliato o proteggere il canestro. Ogni formula ci dà un'idea di come le squadre gestiscono e sfruttano i rimbalzi durante le partite. L'obiettivo è vedere quale impatto hanno questi fattori sulle vittorie.

> $\text{Formula1} = \frac{\text{Rimbalzi offensivi in attacco}}{\text{Tiri sbagliati su azione}}$  
  
- **Formula 1: Efficienza nel Rimbalzo Offensivo**  
Questa formula calcola la percentuale di rimbalzi offensivi catturati dalla squadra in seguito ai tiri mancati. Il numeratore, "Rimbalzi offensivi in attacco", rappresenta il totale dei rimbalzi catturati dopo un tiro mancato dall'attacco. Il denominatore, "Tiri sbagliati su azione", è il numero totale di tiri non riusciti dalla squadra. Il quoziente fornisce un indice diretto della competenza di una squadra nel mantenere il possesso della palla dopo un tentativo di tiro fallito, un aspetto cruciale per generare opportunità di punteggio aggiuntive.

> $\text{Formula2} = \frac{\text{Rimbalzi difensivi in difesa presi}}{\text{Tiri sbagliati su azione degli avversari}}$  
  
- **Formula 2: Competenza nel Rimbalzo Difensivo**
Questa formula misura l'efficacia della squadra nel recuperare i rimbalzi difensivi. Il numeratore, "Rimbalzi difensivi in difesa presi", indica il totale dei rimbalzi catturati dalla squadra in difesa. Il denominatore, "Tiri sbagliati su azione degli avversari", è il numero di tiri falliti dalla squadra avversaria. Il risultato fornisce un'indicazione quantitativa della capacità di una squadra di terminare l'attacco avversario e iniziare una transizione offensiva, elemento fondamentale per il controllo del flusso di gioco.


> $\text{Formula3} = \frac{\text{Palle riprese in attacco} + 1.5 \times \text{Palle riprese in difesa}}{\text{Palle perse in attacco} + 2 \times \text{Rimbalzi subiti in difesa}}$  
  
- **Formula 3: Bilancio Rimbalzi/Palle Perse**
Questa formula presenta un rapporto complesso, dove il numeratore somma "Palle riprese in attacco" (rimbalzi offensivi) e "Palle riprese in difesa" (rimbalzi difensivi) moltiplicate per 1.5, un fattore che sottolinea l'importanza dei rimbalzi difensivi. Il denominatore combina "Palle perse in attacco" e "Rimbalzi subiti in difesa" moltiplicati per 2, indicando le occasioni perse di recupero di rimbalzi. Questa formula è progettata per valutare la gestione globale dei rimbalzi da parte di una squadra, enfatizzando il valore della difesa rispetto all'attacco.

> $\text{Formula4} = (\text{Palle riprese in attacco - Palle perse in attacco}) + 1.5*(\text{Palle riprese in difesa - Palle perse in difesa})$  
  
- **Formula 4: Efficienza Rimbalzi Netta**
Questa formula calcola la differenza netta tra i rimbalzi catturati e quelli persi, sia in attacco che in difesa, applicando un coefficiente di 1.5 ai rimbalzi difensivi. Il calcolo evidenzia il saldo netto di rimbalzi catturati contro quelli persi, con un'enfasi aggiuntiva sulla componente difensiva. Questo indice fornisce una misura diretta dell'efficacia complessiva di una squadra nel dominare il gioco sui rimbalzi.

> $\text{Formula5} = \frac{(\frac{\text{Rimbalzi subiti in difesa}}{\text{Palle perse in difesa}})}{(\frac{\text{Rimbalzi subiti in attacco}}{\text{Palle perse in attacco}})}$  
  
- **Formula 5: Rapporto Rimbalzi/Palle Perse**
Questa formula offre un confronto tra l'effetto dei rimbalzi sulla perdita di palla in attacco e in difesa. Il numeratore rappresenta il rapporto tra "Rimbalzi subiti in difesa" e "Palle perse in difesa", mentre il denominatore fa lo stesso per l'attacco. Questo rapporto mette in luce l'impatto dei rimbalzi sulle opportunità perse, sia in termini di difesa che di attacco.

> $\text{Formula6} = (\text{Rimbalzi ottenuti in attacco} + \text{Rimbalzi ottenuti in difesa}) - (\text{Rimbalzi subiti in difesa} - \text{Rimbalzi subiti in attacco})^2$  

- **Formula 6: Bilancio Complessivo Rimbalzi**  
Questa formula calcola un indice che tiene conto sia dei rimbalzi ottenuti in attacco (Rimbalzi ottenuti in attacco) e in difesa (Rimbalzi ottenuti in difesa), sia dei rimbalzi subiti in difesa (Rimbalzi subiti in difesa) e in attacco (Rimbalzi subiti in attacco), elevando al quadrato la differenza tra i rimbalzi subiti. Offre una visione complessiva dell'efficacia della squadra nel controllo dei rimbalzi sotto entrambi i canestri.

> $\text{Formula7} = (\text{Efficienza nel Rimbalzo Offensivo} + \text{Competenza nel Rimbalzo Difensivo})^2$  

- **Formula 7: Sinergia Tra Rimbalzi Offensivi e Difensivi**  
Combina le misurazioni dell'efficienza nei rimbalzi offensivi (Efficienza nel Rimbalzo Offensivo) e difensivi (Competenza nel Rimbalzo Difensivo), elevandone la somma al quadrato. Questo calcolo evidenzia l'importanza della sinergia tra le due componenti del gioco sui rimbalzi.

> $\text{Formula8} = \frac{\text{Rimbalzi ottenuti in attacco}}{\text{Totale rimbalzi in attacco}}$  

- **Formula 8: Proporzione Rimbalzi Offensivi**  
Questa formula determina la percentuale dei rimbalzi offensivi (Rimbalzi ottenuti in attacco) sul totale dei rimbalzi in attacco (Totale rimbalzi in attacco). Fornisce un'indicazione diretta dell'efficienza di una squadra nel recuperare la palla dopo i tiri falliti in attacco.

> $\text{Formula9} = \left(\frac{\text{Rimbalzi ottenuti in attacco}}{\text{Rimbalzi subiti in attacco}}\right)^2$  

- **Formula 9: Predominanza dei Rimbalzi Offensivi**  
Calcola il rapporto tra i rimbalzi offensivi ottenuti (Rimbalzi ottenuti in attacco) e i rimbalzi subiti in attacco (Rimbalzi subiti in attacco), elevato al quadrato. Questa formula enfatizza la capacità di una squadra di dominare sotto il proprio canestro in fase offensiva.

> $\text{Formula10} = \left(\frac{\text{Rimbalzi ottenuti in difesa}}{\text{Rimbalzi subiti in difesa}}\right)^2$  

- **Formula 10: Predominanza dei Rimbalzi Difensivi**  
Analoga alla Formula 9, ma applicata al contesto difensivo. Misura il rapporto tra i rimbalzi difensivi ottenuti (Rimbalzi ottenuti in difesa) e i rimbalzi subiti in difesa (Rimbalzi subiti in difesa), elevato al quadrato. Sottolinea l'efficacia di una squadra nel proteggere il proprio canestro in fase difensiva.

## Modello lineare sul dataframe train

Legenda significato acronimi:

- o_oreb: Rimbalzi ottenuti in attacco 
- o_dreb: Rimbalzi subiti in attacco 
- o_reb: Totale rimbalzi in attacco 
- d_oreb: Rimbalzi subiti in difesa 
- d_dreb: Rimbalzi ottenuti in difesa 
- d_reb: Totale rimbalzi in difesa 

```{r Formule, warning = FALSE}

df$f1 <- (df$o_oreb) / (df$o_fga - df$o_fgm)
df$f2 <- (df$d_dreb) / (df$d_fga - df$d_fgm)
df$f3 <- (df$o_oreb + 1.5 * df$d_dreb) / (df$o_dreb + 2 * df$d_oreb)
df$f4 <- (df$o_oreb - df$o_dreb) + 1.5 * (df$d_dreb - df$d_oreb)
df$f5 <- (df$d_oreb / df$d_to) / (df$o_dreb / df$o_to)
df$f6 <- (df$o_oreb + df$d_dreb) - (df$d_oreb - df$o_dreb)^2
df$f7 <- (df$f1 + df$f2)^2
df$f8 <- (df$o_oreb) / (df$o_reb)
df$f9 <- ((df$o_oreb) / (df$o_dreb))^2
df$f10 <- ((df$d_dreb) / (df$d_oreb))^2

```

Si esegue la divisione del dataframe df in un set di addestramento (train) e un set di test (test). La divisione è effettuata campionando casualmente il 70% delle righe per l'addestramento e utilizzando il restante 30% per il test. Successivamente, viene creato il modello lineare utilizzando le variabili predittive sopra create per prevedere la variabile di risposta won nel set di addestramento.
```{r Divisione tra train e test}
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))

df = subset(df, select = c("f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "won", "divID", "confID"))

train  <- df[sample, ]
test   <- df[!sample, ]

# Creazione del modello lineare
linMod <- lm(won ~ f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10, data = train)
summary(linMod)

```

# Modello lineare normalizzato sul dataframe train

La normalizzazione dei dati è una pratica fondamentale nell'elaborazione di modelli statistici, specialmente nei modelli lineari. Questo processo è volto a standardizzare la scala delle variabili, rendendo più agevole il confronto tra di esse e migliorando l'efficienza dell'algoritmo di regressione. In particolare, la normalizzazione è cruciale quando le variabili hanno scale molto diverse, poiché ciò potrebbe influenzare negativamente la precisione del modello.

Nel codice R seguente, abbiamo normalizzato le variabili del nostro dataframe 'df', utilizzando la funzione `scale`. Questo assicura che ciascuna variabile contribuisca in modo equo al modello, permettendo una più accurata interpretazione dei coefficienti della regressione lineare.

```{r, warning = FALSE}

# Normalizziamo le covariate
train$f1_z <- scale(train$f1)
train$f2_z <- scale(train$f2)
train$f3_z <- scale(train$f3)
train$f4_z <- scale(train$f4)
train$f5_z <- scale(train$f5)
train$f6_z <- scale(train$f6)
train$f7_z <- scale(train$f7)
train$f8_z <- scale(train$f8)
train$f9_z <- scale(train$f9)
train$f10_z <- scale(train$f10)

# Normalizzo i dati di test
test$f1_z <- scale(test$f1)
test$f2_z <- scale(test$f2)
test$f3_z <- scale(test$f3)
test$f4_z <- scale(test$f4)
test$f5_z <- scale(test$f5)
test$f6_z <- scale(test$f6)
test$f7_z <- scale(test$f7)
test$f8_z <- scale(test$f8)
test$f9_z <- scale(test$f9)
test$f10_z <- scale(test$f10)

linModNormalized <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train)

```

## Grafici

#DA AGGIUNGERE SPIEGAZIONE GRAFICO
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Imposta il layout della pagina
par(mfrow = c(2, 2))
# Grafico dei residui standardizzati
plot(linModNormalized, which = 1, col = "skyblue", pch = 16, main = "Residui Standardizzati")
abline(h = 0, col = "red", lty = 2)  # Aggiungi una linea orizzontale a zero nel grafico dei residui standardizzati
# Grafico dei livelli
plot(linModNormalized, which = 2, col = "lightgreen", pch = 16, main = "Grafico dei Livelli")
# Grafico della distribuzione dei residui
plot(linModNormalized, which = 3, col = "pink", pch = 16, main = "Distribuzione dei Residui")
# Grafico di Q-Q plot dei residui
plot(linModNormalized, which = 4, col = "orange", pch = 16, main = "Q-Q Plot dei Residui")
# Aggiungi altre personalizzazioni a piacere, come titoli, etichette degli assi, ecc.
# Ripristina il layout predefinito
par(mfrow = c(1, 1))
```

---

# Test modello lineare

Il processo di test di un modello lineare è cruciale per assicurare la sua affidabilità e accuratezza. Questa fase prevede la valutazione di vari aspetti del modello, come l'adattamento dei dati, la normalità dei residui, l'omoschedasticità e la multicollinearità. Ognuno di questi test fornisce un'indicazione su come il modello si adatta ai dati e su eventuali problemi che potrebbero influenzarne le prestazioni.

### Summary
Per una comprensione immediata del modello, è utile visualizzare il riepilogo tramite `summary(linModNormalized)`. Questo fornisce dettagli sui coefficienti, la significatività statistica e altre metriche chiave.
```{r}
summary (linModNormalized)
```

### R-quadrato
Il test R-quadrato misura la proporzione della varianza totale della variabile dipendente che viene spiegata dal modello di regressione. Un R-quadrato elevato indica che una grande parte della varianza nella variabile dipendente può essere spiegata dalle variabili indipendenti nel modello.  
- **Range:** 0 a 1  
- **Interpretazione:** 0 indica nessuna spiegazione della varianza da parte del modello. 1 indica una spiegazione completa della varianza da parte del modello.
```{r}
summary_linModNormalized <- summary(linModNormalized)
r_squared <- summary_linModNormalized$r.squared
cat("R-quadro:", r_squared, "\n")
```

### R-quadrato Adattato
Il R-quadrato adattato modifica il R-quadrato per tenere conto del numero di predittori nel modello. È più affidabile per i modelli con molteplici variabili indipendenti, poiché penalizza la complessità aggiuntiva, fornendo una misura più realistica della bontà di adattamento.  
- **Range:** Può essere negativo, ma generalmente 0 a 1  
- **Interpretazione:** Valori più vicini a 1 indicano una migliore spiegazione della varianza, considerando il numero di predittori.
```{r}
n <- length(train$o_reb)
k <- length(linModNormalized$coefficients) - 1
adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - k - 1))
cat("R-quadro adattato:", adjusted_r_squared, "\n")
```

### Test Shapiro
Il test di Shapiro-Wilk sui residui è utilizzato per valutare la normalità dei residui in un modello di regressione lineare. La normalità dei residui è un'assunzione critica in molti test statistici. Se i residui non seguono una distribuzione normale, le inferenze sulle stime dei parametri potrebbero essere invalide.  
- **Range:** 0 a 1  
- **Interpretazione:** Valori più vicini a 1 suggeriscono una maggiore probabilità che i residui seguano una distribuzione normale.
```{r}
shapiro.test(residuals(linModNormalized))
```

### Test di omoschedasticità
Il test di Breusch-Pagan verifica l'assunzione di omoschedasticità (varianza costante) dei residui in un modello di regressione. La presenza di eteroschedasticità (varianza non costante) nei residui può portare a stime inefficaci e test statistici non affidabili.  
- **Range:** 0 a $+\infty$  
- **Interpretazione:** Valori più alti indicano una maggiore probabilità di eteroschedasticità. Si confronta il valore del test con un valore critico (ad es., da una distribuzione chi-quadrato) per determinare la significatività.
```{r}
bptest(linModNormalized)
```

### Test di multicollinearità
Il test di multicollinearità verifica se esiste una correlazione elevata tra le variabili indipendenti in un modello di regressione lineare. La multicollinearità può causare problemi nella stima dei coefficienti del modello, rendendo difficili l'interpretazione e la significatività statistica delle variabili indipendenti. Strumenti comuni per rilevarla includono il fattore di inflazione della varianza (VIF) e l'indice di tolleranza.  
- **Range del VIF:** 1 a $+\infty$  
- **Interpretazione:** 1 indica assenza di multicollinearità. Valori superiori a 5 o 10 sono spesso considerati indicatori di multicollinearità significativa.
```{r}
car::vif(linModNormalized)
```

---

# Rimozione outliers e LASSO

Questa sezione si dedica all'identificazione e rimozione degli outliers nel nostro modello lineare normalizzato. Gli outliers possono influenzare notevolmente l'accuratezza e l'affidabilità delle previsioni del modello.  

## Identificazione degli Outliers
Il primo passo è identificare gli outliers. Utilizziamo un grafico di influenza per visualizzare i punti che hanno un impatto maggiore sul modello.
```{r Grafico modello attuale, echo=TRUE, message=FALSE, warning=FALSE}
influencePlot(linModNormalized, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))
title(main = "Influence Plot - Modello 1", col.main = "blue", font.main = 4)

```
Successivamente, calcoliamo i residui del modello e identifichiamo come outliers quei punti la cui distanza dalla media è superiore a un valore soglia, in questo caso due deviazioni standard.
```{r Trovare outliers}
# Il codice implementa l'individuazione degli outliers considerando i residui che superano una soglia moltiplicata per la deviazione standard.

# Calcola i residui dal modello di regressione lineare normalizzato
residui <- residuals(linModNormalized)

# Definisci una soglia per gli outlier
soglia_outlier <- 2
outliers <- which(abs(residui) > soglia_outlier*sd(residui))

# Identifica gli outlier basati sulla soglia definita
outliers <- which(abs(residui) > soglia_outlier * sd(residui))
outliers
```
## Rimozione degli Outliers
Dopo aver identificato gli outliers, procediamo con la loro rimozione dal dataset di allenamento.
```{r Rimozione outliers, echo=TRUE, message=FALSE, warning=FALSE}
if(length(outliers) != 0)
{
  train_1 <- train[-outliers,]
}else
{
  # questo è il caso in cui non siano presenti outliers
  train_1 <- train
}
```
## Confronto dei Modelli Prima e Dopo la Rimozione degli Outliers
Confrontiamo i summary del modello prima e dopo la rimozione degli outliers per valutare l'impatto di questa operazione sulle prestazioni del modello.  

- Prima della Rimozione degli Outliers:  
Visualizziamo il riepilogo del modello originale per avere un punto di riferimento.
```{r Grafici outliers, echo=FALSE, message=FALSE, warning=FALSE}
summary(linModNormalized)
```
- Dopo la Rimozione degli Outliers:  
Ricreiamo il modello e visualizziamo il grafico di influenza per osservare l'impatto della rimozione degli outliers.
```{r, echo=FALSE, message=FALSE, warning=FALSE}
linModNormalized_1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train_1)

summary(linModNormalized_1)
```
grafico di influenza:
```{r}
# Influence plot per il modello lineare normalizzato linModNormalized_1
influencePlot(linModNormalized_1, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))
# Aggiungi un titolo sopra al grafico
title(main = "Influence Plot - Modello 2", col.main = "blue", font.main = 4)

```

### Visualizzazione Residui e Leverage
Questo blocco di codice utilizza la funzione `ols_plot_resid_lev` per visualizzare la relazione tra i residui e il leverage per entrambi i modelli lineari (prima e dopo la rimozione degli outliers). Questa visualizzazione aiuta a identificare ulteriori punti influenti o pattern nei residui che potrebbero influenzare le prestazioni del modello.

```{r}
ols_plot_resid_lev(linModNormalized)
ols_plot_resid_lev(linModNormalized_1)
```

## Conclusione
Entrambi i modelli mostrano prestazioni simili, spiegando circa l'84% della varianza nella variabile dipendente "won". Tuttavia, la rimozione degli outliers ha leggermente migliorato i risultati.

### Utilizzo LASSO

### 1. Preparazione del Modello di Regressione LASSO
Qui prepariamo un modello di regressione LASSO. Il LASSO è utilizzato per la selezione di variabili e la regolarizzazione, aiutando a prevenire l'overfitting e migliorare la generalizzazione del modello.

- Definiamo prima la variabile risposta e la matrice dei predittori.
- Eseguiamo poi la cross-validation k-fold per trovare il valore ottimale di lambda, il parametro di regolarizzazione in LASSO.
- Visualizziamo il plot di MSE (Mean Squared Error) rispetto ai vari valori di lambda.

```{r}
# METODO DI REGRESSIONE LASSO

# define response variable
y <- train_1$won

# define matrix of predictor variables
x <- data.matrix(train_1[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])

# perform k-fold cross-validation to find optimal lambda value
cv_model <- cv.glmnet(x, y, alpha = 1)

# find optimal lambda value that minimizes test MSE
best_lambda <- cv_model$lambda.min
best_lambda

# Grafico personalizzato
plot(cv_model, xvar="lambda", main="", xlab="log(Lambda)", ylab="Mean Squared Error", col="blue", lwd=2)

# Aggiungi un titolo personalizzato con formattazione LaTeX per grassetto e corsivo
title(main=expression(bold(italic("Validazione Incrociata"))), line = 3)
```

```{r, echo = FALSE}
# produce plot of test MSE by lambda value
plot(cv_model)
```

- Addestramento del modello LASSO con il miglior lambda trovato e visualizzazione dei coefficienti.

```{r}
# Fitting the model with the best lambda
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

# Output coefficients and summary
coef(best_model)
```

### 2. Previsione con LASSO e Modello Lineare

Effettuiamo le previsioni utilizzando sia il modello LASSO che quello lineare sui dati di test.

```{r}
# PREDICT

# Predizioni utilizzando il modello Lasso
new <- data.matrix(test[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])
prevLasso <- predict(best_model, s = best_lambda, newx = new)

# Predizioni utilizzando il modello LM (Linear Model)
new <- subset(test, select = c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z"))
prevLM <- predict(linModNormalized_1, newdata = new)

```

### 3. Valutazione delle Prestazioni del Modello
Confrontiamo le prestazioni di entrambi i modelli (LASSO e lineare) attraverso diverse metriche.

- Calcolo del RMS (Root Mean Square)  
Questi blocchi di codice calcolano il RMS, una misura dell'errore di previsione, per il modello LASSO e il modello lineare (LM). Il RMS fornisce una stima dell'errore quadratico medio tra i valori previsti e i valori reali.
```{r}
# RMS Lasso
sqrt(mean((test$won - prevLasso)^2))

# RMS LM
sqrt(mean((test$won - prevLM)^2))
```

- Previsioni Binarie e Matrice di Confusione  
Convertiamo le previsioni del modello LASSO in valori binari (0 o 1) e generiamo una matrice di confusione per confrontare le previsioni con i valori reali. Questo passaggio è utile per valutare la classificazione effettuata dal modello.

```{r}
# Previsioni binarie
prev <- ifelse(prevLasso > 0.5, "1", "0")
prev <- as.factor(as.vector(prev))

# Confusion Matrix: previsioni vs valore reale
table(prev, test$won)
```

### Calcolo delle Metriche di Valutazione  
Calcoliamo diverse metriche di valutazione come l'accuratezza (accuracy), la precisione (precision), la sensibilità (sensitivity), l'F-score e la specificità (specificity). Queste metriche forniscono una valutazione complessiva dell'efficacia del modello.

Ecco come interpretarle:

- **Accuracy** (Accuratezza):
  - **Significato**: La proporzione di previsioni corrette (sia positive che negative) rispetto al totale delle previsioni.
  - **Interpretazione**: Un valore elevato indica che il modello è generalmente accurato nel classificare sia le istanze positive che quelle negative. Tuttavia, in contesti con classi sbilanciate, una alta accuracy può essere fuorviante.
- **Precision** (Precisione):
  - **Significato**: La proporzione di previsioni positive corrette rispetto al totale delle previsioni positive fatte dal modello.
  - **Interpretazione**: Misura la qualità delle previsioni positive del modello. Una alta precisione indica che una grande percentuale delle previsioni positive del modello è effettivamente corretta.
- **Sensitivity** (Sensibilità) o Recall:
  - **Significato**: La proporzione di veri positivi rispetto al totale delle istanze effettivamente positive.
  - **Interpretazione**: Indica quanto bene il modello è in grado di identificare le istanze positive. Un valore alto significa che il modello cattura bene la maggior parte delle istanze positive.
- **F-score**:
  - **Significato**: Una media armonica di precision e sensitivity. 
  - **Interpretazione**: Combina la precisione e la sensibilità in un singolo numero. È utile quando si desidera un equilibrio tra precisione e sensibilità, specialmente in contesti con distribuzioni di classe disuguali.
- **Specificity** (Specificità):
  - **Significato**: La proporzione di veri negativi rispetto al totale delle istanze effettivamente negative.
  - **Interpretazione**: Misura quanto bene il modello è in grado di identificare le istanze negative. Una alta specificità indica che il modello è efficace nel riconoscere le istanze non positive.

```{r}
cm <- table(prev, test$won)

# Metriche di Valutazione
accuracy <- sum(cm[1], cm[4]) / sum(cm[1:4])
precision <- cm[4] / sum(cm[4], cm[2])
sensitivity <- cm[4] / sum(cm[4], cm[3])
fscore <- (2 * (sensitivity * precision)) / (sensitivity + precision)
specificity <- cm[1] / sum(cm[1], cm[2])

```

```{r, echo = FALSE}
sprintf("Accuratezza: %f", accuracy)
sprintf("Precisione: %f", precision)
sprintf("Sensibilità: %f", sensitivity)
sprintf("F-score: %f", fscore)
sprintf("Specificità: %f", specificity)
```

#TEST ANOVA
```{r}
# Esecuzione di un test ANOVA per la variabile 'confID' come predittore
# Supponiamo che 'won' sia la variabile dipendente
resp_conf <- anova(lm(won ~ confID, data = train_1))

# Verifica se la variabile 'confID' ha un effetto significativo sulle vittorie
if (resp_conf["confID", "Pr(>F)"] < 0.05) {
  print("Si rifiuta l'ipotesi nulla perché la variabile Conference ha un effetto sulle vittorie. Posso inserire a modello la variabile.")
} else {
  print("Si accetta l'ipotesi nulla perché la variabile Conference non ha un effetto sulle vittorie. Non posso inserire a modello la variabile.")
}

# Esecuzione di un test ANOVA per la variabile 'divID' come predittore
# Supponiamo che 'won' sia la variabile dipendente
resp_div <- anova(lm(won ~ divID, data = train_1))

# Verifica se la variabile 'divID' ha un effetto significativo sulle vittorie
if (resp_div["divID", "Pr(>F)"] < 0.05) {
  print("Si rifiuta l'ipotesi nulla perché la variabile Division ha un effetto sulle vittorie. Posso inserire a modello la variabile.")
  div <- TRUE
} else {
  print("Si accetta l'ipotesi nulla perché la variabile Division non ha un effetto sulle vittorie. Non posso inserire a modello la variabile.")
  div <- FALSE
}

```

#EFFETTI INTERAZIONE

```{r}
# Verifica del valore di 'div' per costruire il modello appropriato
if (div) {
  linModNormalized1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + divID + f1_z:f2_z + f4_z:divID, data = train_1)
} else {
  linModNormalized1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + f1_z:f2_z + f4_z:divID, data = train_1)
}

# Estrazione del riassunto del modello
riassunto <- summary(linModNormalized1)

# Estrazione dei nomi delle righe dal riassunto del modello
nomi_righe <- rownames(riassunto$coefficients)

# Nomi delle righe da escludere
nomi_da_escludere <- c("(Intercept)", "f1_z:f2_z", "f4_z:divIDCD", "f4_z:divIDMW", "f4_z:divIDNW", "f4_z:divIDPC", "f4_z:divIDSE", "f4_z:divIDSW", "divIDCD", "divIDMW", "divIDNW", "divIDPC", "divIDSE", "divIDSW")

# Creazione di un vettore con i nomi delle righe da utilizzare
nomi_righe_da_utilizzare <- setdiff(nomi_righe, nomi_da_escludere)

# Aggiunta della variabile 'divID' se presente nei nomi delle righe
if ("divIDCD" %in% nomi_righe) {
  nomi_righe_da_utilizzare <- append(nomi_righe_da_utilizzare, c("divID"))
}

# Indici di inizio e fine per le p-values della variabile 'divID'
div_indice_inizio <- which(rownames(riassunto$coefficients) == "f4_z:divIDCD")
div_indice_fine <- which(rownames(riassunto$coefficients) == "f4_z:divIDSW")

# Estrazione delle p-values della variabile 'divID'
div_p_values <- riassunto$coefficients[div_indice_inizio:div_indice_fine, "Pr(>|t|)"]

# Aggiunta di 'f4_z:divID' se la media delle p-values è inferiore a 0.05
if (mean(div_p_values) < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f4_z:divID"))
}

# Aggiunta di 'f1_z:f2_z' se la sua p-value è inferiore a 0.05
if (riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f1_z:f2_z"))
}

# Se nessuna delle condizioni precedenti è soddisfatta, utilizza solo le variabili esistenti
if (!(mean(div_p_values) < 0.05) && !(riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05)) {
  variabili <- nomi_righe_da_utilizzare
}

# Creazione della formula significativa per il modello
formula_significativa <- as.formula(paste("won ~", paste(variabili, collapse = " + ")))

# Costruzione del nuovo modello lineare con la formula significativa
linModNormalized1 <- lm(formula_significativa, data = train_1)

# Visualizzazione del riassunto del nuovo modello
summary(linModNormalized1)

```

# Può aiutare l’uso della POISSON?

```{r}
# Questo codice addestra un modello di regressione generalizzata di Poisson (linModNormalized2_pois) utilizzando la stessa specifica del modello lineare (linModNormalized2). Successivamente,    vengono ottenuti e combinati i coefficienti di entrambi i modelli in un unico dataframe per una facile comparazione.

# Creazioni di un modello di regressione generalizzata di Poisson
linModNormalized1_pois = glm(formula_significativa, family=poisson(link=log), data = train_1)
summary(linModNormalized1_pois)

# Ottenimento dei coefficienti per ambo i modelli
normal = coefficients(linModNormalized1)
poisson = exp(coefficients(linModNormalized1_pois))

# Combinazione dei coefficienti in un unico dataframe
coefficients_table <- cbind(normal, poisson)

coefficients_table



#Considerazioni Generali:
# È importante notare che gli effetti delle variabili possono essere interpretati in modo diverso a seconda della distribuzione scelta per il modello. La scelta tra distribuzione normale e di   Poisson dipende dalla natura della tua variabile dipendente e dai tuoi obiettivi di modellazione. Nel contesto di modelli di regressione, è sempre buona pratica verificare l'adeguatezza del   modello esaminando i residui, eseguendo test diagnostici e valutando la bontà di adattamento. L'interpretazione dei coefficienti dovrebbe essere fatta considerando la scala appropriata per    la distribuzione utilizzata (lineare per la normale, logaritmica per la Poisson). Se stai cercando di prevedere il numero di vittorie, la distribuzione di Poisson potrebbe essere più
# appropriata per variabili conteggio come questa. Tuttavia, è sempre necessario verificare l'adeguatezza del modello ai dati specifici.

```

---

# Conclusioni

