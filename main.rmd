---
title: "Progetto Statistica - Dataset: Basketball Teams - Gruppo Lampedusa"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
author: "Gruppo Lampedusa"
editor_options: 
  markdown: 
    wrap: 72
---

### Indice

1.  Presentazione problema
2.  Analisi dati iniziale e grafici
    a.  Test
3.  Divisione sample/train
4.  Presentazione modello lineare
    a.  Formule
    b.  Modello lineare
    c.  Grafici
    d.  Modello lineare normalizzato
        i.  Grafici
5.  Test modello lineare
    a.  Grafici
    b.  Rimozione outliers
        i.  Grafici

---

# Progetto numero 5

NBA moderna (1976-2011): VARIABILE DIPENDENTE: numero di vittorie in
stagione COVARIATE: tutte le altre (o uno specifico insieme di queste,
in base all'obiettivo di analisi) Considerare solo le squadre che hanno
giocato 82 partite (dataset\$games==82)

---

# Presentazione problema

Con questo report ci siamo interessati allo studio di un modello lienare
predittivo per le vittorie, basato sul numero di rimbalzi annuali
effettuati dalle squadre nel campionato NBA. Vengono prese in
considerazione solo le squadre con almeno 82 partite disputate, con
riferimento agli anni dal 1976 al 2011.

La previsione del modello lineare e' basata sull'uso di coefficienti
ideati per essere il piu possibile significativi e conforme alla nostra
idea di incidenza sulle vittorie di certe variabili riespetto ad altre.

I dettagli su come eseguire il programma e utilizzare la funzione
predittiva si trovano direttamente di seguito, assieme al processo di
realizzazione e verifica del modello stesso.

```{r Inizializzazione, message=FALSE, warning=FALSE, include=FALSE}

library(here)
library(corrplot)
library(nortest)
library(lmtest)
library(car)
library(plotly)
library(heatmaply)
library(ggheatmap)
library(ggplot2)
library(viridis)
library(glmnet)
library(highcharter)
library(reshape2)
library(RColorBrewer)
library(tidyr)
library(gridExtra)
library(dplyr)

knitr::opts_knit$set(root.dir = here("0_Materiale"))

```

---

# Analisi dati iniziale e grafici

TODO: aggiungere descrizione per ogni grafico

```{r Lettura dati dal dataset}
filepath <- here("0_Materiale", "basketball_teams.txt")
dataset <- read.delim(filepath)
# str(dataset)

FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio 

df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]
df$reb <- df$o_reb + df$d_reb

# summary(df)
```

## Correlazione dati

```{r Analisi correlazione dati - corrplot, echo=FALSE, warning = FALSE, message = FALSE}

# CORRPLOT

data_subset <- df[, c(11:40, 54)]
cor_matrix <- cor(data_subset, use = "complete.obs")  

cor_data <- melt(cor_matrix)
names(cor_data) <- c("Variable1", "Variable2", "Correlation")

# Create the heatmap
p <- plot_ly(data = cor_data, x = ~Variable1, y = ~Variable2, z = ~Correlation, 
             type = "heatmap", 
             colors = viridis(n = 1024,  option = "magma"),
             hoverinfo = "x+y+z") %>% 
  layout(title = 'Correlation Matrix Heatmap',
         xaxis = list(tickangle = 45),
         yaxis = list(tickangle = 45),
         autosize = TRUE)
p

```

## Analisi vittorie

```{r Analisi distribuzione vittorie - boxplot, warning=FALSE, echo = FALSE, message = FALSE, message = FALSE}

# BOXPLOT

aggregated_data <- df %>%
  select(tmID, year, won) %>%
  group_by(tmID, year) %>%
  summarize(
    won = mean(won, na.rm = TRUE), 
  )

reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(won), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")

fig <- plot_ly()


for (i in 2:ncol(reshaped_data)) {
    current_column_data <- reshaped_data[[i]]
    fig <- fig %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

(fig)

```

```{r, Analisi distribuzione vittorie - istogramma, warning = FALSE, echo = FALSE, message = FALSE}

# ISTOGRAMMA

histogram <- plot_ly(df, x = ~won, type = "histogram", marker = list(color = "skyblue", line = list(color = "white", width = 0.5))) %>%
  layout(title = "Distribuzione delle Vittorie",
         xaxis = list(title = "Numero di Vittorie"),
         yaxis = list(title = "Frequenza"),
         barmode = "overlay") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "lines", line = list(color = "red", width = 2), name = "Media")

# Visualizza l'istogramma interattivo
histogram

```

```{r, Analisi distribuzione vittorie - densita, warning = FALSE, echo = FALSE, message = FALSE}

# DENSITA

density_plot <- density(df$won)

# Crea il plot di densità con plot_ly
density_interactive <- plot_ly(x = density_plot$x, y = density_plot$y, type = "scatter", mode = "lines", 
                               line = list(color = "skyblue", width = 2)) %>%
  layout(title = list(text = "Distribuzione di Densità delle Vittorie", x = 0.5),
         xaxis = list(title = "Numero di Vittorie"),
         yaxis = list(title = "Densità"),
         showlegend = FALSE) %>%
  add_trace(x = c(mean(df$won), mean(df$won)), y = c(0, max(density_plot$y)), 
            type = "scatter", mode = "lines", line = list(color = "red", width = 2),
            name = "Media") %>%
  add_trace(x = mean(df$won), y = max(density_plot$y), type = "scatter", mode = "markers", 
            marker = list(color = "red", size = 8)) %>%
  add_annotations(text = sprintf("Media: %.2f", mean(df$won)), x = mean(df$won), y = max(density_plot$y) * 1.05, 
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2, 
                  ax = 0, ay = -40, xshift = 10, yshift = -10)

# Visualizza il plot di densità interattivo
density_interactive

```

## Analisi rimbalzi

TODO: aggiungere descrizione per ogni grafico

```{r Plot densita per ogni variabile, echo = FALSE}
df_reb <- subset(df, select = c("o_oreb", "o_dreb", "o_reb", "d_oreb", "d_dreb", "d_reb", "won"))
  
par(mfrow = c(2, 3))  # Imposta il layout a 2 righe e 3 colonne

for (variables in 1:(dim(df_reb)[2]-1)){
  thisvar = df_reb[,variables]
  d <- density(thisvar)
  xmin <- floor(min(thisvar))
  xmax <- ceiling(max(thisvar))
  
  # Crea il plot della densità con stile accattivante
  plot(d, main = names(df_reb)[variables], xlab = "", col = "skyblue", lwd = 1, xlim = c(xmin, xmax), ylim = c(0, max(d$y)*1.1))

  # Aggiungi la distribuzione normale teorica ideale in rosso
  x <- seq(xmin, xmax, length = 100)
  lines(x, dnorm(x, mean = mean(thisvar), sd = sd(thisvar)), col = "red", lwd = 1)

  # Aggiungi griglia per migliorare la leggibilità
  grid()
}

# Aggiungi titolo
title("Density plots with Normal Distribution", line = -17, cex.main = 2, outer = FALSE)


```

```{r Heatmap rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}

values <- aggregate(cbind(reb, o_oreb, o_dreb, d_oreb, d_dreb, o_reb, d_reb, won) ~ tmID, data = df, FUN = sum)

heatmap_df <- subset(values, select = -c(o_oreb, o_dreb, d_oreb, d_dreb, won, reb))
rownames(heatmap_df) <- heatmap_df$tmID
heatmap_df <- heatmap_df[,-1]

heatmaply(
 heatmap_df,
 colors = viridis(n = 256,  option = "magma"),
 k_col = 2,
 k_row = 4,
)
```

```{r Istogramma stacked rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
plot_ly(values, x = ~tmID, y = ~o_reb, type = 'bar', name = 'Rimbalzi offensivi', marker = list(color = '#FFAFA1')) %>%
  add_trace(y = ~d_reb, name = 'Rimbalzi difensivi', marker = list(color = '#b2fff8')) %>%
  layout(yaxis = list(title = 'Valori'), barmode = 'stack')
```

```{r Istogramma rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
plot_ly(data = df, x = ~reb, type = "histogram",
        marker = list(color = 'lightblue', line = list(color = 'black', width = 1)),
        nbinsx = 20) %>% 
  layout(title = 'Istogramma dei Rimbalzi',
         xaxis = list(title = 'Rimbalzi'),
         yaxis = list(title = 'Frequenza'),
         shapes = list(type = "line", 
                       x0 = mean(df$reb), x1 = mean(df$reb),
                       y0 = 0, y1 = 215,
                       line = list(color = "red", width = 2, dash = "dash")),
         yaxis = list(autorange = TRUE))
```

```{r Densita rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
density_data <- density(df$reb)
mu <- mean(df$reb)
sigma <- sd(df$reb)
normal_data <- dnorm(density_data$x, mean = mu, sd = sigma)

p <- plot_ly(x = density_data$x, y = density_data$y, type = 'scatter', mode = 'lines',
             line = list(color = 'blue', width = 2),
             name = "Densità rimbalzi totale") %>%
  layout(title = "Densità dei Rimbalzi",
         xaxis = list(title = "Rimbalzi"),
         yaxis = list(title = "Density", autotick = TRUE, autorange = TRUE))

p <- add_trace(p, x = density_data$x, y = normal_data, mode = 'lines',
               line = list(color = 'green', width = 2),
               fill = "tozeroy", fillcolor = "rgba(0, 255, 0, 0.2)",
               name = "Dist normale ideale")

p <- add_trace(p, x = c(mu, mu), y = c(0, max(density_data$y)),
               mode = 'lines', line = list(color = 'red', width = 2, dash = 'dash'),
               name = "Media")

(p)
```

```{r Boxplot rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
aggregated_data <- df %>%
  select(tmID, year, o_reb, d_reb) %>%
  group_by(tmID, year) %>%
  summarize(
    o_reb = mean(o_reb, na.rm = TRUE), 
    d_reb = mean(d_reb, na.rm = TRUE)
  )

reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(o_reb, d_reb), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")

fig <- plot_ly()


for (i in 2:ncol(reshaped_data)) {
    current_column_data <- reshaped_data[[i]]
    fig <- fig %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

(fig)
```

```{r Corrplot rimbalzi, warning = FALSE, message = FALSE, echo = FALSE}
data_subset <- df[, c("reb", "o_reb", "d_reb")]
cor_matrix <- cor(data_subset)

rownames(cor_matrix) <- colnames(data_subset)
colnames(cor_matrix) <- colnames(data_subset)

cor_data <- reshape2::melt(cor_matrix)
names(cor_data) <- c("Var1", "Var2", "Corr")

dimnames(cor_matrix) <- list(rownames(cor_matrix), colnames(cor_matrix))
data_for_plotly <- as.data.frame(as.table(cor_matrix))

p <- plot_ly(data = cor_data, 
             x = ~Var1, 
             y = ~Var2, 
             z = ~Corr, 
             type = "heatmap", 
             colors = colorRampPalette(c("#4575b4", "#91bfdb", "#e0f3f8", "#fee08b", "#d73027"))(100),
             hoverinfo = "x+y+z") %>% 
  layout(title = 'Correlation Matrix',
         xaxis = list(title = "", tickangle = 45, side = "bottom", automargin = TRUE),
         yaxis = list(title = "", automargin = TRUE),
         autosize = TRUE)

cor_values <- round(as.matrix(cor_matrix), 2)  # Round for readability
for (i in seq_len(nrow(cor_matrix))) {
  for (j in seq_len(ncol(cor_matrix))) {
    p <- p %>% add_annotations(
      x = rownames(cor_matrix)[i],
      y = colnames(cor_matrix)[j],
      text = as.character(cor_values[i, j]),
      showarrow = FALSE,
      font = list(color = ifelse(cor_values[i, j] < 0.5, "white", "black"))
    )
  }
}

(p)
```

## Test

### Test Anderson-Darling sui rimbalzi

TODO: aggiungere descrizione test

```{r, warning=FALSE}
ad.test(df$reb)
```

Con un livello di significatività ($\alpha$) di 0.01 e un p-value molto
piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per
i dati della variabile df\$reb, puoi concludere che hai sufficiente
evidenza statistica per respingere lipotesi nulla che i dati seguono una
distribuzione normale.Con il tuo livello di significatività del 0.01 e
il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di
significatività, quindi respingeresti lipotesi nulla. Questo suggerisce
che i dati nella variabile df\$reb non seguono una distribuzione normale
al livello di significatività del 0.01. In termini più pratici, hai
abbastanza evidenza statistica per concludere che la variabile df\$reb
non segue una distribuzione normale basandoti sui risultati del test di
Anderson-Darling.

### Test Kolmogorov-Smirnov

TODO: Aggiungere descrizione test

```{r, warning=FALSE}
ks.test(df$reb, "pnorm")
```

Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a
campione singolo sui dati contenuti nella variabile df\$reb. Il test KS
confronta la distribuzione empirica dei tuoi dati con una distribuzione
teorica (spesso una distribuzione uniforme). In breve, il risultato
suggerisce che i tuoi dati non seguono la distribuzione teorica
presunta, e cè un elevata probabilità che la differenza osservata sia
statisticamente significativa.

### Test Shapiro-Wilk

TODO: Aggiungere descrizione test

```{r, warning=FALSE}
ks.test(df$reb, "pnorm")
```

In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi
dati nella variabile df\$reb non seguono una distribuzione normale.
Questo è supportato dal valore basso del p-value, il quale suggerisce
che la differenza tra la distribuzione dei tuoi dati e una distribuzione
normale è statisticamente significativa.

---

# Divisione train/test

Dividiamo ora il nostro dataset in 2 parti, la parte train, ossia la parte che utilizzeremo per "addestrare" il nostro modello lineare, e la parte test, ossia una parte del dataset su cui testeremo il nostro modello lineare
```{r}
sample <- sample(c(TRUE, FALSE), size = nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train_df <- df[sample, ]
test_df <- df[!sample, ]
```

---
 
# Presentazione modello lineare

## Modello: L'importanza dei rimbalzi

TODO: Aggiungere descrizione modello lineare

## Formule

TODO: Aggiungere breve testo introduttivo

$\text{Formula1} = \frac{\text{Rimbalzi offensivi in attacco}}{\text{Tiri sbagliati su azione}}$
Rappresenta la capacità della squadra di ripossesso della palla dopo un tiro che non va a canestro e colpisce il tabellone.

$\text{Formula2} = \frac{\text{Rimbalzi difensivi in difesa presi}}{\text{Tiri sbagliati su azione degli avversari}}$
Rappresenta la capacità della squadra di impossessarsi della palla dopo un tiro sbagliato della squadra avversaria che colpisce il tabellone, che troviamo un buon stimatore della capacità di contropiede della squadra.

$\text{Formula3} = \frac{\text{Palle riprese in attacco} + 1.5 \times \text{Palle riprese in difesa}}{\text{Palle perse in attacco} + 2 \times \text{Rimbalzi subiti in difesa}}$
Rappresenta il rapporto tra le palle riprese nei rimbalzi (sia offensivi che difensivi) rispetto alle palle perse nei rimbalzi (sia offensivi che difensivi). I coefficienti sono stati scelti in base a ciò che riteniamo più importante in una partita, ossia la difesa del proprio canestro.

$\text{Formula4} = (\text{Palle riprese in attacco - Palle perse in attacco}) + 1.5*(\text{Palle riprese in difesa - Palle perse in difesa})$
Cresce all'aumentare dei rimbalzi ottenuti e diminuisce all'aumentare dei rimbalzi subiti, considerando anche un coefficiente che da particolare importanza alla difesa.

$\text{Formula5} = \frac{(\frac{\text{Rimbalzi subiti in difesa}}{\text{Palle perse in difesa}})}{(\frac{\text{Rimbalzi subiti in attacco}}{\text{Palle perse in attacco}})}$
Mostra quanto siano influenti i rimbalzi nel rapporto tra le palle perse dalla squadra e le palle perse dagli avversari.

## Modello lineare sul dataframe train

TODO: Aggiungere descrizione

- o_oreb = Rimbalzi ottenuti in attacco 
- o_dreb = Rimbalzi subiti in attacco 
- o_reb  = Totale rimbalzi in attacco 
- d_oreb = Rimbalzi subiti in difesa 
- d_dreb = Rimbalzi ottenuti in difesa 
- d_reb  = Totale rimbalzi in difesa 

```{r Modello lineare su train, warning = FALSE}

train_df$f1 <- (train_df$o_oreb)/(train_df$o_fga-train_df$o_fgm)
train_df$f2 <- (train_df$d_dreb)/(train_df$d_fga-train_df$d_fgm)
train_df$f3 <- (train_df$o_oreb + 1.5 * train_df$d_dreb)/(train_df$o_dreb + 2 * train_df$d_oreb)
train_df$f4 <- (train_df$o_oreb - train_df$o_dreb) + 1.5 * (train_df$d_dreb - train_df$d_oreb)
train_df$f5 <- (train_df$d_oreb / train_df$d_to) / (train_df$o_dreb / train_df$o_to)

train_lm <- lm(won ~ f1 + f2 + f3 + f4 + f5, data = train_df)
summary (train_lm)

```

## Grafici

TODO: Aggiungere presentazione grafici

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Funzione per creare il plot di Residuals vs Fitted (Residui vs. Valori Previsti)
res_vs_fitted <- ggplot(train_lm, aes(.fitted, .resid)) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Residuals vs Fitted", x = "Fitted Values", y = "Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot QQ dei Residui
qq_plot <- ggplot(train_lm, aes(sample = .stdresid)) +
  stat_qq(color = "skyblue", size = 2) +
  stat_qq_line(color = "red", size = 1) +
  labs(title = "QQ Plot dei Residui", x = "Quantiles teorici", y = "Quantiles osservati") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot Scale-Location
scale_location_plot <- ggplot(train_lm, aes(.fitted, sqrt(abs(.stdresid)))) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Scale-Location Plot", x = "Fitted Values", y = "sqrt(|Standardized Residuals|)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot Residuals vs Leverage (Residui vs. Leverage)
res_vs_leverage <- ggplot(train_lm, aes(.hat, .stdresid)) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Residuals vs Leverage", x = "Leverage", y = "Standardized Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

plotly_res_vs_fitted <- ggplotly(res_vs_fitted)
plotly_qq_plot <- ggplotly(qq_plot)
plotly_scale_location_plot <- ggplotly(scale_location_plot)
plotly_res_vs_leverage <- ggplotly(res_vs_leverage)

subplot(plotly_res_vs_fitted, plotly_qq_plot, plotly_scale_location_plot, plotly_res_vs_leverage)
```

---

# Modello lineare normalizzato sul dataframe train

TODO: Introduzione a perché normalizzare i dati

```{r, warning = FALSE}

train_df$f1_z <- scale(train_df$f1)
train_df$f2_z <- scale(train_df$f2)
train_df$f3_z <- scale(train_df$f3)
train_df$f4_z <- scale(train_df$f4)
train_df$f5_z <- scale(train_df$f5)

train_lm_z <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z, data = train_df)
summary(train_lm_z)

```

## Grafici

```{r echo = FALSE, message = FALSE, message=FALSE, warning=FALSE}
# Funzione per creare il plot di Residuals vs Fitted (Residui vs. Valori Previsti)
res_vs_fitted <- ggplot(train_lm_z, aes(.fitted, .resid)) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Residuals vs Fitted", x = "Fitted Values", y = "Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot QQ dei Residui
qq_plot <- ggplot(train_lm_z, aes(sample = .stdresid)) +
  stat_qq(color = "skyblue", size = 2) +
  stat_qq_line(color = "red", size = 1) +
  labs(title = "QQ Plot dei Residui", x = "Quantiles teorici", y = "Quantiles osservati") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot Scale-Location
scale_location_plot <- ggplot(train_lm_z, aes(.fitted, sqrt(abs(.stdresid)))) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Scale-Location Plot", x = "Fitted Values", y = "sqrt(|Standardized Residuals|)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

# Funzione per creare il plot Residuals vs Leverage (Residui vs. Leverage)
res_vs_leverage <- ggplot(train_lm_z, aes(.hat, .stdresid)) +
  geom_point(color = "skyblue", alpha = 0.7, size = 3) +
  geom_smooth(se = FALSE, color = "red", method = "loess", size = 1) +
  labs(title = "Residuals vs Leverage", x = "Leverage", y = "Standardized Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"))

plotly_res_vs_fitted <- ggplotly(res_vs_fitted)
plotly_qq_plot <- ggplotly(qq_plot)
plotly_scale_location_plot <- ggplotly(scale_location_plot)
plotly_res_vs_leverage <- ggplotly(res_vs_leverage)

subplot(plotly_res_vs_fitted, plotly_qq_plot, plotly_scale_location_plot, plotly_res_vs_leverage)
```

---

# Test modello lineare

TODO Aggiungere introduzione

### Summary
```{r}
summary (train_lm_z)
```

### R-quadrato
```{r}
summary_linModNormalized <- summary(train_lm_z)
r_squared <- summary_linModNormalized$r.squared
cat("R-squared:", r_squared, "\n")
```

### R-quadrato Adattato
```{r}
n <- length(df$o_oreb)
k <- length(train_lm_z$coefficients) - 1
adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - k - 1))
cat("Adjusted R-squared:", adjusted_r_squared, "\n")
```

### Test Shapiro
```{r}
shapiro.test(residuals(train_lm_z))
```

### Test di omoschedasticità
```{r}
bptest(train_lm_z)
```

### Test di multicollinearità
```{r}
car::vif(train_lm_z)
```

---

# Modello lineare sul dataframe test

## Grafici

---

# LASSO

## Rifare test

