---
title: "ProgettoLampedusa"
date: "`r Sys.Date()`"
output:
  html_document: default
  pdf_document: default
  word_document: default
author: "Lampedusa_Group"
editor_options: 
  markdown: 
    wrap: 72
---


```{r setup, include=TRUE, warning=FALSE, message=FALSE, error=FALSE}

# Carica le librerie necessarie
library(here)         # Gestione dei percorsi dei file
library(corrplot)     # Visualizzazione matrice di correlazione
library(nortest)      # Test di normalità
library(lmtest)       # Test diagnostici per modelli lineari
library(car)          # Test di collinearità e altri test per modelli lineari
library(plotly)       # Visualizzazioni interattive
library(heatmaply)    # Heatmap interattivo
library(ggheatmap)    # Heatmap con ggplot2
library(gridExtra)    # Organizzazione di grafici con grid
library(ggfortify)    # Visualizzazioni grafiche per modelli statistici
library(olsrr)        # Diagnostica e grafici per modelli di regressione
library(ggplot2)      # Creazione di grafici con ggplot2
library(viridis)      # Colormaps viridis
library(glmnet)       # Modelli di regressione con penalizzazione lasso ed elastic net
library(highcharter)  # Creazione di grafici interattivi con Highcharts
library(reshape2)     # Manipolazione dati
library(RColorBrewer) # Colormaps
library(tidyr)        # Manipolazione dati
library(dplyr)        # Manipolazione dati

# Configura il percorso di root per la generazione di report
knitr::opts_knit$set(root.dir = here("0_Materiale"))

```


## INIZIALIZZAZIONE DATI E GRAFICI DATI
```{r}

# Leggi il dataset da un file di testo
dataset <- read.delim("basketball_teams.txt")

# Definisci il primo e l'ultimo anno del range da considerare per lo studio
FIRST <- 1976
LAST <- 2011

# Filtra il dataset secondo le condizioni specificate
df <- dataset[dataset$lgID == "NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games == 82,]

# Converti la colonna lgID in un fattore per consentire la generazione di variabili dummy
dataset$lgID <- as.factor(dataset$lgID)

# Stampiamo un riassunto statistico del dataframe filtrato
summary(df)

```


## STUDIO DATI RELATIVI AI RIMBALZI
```{r}

# o_oreb = Rimbalzi ottenuti in attacco
# o_dreb = Rimbalzi subiti in attacco
# o_reb  = totale rimbalzi in attacco
# d_oreb = Rimbalzi subiti in difesa
# d_dreb = Rimbalzi ottenuti in difesa
# d_reb  = totale rimbalzi in difesa

# Seleziona le colonne pertinenti dal dataframe
df_reb <- subset(df, select = c("o_oreb", "o_dreb", "o_reb", "d_oreb", "d_dreb", "d_reb", "won"))

# Imposta il layout a 2 righe e 3 colonne per i grafici di densità
par(mfrow = c(2, 3))

# Ciclo per generare grafici di densità per ciascuna variabile di interesse
for (variables in 1:(dim(df_reb)[2]-1)) {
  thisvar <- df_reb[, variables]
  d <- density(thisvar)
  xmin <- floor(min(thisvar))
  xmax <- ceiling(max(thisvar))
  
  # Crea il plot della densità con stile accattivante
  plot(d, main = names(df_reb)[variables], xlab = "", col = "blue", lwd = 1.5, xlim = c(xmin, xmax), ylim = c(0, max(d$y)*1.1))
  
  # Aggiunta la distribuzione normale teorica ideale in rosso
  x <- seq(xmin, xmax, length = 100)
  lines(x, dnorm(x, mean = mean(thisvar), sd = sd(thisvar)), col = "red", lwd = 1.5)  # Modifica lo spessore delle linee
  
  # Aggiunta griglia per migliorare la leggibilità
  grid()
}

# Aggiunta titolo in grassetto e corsivo, con spessore del testo modificato
title(bquote(bold(italic("Density plots with Normal Distribution"))), line = -17, cex.main = 2, outer = TRUE)

# Stampa percentuale di valori non zero per ciascuna variabile di interesse
print(paste("Percentage non-zero o_oreb: ", round(length(which(df_reb$o_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_dreb: ", round(length(which(df_reb$o_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero o_reb: ", round(length(which(df_reb$o_reb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_oreb: ", round(length(which(df_reb$d_oreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_dreb: ", round(length(which(df_reb$d_dreb > 0)) / dim(df_reb)[1] * 100, 2)))
print(paste("Percentage non-zero d_reb: ", round(length(which(df_reb$d_reb > 0)) / dim(df_reb)[1] * 100, 2)))


```


## GRAFICI DEI DATI RELATIVI AI RIMBALZI
```{r}

# SANDBOX

# Creazione di un vettore per archiviare un elenco di squadre
teams <- c()

# Creazione di una nuova variabile 'reb' come somma di 'o_reb' e 'd_reb'
df$reb <- c(df$o_reb + df$d_reb)

# Visualizzazione di un riepilogo statistico sulla variabile 'reb'
summary(df$reb)

# Loop per ottenere un elenco unico di squadre
for (team in df$tmID) {
  teams <- unique(c(teams, team))
}

# Ordinamento delle squadre
teams <- sort(teams)

# Calcolo di valori aggregati per le variabili specificate
values <- aggregate(cbind(reb, o_oreb, o_dreb, d_oreb, d_dreb, o_reb, d_reb, won) ~ tmID, data = df, FUN = sum)

# Creazione di dati per una distribuzione normale
x <- seq(-4, 4, by = 0.01)
y <- dnorm(x, mean = 0, sd = 1)
normal <- data.frame(x, y)



# ISTOGRAMMA INTERATTIVO

histogram <- plot_ly(data = df, x = ~reb, type = "histogram",
        marker = list(color = 'skyblue', line = list(color = 'black', width = 1)),
        nbinsx = 20, legendgroup = "Rimbalzi", name = "Campione") %>% 
  add_trace(type = "scatter", mode = "lines",
            x = c(mean(df$reb), mean(df$reb)),
            y = c(0, 215),
            line = list(color = "red", width = 2, dash = "dash"),
            name = "Media") %>%
  layout(title = list(text = "<b><i>Istogramma dei Rimbalzi</i></b>", pad = 10),
         xaxis = list(title = '<b><i>Rimbalzi</i></b>'),
         yaxis = list(title = '<b><i>Frequenza</i></b>'),
         legend = list(title = "<b><i>Legenda</i></b>", tracegrouporder = "reversed"))

(histogram)



# PLOT DI DENSITA CON SOVRAPPOSIZIONE DI UNA NORMALE IDEALE

density_data <- density(df$reb)
mu <- mean(df$reb)
sigma <- sd(df$reb)
normal_data <- dnorm(density_data$x, mean = mu, sd = sigma)

density_plot <- plot_ly(x = density_data$x, y = density_data$y, type = 'scatter', mode = 'lines',
             line = list(color = 'blue', width = 2),
             name = "Densità rimbalzi totale") %>%
  layout(title = "Densità dei Rimbalzi",
         xaxis = list(title = "Rimbalzi"),
         yaxis = list(title = "Density", autotick = TRUE, autorange = TRUE))

density_plot <- add_trace(density_plot, x = density_data$x, y = normal_data, mode = 'lines',
               line = list(color = 'green', width = 2),
               fill = "tozeroy", fillcolor = "rgba(0, 255, 0, 0.2)",
               name = "Dist normale ideale")

density_plot <- add_trace(density_plot, x = c(mu, mu), y = c(0, max(density_data$y)),
               mode = 'lines', line = list(color = 'red', width = 2, dash = 'dash'),
               name = "Media")

(density_plot)



# CORRPLOT

data_subset <- df[, c("reb", "o_reb", "d_reb")]
cor_matrix <- cor(data_subset)

rownames(cor_matrix) <- colnames(data_subset)
colnames(cor_matrix) <- colnames(data_subset)

cor_data <- reshape2::melt(cor_matrix)
names(cor_data) <- c("Var1", "Var2", "Corr")

dimnames(cor_matrix) <- list(rownames(cor_matrix), colnames(cor_matrix))
data_for_plotly <- as.data.frame(as.table(cor_matrix))

cor_plot <- plot_ly(data = cor_data, 
             x = ~Var1, 
             y = ~Var2, 
             z = ~Corr, 
             type = "heatmap", 
             colors = colorRampPalette(c("#4575b4", "#91bfdb", "#e0f3f8", "#fee08b", "#d73027"))(100),
             hoverinfo = "x+y+z") %>% 
  layout(title = 'Correlation Matrix',
         xaxis = list(title = "", tickangle = 45, side = "bottom", automargin = TRUE),
         yaxis = list(title = "", automargin = TRUE),
         autosize = TRUE)

cor_values <- round(as.matrix(cor_matrix), 2)  # Round for readability
for (i in seq_len(nrow(cor_matrix))) {
  for (j in seq_len(ncol(cor_matrix))) {
    cor_plot <- cor_plot %>% add_annotations(
      x = rownames(cor_matrix)[i],
      y = colnames(cor_matrix)[j],
      text = as.character(cor_values[i, j]),
      showarrow = FALSE,
      font = list(color = ifelse(cor_values[i, j] < 0.5, "white", "black"))
    )
  }
}
(cor_plot)



# BOX PLOT

aggregated_data <- df %>%
  select(tmID, year, o_reb, d_reb) %>%
  group_by(tmID, year) %>%
  summarize(
    o_reb = mean(o_reb, na.rm = TRUE), 
    d_reb = mean(d_reb, na.rm = TRUE),
    .groups = "drop"  # Aggiunto per evitare il raggruppamento
  )
reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(o_reb, d_reb), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")
box_plot <- plot_ly()
for (i in 2:ncol(reshaped_data)) {
    current_column_data <- reshaped_data[[i]]
    box_plot <- box_plot %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

(box_plot)



# HEATMAP

heatmap_df <- subset(values, select = -c(o_oreb, o_dreb, d_oreb, d_dreb, won, reb))
rownames(heatmap_df) <- heatmap_df$tmID
heatmap_df <- heatmap_df[,-1]

heatmap_plot <- heatmaply(
 heatmap_df,
 colors = viridis(n = 256,  option = "magma"),
 k_col = 2,
 k_row = 4,
)

(heatmap_plot)



# BARPLOT

bar_plot <- plot_ly(values, x = ~tmID, y = ~o_reb, type = 'bar', name = 'Rimbalzi offensivi', marker = list(color = '#FFAFA1')) %>%
  add_trace(y = ~d_reb, name = 'Rimbalzi difensivi', marker = list(color = '#b2fff8')) %>%
  layout(yaxis = list(title = 'Valori'), barmode = 'stack')

(bar_plot)

```


## TEST ANDERSON-DARLING
```{r}

# Questo codice esegue il test di Anderson-Darling sulla variabile 'reb' nel tuo dataset (df)
ad.test(df$reb)
```
#Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01. In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling.


## TEST KOLMOGOROV SMIRNOV
```{r}

# Test di Kolmogorov-Smirnov per confrontare la distribuzione di 'reb' con una distribuzione normale
ks.test(df$reb, "pnorm")
```
# Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme). In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.


## TEST SHAPIRO WILK
```{r}

# Test di Shapiro-Wilk per la normalità dei dati nella variabile 'reb' (rimbalzi)
sf.test(df$reb)
```
#In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa.


## STUDIO SULLE VITTORIE
```{r}

# ISTOGRAMMA INTERATTIVO

# Calcola la media della variabile "won" nel data frame "df"
mean_value <- mean(df$won)

# Crea un istogramma con plot_ly
histogram <- plot_ly(df, x = ~won, type = "histogram",
                     marker = list(color = "skyblue", line = list(color = "white", width = 0.5)),
                     opacity = 0.7, name = "Campione") %>%
  layout(title = list(text = "<b><i>Distribuzione delle Vittorie</i></b>", y = 0.97),
         xaxis = list(title = "<b><i>Numero di Vittorie</i></b>", zeroline = FALSE),
         yaxis = list(title = "<b><i>Frequenza</i></b>", zeroline = FALSE),
         barmode = "overlay") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "lines", 
            line = list(color = "red", width = 2), name = "<i><b>Media</i></b>") %>%
  add_trace(x = ~mean(won), type = "scatter", mode = "markers", 
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean_value, y = 0, 
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2)

# Visualizza l'istogramma interattivo
histogram



# PLOT DENSITA INTERATTIVO

# Calcola la densità delle vittorie
density_plot <- density(df$won)

# Crea il plot di densità con plot_ly
density_interactive <- plot_ly(x = density_plot$x, y = density_plot$y, type = "scatter", mode = "lines",
                               line = list(color = "skyblue", width = 2), name = "Densità") %>%
  layout(title = list(text = "<b><i>Distribuzione di Densità delle Vittorie</i></b>", x = 0.5),
         xaxis = list(title = "<i>Numero di Vittorie</i>"),
         yaxis = list(title = "<i>Densità</i>"),
         showlegend = TRUE) %>%
  add_trace(x = c(mean(df$won), mean(df$won)), y = c(0, max(density_plot$y)),
            type = "scatter", mode = "lines", line = list(color = "red", width = 2),
            name = "<i><b>Media</b></i>") %>%
  add_trace(x = mean(df$won), y = max(density_plot$y), type = "scatter", mode = "markers",
            marker = list(color = "red", size = 8), showlegend = FALSE) %>%
  add_annotations(text = sprintf("<i><b>Media: %.2f</b></i>", mean(df$won)), x = mean(df$won), y = max(density_plot$y) * 1.05,
                  arrowhead = 2, arrowcolor = "red", arrowsize = 1.5, arrowwidth = 2,
                  ax = 0, ay = -40)

# Visualizza il plot di densità interattivo
density_interactive



# CORRPLOT

data_subset <- df[, c(11:40, 54)]
cor_matrix <- cor(data_subset, use = "complete.obs")
cor_data <- melt(cor_matrix)
names(cor_data) <- c("Variable1", "Variable2", "Correlation")

# Crea la heatmap
p <- plot_ly(data = cor_data, x = ~Variable1, y = ~Variable2, z = ~Correlation,
             type = "heatmap",
             colors = viridis(n = 1024, option = "magma"),
             hoverinfo = "x+y+z") %>%
  layout(
    title = '<b><i>Correlation Matrix Heatmap</i></b>',
    xaxis = list(
      title = list(text = "<b><i>Variabile 1</i></b>", standoff = 0),
      tickangle = 45,
      zeroline = FALSE
    ),
    yaxis = list(
      title = list(text = "<b><i>Variabile 2</i></b>", standoff = 0),
      tickangle = 45,
      zeroline = FALSE
    ),
    autosize = TRUE
  )

# Visualizza la heatmap
(p)



# BOXPLOT

aggregated_data <- df %>%
  select(tmID, year, won) %>%
  group_by(tmID, year) %>%
  summarize(
    won = mean(won, na.rm = TRUE),
  )

reshaped_data <- aggregated_data %>%
  pivot_longer(cols = c(won), names_to = "stat_type", values_to = "stat") %>%
  unite("new_col", tmID, stat_type, sep = "_") %>%
  pivot_wider(names_from = new_col, values_from = "stat")

fig <- plot_ly()

for (i in 2:ncol(reshaped_data)) {
  current_column_data <- reshaped_data[[i]]
  fig <- fig %>% add_trace(y = current_column_data, name = colnames(reshaped_data)[i], type = "box")
}

# Visualizza il boxplot interattivo
(fig)

```


## INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE

### L'IMPORTANZA DEI RIMBALZI
```{r}

# Questo codice effettua alcune operazioni di preprocessing sui dati, come la creazione di nuove variabili (f1 a f10) e la divisione del dataset in set di training e test. Successivamente,      viene creato un modello lineare (linMod) e ne viene eseguito il resampling. Infine, viene creato un modello lineare con le covariate normalizzate (linModNormalized) e vengono generati         grafici di diagnostica per entrambi i modelli.



# o_oreb = Rimbalzi ottenuti in attacco
# o_dreb = Rimbalzi subiti in attacco
# o_reb  = totale rimbalzi in attacco = o_oreb + o_dreb
# d_oreb = Rimbalzi subiti in difesa
# d_dreb = Rimbalzi ottenuti in difesa
# d_reb  = totale rimbalzi in difesa

# Definizione di nuove variabili
df$f1 <- (df$o_oreb) / (df$o_fga - df$o_fgm)
df$f2 <- (df$d_dreb) / (df$d_fga - df$d_fgm)
df$f3 <- (df$o_oreb + 1.5 * df$d_dreb) / (df$o_dreb + 2 * df$d_oreb)
df$f4 <- (df$o_oreb - df$o_dreb) + 1.5 * (df$d_dreb - df$d_oreb)
df$f5 <- (df$d_oreb / df$d_to) / (df$o_dreb / df$o_to)
df$f6 <- (df$o_oreb + df$d_dreb) - (df$d_oreb - df$o_dreb)^2
df$f7 <- (df$f1 + df$f2)^2
df$f8 <- (df$o_oreb) / (df$o_reb)
df$f9 <- ((df$o_oreb) / (df$o_dreb))^2
df$f10 <- ((df$d_dreb) / (df$d_oreb))^2

# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
df = subset(df, select = c("f1", "f2", "f3", "f4", "f5", "f6", "f7", "f8", "f9", "f10", "won", "divID", "confID"))

train  <- df[sample, ]
test   <- df[!sample, ]

#ATTENZIONE: facendo il train sul valore delle variabili, questo significa che sono esse ad essere i nostri dati, non i rimbalzi in se.

# Creazione del modello lineare
linMod <- lm(won ~ f1 + f2 + f3 + f4 + f5 + f6 + f7 + f8 + f9 + f10, data = train)
summary(linMod)


# Normalizziamo le covariate
train$f1_z <- scale(train$f1)
train$f2_z <- scale(train$f2)
train$f3_z <- scale(train$f3)
train$f4_z <- scale(train$f4)
train$f5_z <- scale(train$f5)
train$f6_z <- scale(train$f6)
train$f7_z <- scale(train$f7)
train$f8_z <- scale(train$f8)
train$f9_z <- scale(train$f9)
train$f10_z <- scale(train$f10)

# Normalizzo i dati di test
test$f1_z <- scale(test$f1)
test$f2_z <- scale(test$f2)
test$f3_z <- scale(test$f3)
test$f4_z <- scale(test$f4)
test$f5_z <- scale(test$f5)
test$f6_z <- scale(test$f6)
test$f7_z <- scale(test$f7)
test$f8_z <- scale(test$f8)
test$f9_z <- scale(test$f9)
test$f10_z <- scale(test$f10)

linModNormalized <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train)



# Imposta il layout della pagina
par(mfrow = c(2, 2))

# Grafico dei residui standardizzati
plot(linModNormalized, which = 1, col = "skyblue", pch = 16, main = "Residui Standardizzati")
abline(h = 0, col = "red", lty = 2)  # Aggiunta una linea orizzontale a zero nel grafico dei residui standardizzati

# Grafico dei livelli
plot(linModNormalized, which = 2, col = "lightgreen", pch = 16, main = "Grafico dei Livelli")

# Grafico della distribuzione dei residui
plot(linModNormalized, which = 3, col = "pink", pch = 16, main = "Distribuzione dei Residui")

# Grafico di Q-Q plot dei residui
plot(linModNormalized, which = 4, col = "orange", pch = 16, main = "Q-Q Plot dei Residui")

# Ripristina il layout predefinito
par(mfrow = c(1, 1))

```


## TEST SUL MODELLO DI REGRESSIONE LINEARE

### TEST BREUSCH-PAGAN (Test di omoschedasticità)
```{r}

# 1 Summary
summary(linModNormalized)

# 2 R-quadrato e R-quadrato Adattato
summary_linModNormalized <- summary(linModNormalized)
r_squared <- summary_linModNormalized$r.squared
cat("R-squared:", r_squared, "\n")

n <- length(df$o_oreb)
k <- length(linModNormalized$coefficients) - 1
adjusted_r_squared <- 1 - ((1 - r_squared) * (n - 1) / (n - k - 1))
cat("Adjusted R-squared:", adjusted_r_squared, "\n")

# 3 Test Shapiro per valutare la normalità dei residui
shapiro.test(residuals(linModNormalized))

# 4 Test di omoschedasticità (Breusch-Pagan test) --> il risultato suggerisce omoschedasiticità
bptest(linModNormalized)

# 5 Test di multicollinearità
car::vif(linModNormalized)

```


## TROVO GLI OUTLAYERS
```{r, include=TRUE}

# Il codice implementa l'individuazione degli outliers considerando i residui che superano una soglia moltiplicata per la deviazione standard.


# Calcola i residui dal modello di regressione lineare normalizzato
residui <- residuals(linModNormalized)

# Definisci una soglia per gli outlier
soglia_outlier <- 2
outliers <- which(abs(residui) > soglia_outlier*sd(residui))

# Identifica gli outlier basati sulla soglia definita
outliers <- which(abs(residui) > soglia_outlier * sd(residui))
outliers

```


## MODELLO SENZA OUTLAYERS
```{r, include=TRUE}

# Il codice rimuove gli outliers, ricrea il modello lineare normalizzato e produce grafici di diagnostica per entrambi i modelli.


# Rimuovi gli outliers e ricrea il modello lineare normalizzato
if (length(outliers) != 0) {
  train_1 <- train[-outliers,]
} else {
  train_1 <- train
}

# ATTENZIONE: facendo il train sul valore delle variabili, questo significa che sono esse ad essere i nostri dati, non i rimbalzi in sé.

linModNormalized_1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z, data = train_1)

# Stampa i summary dei modelli
summary(linModNormalized)
summary(linModNormalized_1)



# Visualizza il grafico dei residui rispetto ai livelli per il modello lineare normalizzato linModNormalized
ols_plot_resid_lev(linModNormalized)

# Visualizza il grafico dei residui rispetto ai livelli per il modello lineare normalizzato linModNormalized_1
ols_plot_resid_lev(linModNormalized_1)



# Influence plot il modello lineare normalizzato linModNormalized
influencePlot(linModNormalized, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))
title(main = "Influence Plot - Modello 1", col.main = "blue", font.main = 4)

# Apri una nuova finestra grafica
dev.new()

# Influence plot per il modello lineare normalizzato linModNormalized_1
influencePlot(linModNormalized_1, id = 5)

# Personalizzazione del grafico
par(mar=c(5, 5, 2, 2))

# Aggiunta un titolo sopra al grafico
title(main = "Influence Plot - Modello 2", col.main = "blue", font.main = 4)


```


## METODO DI REGRESSIONE LASSO
```{r}

# Il codice implementa il metodo di regressione LASSO con cross-validation per trovare il miglior valore lambda.


# Definizione della variabile di risposta
y <- train_1$won

# Definizione della matrice delle variabili predittive (uso solo poche variabili ma potete farlo con tutte da togliere però la risposta area)
x <- data.matrix(train_1[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])

# Esegui la cross-validation k-fold per trovare il valore lambda ottimale
cv_model <- cv.glmnet(x, y, alpha = 1)

# Trova il valore lambda ottimale che minimizza il test MSE
best_lambda <- cv_model$lambda.min
best_lambda

# Addestramento del modello con cross-validation
cv_model <- cv.glmnet(x, y)

# Grafico personalizzato
plot(cv_model, xvar="lambda", main="", xlab="log(Lambda)", ylab="Mean Squared Error", col="blue", lwd=2)

# Aggiunta un titolo personalizzato con formattazione LaTeX per grassetto e corsivo
title(main=expression(bold(italic("Validazione Incrociata"))), line = 3)

# Fittiamo il modello con il miglior lambda (penalizzazione)
best_model <- glmnet(x, y, alpha = 1, lambda = best_lambda)

# Stampa i coefficienti del modello LASSO
coef(best_model)

# Stampa il summary del modello lineare normalizzato precedente per confronto
summary(linModNormalized_1)

```


## STIME
```{r}

# Questo codice esegue stime usando un modello Lasso e un modello lineare (LM) su un set di dati di test e ne valuta le prestazioni utilizzando l'errore quadratico medio (RMSE) e le metriche    di classificazione binaria, ad esempio matrice di confusione, accuratezza, precisione, sensibilità, punteggio F e specificità.



# Predizioni utilizzando il modello Lasso
new <- data.matrix(test[, c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z")])
prevLasso <- predict(best_model, s = best_lambda, newx = new)

# Predizioni utilizzando il modello LM (Linear Model)
new <- subset(test, select = c("f1_z", "f2_z", "f3_z", "f4_z", "f5_z", "f6_z", "f7_z", "f8_z", "f9_z", "f10_z"))
prevLM <- predict(linModNormalized_1, newdata = new)

# Calcolo dell'Errore Quadratico Medio (RMSE) per il modello Lasso
rmsLasso <- sqrt(mean((test$won - prevLasso)^2))

# Calcolo dell'Errore Quadratico Medio (RMSE) per il modello LM (Linear Model)
rmsLM <- sqrt(mean((test$won - prevLM)^2))

# Classificazione binaria utilizzando una soglia (0.5) per le predizioni del modello Lasso
prev <- ifelse(prevLasso > 0.5, "1", "0")
prev <- as.factor(prev)

# Matrice di Confusione per le predizioni del modello Lasso
confMatrix <- table(prev, test$won)

# Metriche di Performance
accuracy <- sum(confMatrix[1], confMatrix[4]) / sum(confMatrix[1:4])
precision <- confMatrix[4] / sum(confMatrix[4], confMatrix[2])
sensitivity <- confMatrix[4] / sum(confMatrix[4], confMatrix[3])
fscore <- (2 * (sensitivity * precision)) / (sensitivity + precision)
specificity <- confMatrix[1] / sum(confMatrix[1], confMatrix[2])

# Visualizza i Risultati
print(paste("Accuratezza:", round(accuracy, digits = 4)))
print(paste("Precisione:", round(precision, digits = 4)))
print(paste("Sensibilità:", round(sensitivity, digits = 4)))
print(paste("F-Score:", round(fscore, digits = 4)))
print(paste("Specificità:", round(specificity, digits = 4)))

# Confronto tra RMS
print(paste("RMS Lasso:", round(rmsLasso, digits = 4)))
print(paste("RMS Modello Lineare:", round(rmsLM, digits = 4)))

```


## TEST ANOVA
```{r}

# Esecuzione di un test ANOVA per la variabile 'confID' come predittore

# Supponiamo che 'won' sia la variabile dipendente
resp_conf <- anova(lm(won ~ confID, data = train_1))

# Verifica se la variabile 'confID' ha un effetto significativo sulle vittorie
if (resp_conf["confID", "Pr(>F)"] < 0.05) {
  print("Si rifiuta l'ipotesi nulla perché la variabile Conference ha un effetto sulle vittorie. Posso inserire a modello la variabile.")
} else {
  print("Si accetta l'ipotesi nulla perché la variabile Conference non ha un effetto sulle vittorie. Non posso inserire a modello la variabile.")
}


# Esecuzione di un test ANOVA per la variabile 'divID' come predittore

# Supponiamo che 'won' sia la variabile dipendente
resp_div <- anova(lm(won ~ divID, data = train_1))


# Verifica se la variabile 'divID' ha un effetto significativo sulle vittorie
if (resp_div["divID", "Pr(>F)"] < 0.05) {
  print("Si rifiuta l'ipotesi nulla perché la variabile Division ha un effetto sulle vittorie. Posso inserire a modello la variabile.")
  div <- TRUE
} else {
  print("Si accetta l'ipotesi nulla perché la variabile Division non ha un effetto sulle vittorie. Non posso inserire a modello la variabile.")
  div <- FALSE
}

```


## EFFETTI INTERAZIONE
```{r}

# Verifica del valore di 'div' per costruire il modello appropriato
if (div) {
  linModNormalized1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + divID + f1_z:f2_z + f4_z:divID, data = train_1)
} else {
  linModNormalized1 <- lm(won ~ f1_z + f2_z + f3_z + f4_z + f5_z + f6_z + f7_z + f8_z + f9_z + f10_z + f1_z:f2_z + f4_z:divID, data = train_1)
}

# Estrazione del riassunto del modello
riassunto <- summary(linModNormalized1)

# Estrazione dei nomi delle righe dal riassunto del modello
nomi_righe <- rownames(riassunto$coefficients)

# Nomi delle righe da escludere
nomi_da_escludere <- c("(Intercept)", "f1_z:f2_z", "f4_z:divIDCD", "f4_z:divIDMW", "f4_z:divIDNW", "f4_z:divIDPC", "f4_z:divIDSE", "f4_z:divIDSW", "divIDCD", "divIDMW", "divIDNW", "divIDPC", "divIDSE", "divIDSW")

# Creazione di un vettore con i nomi delle righe da utilizzare
nomi_righe_da_utilizzare <- setdiff(nomi_righe, nomi_da_escludere)

# Aggiunta della variabile 'divID' se presente nei nomi delle righe
if ("divIDCD" %in% nomi_righe) {
  nomi_righe_da_utilizzare <- append(nomi_righe_da_utilizzare, c("divID"))
}

# Indici di inizio e fine per le p-values della variabile 'divID'
div_indice_inizio <- which(rownames(riassunto$coefficients) == "f4_z:divIDCD")
div_indice_fine <- which(rownames(riassunto$coefficients) == "f4_z:divIDSW")

# Estrazione delle p-values della variabile 'divID'
div_p_values <- riassunto$coefficients[div_indice_inizio:div_indice_fine, "Pr(>|t|)"]

# Aggiunta di 'f4_z:divID' se la media delle p-values è inferiore a 0.05
if (mean(div_p_values) < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f4_z:divID"))
}

# Aggiunta di 'f1_z:f2_z' se la sua p-value è inferiore a 0.05
if (riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05) {
  variabili <- append(nomi_righe_da_utilizzare, c("f1_z:f2_z"))
}

# Se nessuna delle condizioni precedenti è soddisfatta, utilizza solo le variabili esistenti
if (!(mean(div_p_values) < 0.05) && !(riassunto$coefficients["f1_z:f2_z", "Pr(>|t|)"] < 0.05)) {
  variabili <- nomi_righe_da_utilizzare
}

# Creazione della formula significativa per il modello
formula_significativa <- as.formula(paste("won ~", paste(variabili, collapse = " + ")))

# Costruzione del nuovo modello lineare con la formula significativa
linModNormalized1 <- lm(formula_significativa, data = train_1)

# Visualizzazione del riassunto del nuovo modello
summary(linModNormalized1)

```


## Può aiutare l’uso della POISSON?
```{r}

# Questo codice addestra un modello di regressione generalizzata di Poisson (linModNormalized2_pois) utilizzando la stessa specifica del modello lineare (linModNormalized2). Successivamente,    vengono ottenuti e combinati i coefficienti di entrambi i modelli in un unico dataframe per una facile comparazione.



# Creazioni di un modello di regressione generalizzata di Poisson
linModNormalized1_pois = glm(formula_significativa, family=poisson(link=log), data = train_1)
summary(linModNormalized1_pois)

# Ottenimento dei coefficienti per ambo i modelli
normal = coefficients(linModNormalized1)
poisson = exp(coefficients(linModNormalized1_pois))

# Combinazione dei coefficienti in un unico dataframe
coefficients_table <- cbind(normal, poisson)

coefficients_table


#Considerazioni Generali:
# È importante notare che gli effetti delle variabili possono essere interpretati in modo diverso a seconda della distribuzione scelta per il modello. La scelta tra distribuzione normale e di   Poisson dipende dalla natura della tua variabile dipendente e dai tuoi obiettivi di modellazione. Nel contesto di modelli di regressione, è sempre buona pratica verificare l'adeguatezza del   modello esaminando i residui, eseguendo test diagnostici e valutando la bontà di adattamento. L'interpretazione dei coefficienti dovrebbe essere fatta considerando la scala appropriata per    la distribuzione utilizzata (lineare per la normale, logaritmica per la Poisson). Se stai cercando di prevedere il numero di vittorie, la distribuzione di Poisson potrebbe essere più
# appropriata per variabili conteggio come questa. Tuttavia, è sempre necessario verificare l'adeguatezza del modello ai dati specifici.

```