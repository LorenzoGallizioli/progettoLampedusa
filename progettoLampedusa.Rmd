
---
title: "ProgettoLampedusa"
output: html_document
date: "2023-12-07"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()

```

# Progetto scelto: Numero 5

NBA moderna (1976-2011): VARIABILE DIPENDENTE: numero di vittorie in stagione
COVARIATE: tutte le altre (o uno specifico insieme di queste, in base all'obiettivo di analisi)
> Considerare solo le squadre che hanno giocato 82 partite (dataset$games==82)

```{r}

# INIZIALIZZAZIONE DATI E GRAFICI DATI

dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio

df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]

dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)

# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]

hist(df$won)
plot(density(df$won))

M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
         tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
         title="Correlation Matrix between Predictor and Outcome variables")

boxplot(df$won ~ df$tmID, las=2)

```

```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE

df$o_canestriSuTotali <- df$o_fgm/df$o_fga # proporzione tra tiri realizzati su tiri totali
df$d_canestriSuTotali <- df$d_fgm/df$d_fga # proporzione tra tiri subiti su tiri totali
df$d_stoppateSuTiri <- df$d_blk/df$d_fga # proporzione su quanti tiri tentati sono stati stoppati
df$o_rimbTiriSbagliati <- df$o_oreb/(df$o_fga-df$o_fgm) # percentuale di rimbalzi presi su tiri sbagliati in attacco
df$d_rimbDef <- df$d_dreb/(df$d_fga-df$d_fgm) # percentuale di rimbalzi difensivi presi in difesa
df$formula_metric <- df$d_pf * (df$o_ftm / df$o_fta)^2 * (df$o_ftm / (df$o_ftm + 2 * (df$o_fgm - df$o_3pm) + 3 * df$o_3pm))

# Modello di regressione 1
(linMod <- lm(won ~ o_canestriSuTotali + d_canestriSuTotali + d_stoppateSuTiri + o_rimbTiriSbagliati + d_rimbDef + formula_metric, data = df ))
summary (linMod)

```

```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time

# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
df$d_canestriSuTotali_z <- scale(df$d_canestriSuTotali)
df$d_stoppateSuTiri_z <- scale(df$d_stoppateSuTiri)
df$o_rimbTiriSbagliati_z <- scale(df$o_rimbTiriSbagliati)
df$d_rimbDef_z <- scale(df$d_rimbDef)
  
# Modello di regressione 2
(linModNormalized <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = df ))
summary (linModNormalized)

```

```{r}

# TEST SUL MODELLO DI REGRESSIONE LINEARE

# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)

# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]

m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
summary(m)

```


```{r}


df$reb = df$o_reb + df$d_reb
summary(df$reb)

hist (df$reb, col = 'steelblue', main = 'caccaculo',
     xlab = 'Petal Width')

plot(density(df$reb))


df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
         tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
         title="Correlation Matrix between Predictor and Outcome variables")

pie(df$reb, labels=df$tmID)

barplot(df$reb, col = c("#1b98e0", "#353436"))

legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))

boxplot(df$won ~ df$reb, las=2)

heatmap(cbind(df$o_reb, df$d_reb))



#TEST ANDERSON-DARLING

install.packages('nortest')
library(nortest)

ad.test(df$reb)


'''Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.

Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01.

In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling. '''


#TEST KOLMOGOROV SMIRNOV

ks.test(df$reb, "pnorm")

''' Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme).

In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.'''


#TEST SHAPIRO WILK

sf.test(df$reb)

''' In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa. '''

```



