
---
title: "ProgettoLampedusa"
output: html_document
date: "2023-12-07"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()

```

# Progetto scelto: Numero 5

NBA moderna (1976-2011): VARIABILE DIPENDENTE: numero di vittorie in stagione
COVARIATE: tutte le altre (o uno specifico insieme di queste, in base all'obiettivo di analisi)
> Considerare solo le squadre che hanno giocato 82 partite (dataset$games==82)

```{r}

# INIZIALIZZAZIONE DATI E GRAFICI DATI

dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio

df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]

dataset$lgID <- as.factor(dataset$lgID) # perchè mi permettono di poter generare variabili dummy
summary(df)

# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]

hist(df$won)
plot(density(df$won))

M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
         tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
         title="Correlation Matrix between Predictor and Outcome variables")

boxplot(df$won ~ df$tmID, las=2)

```
$\text{Formula1} = \frac{\text{Rimbalzi offensivi in attacco}}{\text{Tiri sbagliati su azione}}$
$\text{Formula2} = \frac{\text{Rimbalzi difensivi in difesa presi}}{\text{Tiri sbagliati su azione degli avversari}}$
$\text{Formula3} = \frac{\text{Palle riprese in attacco} + 1.5 \times \text{Palle riprese in difesa}}{\text{Palle perse in attacco} + 2 \times \text{Palle perse in difesa}}$
```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE
# """
# o_oreb = palle riprese dopo azione in attacco
# o_dreb = palle perse dopo azione in attacco
# o_reb  = totale rimbalzi in attacco
# d_oreb = palle perse dopo azione subita
# d_dreb = palle riprese dopo azione subita
# d_reb  = totale rimbalzi in difesa

# formula rapporto:
# o_oreb / o_reb

# formula differenza:
# o_oreb - o_dreb

#   (2 * df$o_to * df$d_to) / (df$o_dreb * df$d_oreb)

# MODELLO "L'IMPORTANZA DEI RIMBALZI"

# Formula 1 [Coefficiente di possesso rimbalzi offensivi]:
# - Abbiamo trovato questa formula importante perché rappresenta la capacità della squadra di ripossesso della palla
# dopo un tiro che non va a canestro e colpisce il tabellone

# Formula 2 [Coefficiente di contropiede]:
# - Abbiamo trovato questa formula importante perché rappresenta la capacità della squadra di impossessarsi della 
# palla dopo un tiro sbagliato della squadra avversaria che colpisce il tabellone, che troviamo un buon stimatore
# della capacità di contropiede della squadra

# Formula 3 [Coefficiente ]
# - Abbiamo trovato questa formula importante perché rappresenta il rapporto tra le palle riprese nei rimbalzi (sia
# offensivi che difensivi) rispetto alle palle perse nei rimbalzi (sia offensivi che difensivi). I coefficienti
# sono stati scelti in base a ciò che riteniamo più importante in una partita, ossia la difesa del proprio
# canestro

# Formula 4:
# 


df$f1 <- (df$o_oreb)/(df$o_fga-df$o_fgm)
df$f2 <- (df$d_dreb)/(df$d_fga-df$d_fgm)
df$f3 <- (df$o_oreb + 1.5 * df$d_dreb)/(df$o_dreb + 2 * df$d_oreb)
df$f4 <- (df$o_oreb - df$o_dreb) + 1.5 * (df$d_dreb - df$d_oreb)
df$f5 <- (df$d_oreb / df$d_to) / (df$o_dreb / df$o_to)

# Modello di regressione 1
linMod <- lm(won ~ f1 + f2 + f3 + f4 + f5, data = df)
summary (linMod)

plot(linMod)

```

```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time

# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
df$d_canestriSuTotali_z <- scale(df$d_canestriSuTotali)
df$d_stoppateSuTiri_z <- scale(df$d_stoppateSuTiri)
df$o_rimbTiriSbagliati_z <- scale(df$o_rimbTiriSbagliati)
df$d_rimbDef_z <- scale(df$d_rimbDef)
  
# Modello di regressione 2
(linModNormalized <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = df ))
summary (linModNormalized)

```

```{r}

# TEST SUL MODELLO DI REGRESSIONE LINEARE

# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)

# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]

m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
summary(m)

```

<<<<<<< HEAD

```{r}


df$reb <- c(df$o_reb + df$d_reb, )
summary(df$reb)

hist (df$reb, col = 'steelblue', main = 'caccaculo',
     xlab = 'Petal Width')

plot(density(df$reb))


df_reb <- data.frame (df$reb, df$o_reb, df$d_reb)
M <- cor(df_reb) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
         tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
         title="Correlation Matrix between Predictor and Outcome variables")

pie(df$reb, labels=df$tmID)

barplot(df$reb, col = c("#1b98e0", "#353436"))

legend("topright", legend = c("Group 1", "Group 2"), fill = c("#1b98e0", "#353436"))

boxplot(df$won ~ df$reb, las=2)

heatmap(cbind(df$o_reb, df$d_reb))



#TEST ANDERSON-DARLING

install.packages('nortest')
library(nortest)

ad.test(df$reb)

#Con un livello di significatività (α) di 0.01 e un p-value molto piccolo (3.1e-09) ottenuto dal test di normalità di Anderson-Darling per i dati della variabile df$reb, puoi concludere che hai sufficiente evidenza statistica per respingere lipotesi nulla che i dati seguono una distribuzione normale.Con il tuo livello di significatività del 0.01 e il p-value molto piccolo (3.1e-09), il p-value è inferiore al livello di significatività, quindi respingeresti lipotesi nulla. Questo suggerisce che i dati nella variabile df$reb non seguono una distribuzione normale al livello di significatività del 0.01. In termini più pratici, hai abbastanza evidenza statistica per concludere che la variabile df$reb non segue una distribuzione normale basandoti sui risultati del test di Anderson-Darling.


#TEST KOLMOGOROV SMIRNOV

ks.test(df$reb, "pnorm")

# Il risultato che hai ottenuto riguarda il test di Kolmogorov-Smirnov a campione singolo sui dati contenuti nella variabile df$reb. Il test KS confronta la distribuzione empirica dei tuoi dati con una distribuzione teorica (spesso una distribuzione uniforme). In breve, il risultato suggerisce che i tuoi dati non seguono la distribuzione teorica presunta, e cè un elevata probabilità che la differenza osservata sia statisticamente significativa.


#TEST SHAPIRO WILK

sf.test(df$reb)

#In sintesi, il risultato del test di Shapiro-Francia indica che i tuoi dati nella variabile df$reb non seguono una distribuzione normale. Questo è supportato dal valore basso del p-value, il quale suggerisce che la differenza tra la distribuzione dei tuoi dati e una distribuzione normale è statisticamente significativa.

```



=======
>>>>>>> c58d6ef503b11e61455634ae66b5a07ca0d71a70
