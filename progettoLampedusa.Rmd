
---
title: "ProgettoLampedusa"
output: html_document
date: "2023-12-07"
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(here)
knitr::opts_knit$set(root.dir = here("progettoLampedusa", "0_Materiale"))
getwd()

```

# Progetto scelto: Numero 5

NBA moderna (1976-2011): VARIABILE DIPENDENTE: numero di vittorie in stagione
COVARIATE: tutte le altre (o uno specifico insieme di queste, in base all'obiettivo di analisi)
> Considerare solo le squadre che hanno giocato 82 partite (dataset$games==82)

```{r}

# INIZIALIZZAZIONE DATI E GRAFICI DATI

dataset <- read.delim("0_Materiale/basketball_teams.txt") # andiamo a leggere il database fornito
FIRST <- 1976 # primo anno del range da considerare per lo studio
LAST <- 2011 # ultimo anno del range da considerare per lo studio

df <- dataset [dataset$lgID=="NBA" & dataset$year >= FIRST & dataset$year <= LAST & dataset$games==82,]

dataset$lgID <- as.factor(dataset$lgID) # perchÃ¨ mi permettono di poter generare variabili dummy
summary(df)

# DEGUB: VERIFICA VALORI MANCANTI
#sum(is.na(nba_model))
#nba_model[which(complete.cases(nba_model))]

hist(df$won)
plot(density(df$won))

M <- cor(as.matrix(df[, c(11:25, 54)])) # correlation matrix
corrplot(M, method="color", outline = TRUE,type="lower",order = "hclust",
         tl.col="black", tl.srt=45, diag=FALSE,tl.cex = 1,mar=c(0,0,3,0),
         title="Correlation Matrix between Predictor and Outcome variables")

boxplot(df$won ~ df$tmID, las=2)

```

```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE

df$o_canestriSuTotali <- df$o_fgm/df$o_fga # proporzione tra tiri realizzati su tiri totali
df$d_canestriSuTotali <- df$d_fgm/df$d_fga # proporzione tra tiri subiti su tiri totali
df$d_stoppateSuTiri <- df$d_blk/df$d_fga # proporzione su quanti tiri tentati sono stati stoppati
df$o_rimbTiriSbagliati <- df$o_oreb/(df$o_fga-df$o_fgm) # percentuale di rimbalzi presi su tiri sbagliati in attacco
df$d_rimbDef <- df$d_dreb/(df$d_fga-df$d_fgm) # percentuale di rimbalzi difensivi presi in difesa
df$formula_metric <- df$d_pf * (df$o_ftm / df$o_fta)^2 * (df$o_ftm / (df$o_ftm + 2 * (df$o_fgm - df$o_3pm) + 3 * df$o_3pm))

# Modello di regressione 1
(linMod <- lm(won ~ o_canestriSuTotali + d_canestriSuTotali + d_stoppateSuTiri + o_rimbTiriSbagliati + d_rimbDef + formula_metric, data = df ))
summary (linMod)

```

```{r}

# INIZIALIZZAZIONE MODELLO DI REGRESSIONE LINEARE NORMALIZZATO
# in un chunk diverso per minimizzare cpu-time

# Normalizziamo le covariate
df$o_canestriSuTotali_z <- scale(df$o_canestriSuTotali)
df$d_canestriSuTotali_z <- scale(df$d_canestriSuTotali)
df$d_stoppateSuTiri_z <- scale(df$d_stoppateSuTiri)
df$o_rimbTiriSbagliati_z <- scale(df$o_rimbTiriSbagliati)
df$d_rimbDef_z <- scale(df$d_rimbDef)
  
# Modello di regressione 2
(linModNormalized <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = df ))
summary (linModNormalized)

```

```{r}

# TEST SUL MODELLO DI REGRESSIONE LINEARE

# Test di homoschedasticita' (Breusch-Pagan test) --> risultato suggerisce omoschedasiticita'
lmtest::bptest(linModNormalized)

# Divisione in Test e Train per evitare che il modello fitti troppo bene sui nostri dati
sample <- sample(c(TRUE, FALSE), nrow(df), replace=TRUE, prob=c(0.7, 0.3))
train  <- df[sample, ]
test   <- df[!sample, ]

m <- lm(won ~ o_canestriSuTotali_z + d_canestriSuTotali_z + d_stoppateSuTiri_z + o_rimbTiriSbagliati_z + d_rimbDef_z, data = train)
summary(m)

```

